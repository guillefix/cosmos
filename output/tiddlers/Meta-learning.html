<p><em>aka learning-to-learn</em></p><p><a class="tc-tiddlylink tc-tiddlylink-resolves" href="#Deep%20meta-reinforcement%20learning">Deep meta-reinforcement learning</a></p><p>Flexible, data-efficient learning naturally requires the operation of prior biases. In general terms,
such biases can derive from two sources; they can either be engineered into the learning system (as,
for example, in convolutional networks), or they can themselves be acquired through learning. The
second case has been explored in the machine learning literature under the rubric of meta-learning
(Schmidhuber et al., 1996; Thrun and Pratt, 1998).</p><p>In one standard setup, the learning agent is confronted with a series of tasks that differ from one
another but also share some underlying set of regularities. Meta-learning is then defined as an
effect whereby the agent improves its performance in each new task more rapidly, on average, than
in past tasks (Thrun and Pratt, 1998). At an architectural level, meta-learning has generally been
conceptualized as involving two learning systems: one lower-level system that learns relatively
quickly, and which is primarily responsible for adapting to each new task; and a slower higher-level
system that works across tasks to tune and improve the lower-level system</p><p>(from <a class="tc-tiddlylink-external" href="https://arxiv.org/pdf/1611.05763.pdf" rel="noopener noreferrer" target="_blank">here</a>)</p><p><a class="tc-tiddlylink-external" href="https://2017.icml.cc/Conferences/2017/Schedule?showEvent=495" rel="noopener noreferrer" target="_blank">https://2017.icml.cc/Conferences/2017/Schedule?showEvent=495</a></p>