<p><a class="tc-tiddlylink-external" href="file:///home/guillefix/Dropbox/Oxford/Systems%20Biology%20DPhil/Research/schoelkopf.pdf" rel="noopener noreferrer" target="_blank">Causal Inference and Statistical Learning!</a></p><p><a class="tc-tiddlylink-external" href="http://www.inference.vc/untitled/" rel="noopener noreferrer" target="_blank">ML beyond Curve Fitting: An Intro to Causal Inference and do-Calculus</a>. you can attempt to perform full causal discovery: attempting to infer the causal model or at least aspects of it, from empirical data.</p><p>But the bottom line is: a full causal model is a form of prior knowledge that you have to add to your analysis in order to get answers to causal questions without actually carrying out interventions.Â </p><hr><p><em>Learning theory and <a class="tc-tiddlylink tc-tiddlylink-resolves" href="#Algorithmic%20information%20theory">Algorithmic information theory</a></em></p><p><a class="tc-tiddlylink-external" href="file:///home/guillefix/Dropbox/Oxford/Systems%20Biology%20DPhil/Research/paper_IEEE_version3_webseite_6526%255b1%255d%20%25282%2529.pdf" rel="noopener noreferrer" target="_blank">Causal inference using the algorithmic Markov condition</a></p><p><a class="tc-tiddlylink-external" href="file:///home/guillefix/Dropbox/Oxford/Systems%20Biology%20DPhil/Research/COLT2010-Steudel_%255b0%255d.pdf" rel="noopener noreferrer" target="_blank">Causal Markov condition for submodular information measures</a></p><p><a class="tc-tiddlylink-external" href="file:///home/guillefix/Dropbox/Oxford/Systems%20Biology%20DPhil/Research/slides_Janzing.pdf" rel="noopener noreferrer" target="_blank">Probality-free causal inference via the Algorithmic Markov Condition</a></p><p><a class="tc-tiddlylink-external" href="http://www.stat.washington.edu/tsr/s566/index.html" rel="noopener noreferrer" target="_blank">http://www.stat.washington.edu/tsr/s566/index.html</a></p>