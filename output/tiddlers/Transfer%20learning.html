<p><em>aka <strong>multi-instance learning</strong>, <strong>multi-task learning</strong></em></p><p>See <a class="tc-tiddlylink tc-tiddlylink-resolves" href="#Deep%20learning">Deep learning</a></p><h3 class=""><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=jCGplSKrl2Y&amp;list=PLjK8ddCbDMphIMSXn-w1IjyYpHU3DaUYw&amp;index=11#t=2m08s" rel="noopener noreferrer" target="_blank">Max-margin learning, transfer and memory networks</a>.</h3><p>good for generalizing models, . Good when don't have much supervision data.</p><h3 class=""><a class="tc-tiddlylink tc-tiddlylink-resolves" href="#Max-margin%20learning">Max-margin learning</a></h3><p>Learn embeddings in one task and transfer these to solve new tasks</p><p><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=jCGplSKrl2Y&amp;list=PLjK8ddCbDMphIMSXn-w1IjyYpHU3DaUYw&amp;index=11#t=15m50s" rel="noopener noreferrer" target="_blank">Example</a>. He exaplains how deep multi-instance learning works. Nice</p><p><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=jCGplSKrl2Y&amp;list=PLjK8ddCbDMphIMSXn-w1IjyYpHU3DaUYw&amp;index=11#t=22m30s" rel="noopener noreferrer" target="_blank">Matching</a></p><p><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=jCGplSKrl2Y&amp;list=PLjK8ddCbDMphIMSXn-w1IjyYpHU3DaUYw&amp;index=11#t=25m10s" rel="noopener noreferrer" target="_blank">Corruption</a> (and example <a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=DzaV6_D_dL4&amp;list=PL613dYIGMXoZBtZhbyiBqb0QtgK6oJbpm&amp;index=3#t=20m" rel="noopener noreferrer" target="_blank">here</a>)</p><p>Example: <a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=jCGplSKrl2Y&amp;list=PLjK8ddCbDMphIMSXn-w1IjyYpHU3DaUYw&amp;index=11#t=41m07s" rel="noopener noreferrer" target="_blank">Bi-lingual word embeddings</a></p><p>When you can't corrupt the data: <a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=jCGplSKrl2Y&amp;list=PLjK8ddCbDMphIMSXn-w1IjyYpHU3DaUYw&amp;index=11#t=42m50s" rel="noopener noreferrer" target="_blank">Siamese networks</a> <a class="tc-tiddlylink-external" href="http://yann.lecun.com/exdb/publis/pdf/chopra-05.pdf" rel="noopener noreferrer" target="_blank">Paper</a></p><p>Example: <a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=jCGplSKrl2Y&amp;list=PLjK8ddCbDMphIMSXn-w1IjyYpHU3DaUYw&amp;index=11#t=45m09s" rel="noopener noreferrer" target="_blank">Question answering system</a>. Followed by <em>relation learning</em> (learning triplets like &quot;cat eats mouse&quot;)</p><p>memory networks (see below) may be useful for transfer learning too..</p><p>One-shot learning using conv nets, as we've already have good embeddings, just compare objects in embeddings. <a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=56TYLaQN4N8&amp;index=12&amp;list=PLjK8ddCbDMphIMSXn-w1IjyYpHU3DaUYw" rel="noopener noreferrer" target="_blank">See beginning of this</a></p><h3 class="">See also <a class="tc-tiddlylink tc-tiddlylink-resolves" href="#Feature%20selection">Feature selection</a></h3><p>See also <a class="tc-tiddlylink tc-tiddlylink-resolves" href="#Incremental%20learning">Incremental learning</a></p>