<p>&lt;p&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Reinforcement%20learning&quot;&gt;Reinforcement learning&lt;/a&gt; methods  which focuses on states and &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#State-action%20pair&quot;&gt;State-action pair&lt;/a&gt;s that the agent is likely to encounter when controlling its environment. This can allow computation to skip over parts of the state space that are irrelevant to the prediction or control problem. &lt;/p&gt;&lt;p&gt;It uses sampled trajectories following the policy for choosing the state which are going to be &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Value%20function%20backup&quot;&gt;backed up&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Real-time%20dynamic%20programming&quot;&gt;Real-time dynamic programming&lt;/a&gt; uses this idea&lt;/p&gt;</p>