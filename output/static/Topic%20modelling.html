<h2 class=""><u><a class="tc-tiddlylink tc-tiddlylink-missing" href="#Latent%20Dirichlet%20allocation">Latent Dirichlet allocation</a></u></h2><p>given number of topics</p><ul><li>documents have multiple topics</li><li>uses <a class="tc-tiddlylink tc-tiddlylink-resolves" href="#Generative%20model">Generative model</a></li></ul><p>Topics: distribution of terms over a fixed vocabulary</p><p>tm,  for preprocessing data. reduce stock words (commonly occuring, not useful). snowballC. stemming software.</p><p>Algotihm: <a class="tc-tiddlylink tc-tiddlylink-resolves" href="#Clustering">Clustering</a> algo.</p><p>Self-consistency. each word assigned topics based on other words which are assigned topics.</p><p><u>Generative model</u>: Each document has a probability over topics (prior of parameter is Dirichlet). Then each word is drawn from the probability distribution represented by the model, each independently.</p>