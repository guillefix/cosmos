<p>&lt;p&gt;Used in different ways in different fields/contexts&lt;/p&gt;&lt;h2 class=&quot;&quot;&gt;&lt;u&gt;In reinforcement learning&lt;/u&gt;&lt;/h2&gt;&lt;p&gt;methods that given a model of the environment, it tries to find optimal policies (depends on definition of model..)&lt;/p&gt;&lt;p&gt;Solving the &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Reinforcement%20learning&quot;&gt;RL&lt;/a&gt; (prediction/control) problem in the context of a fully-known of &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Markov%20decision%20process&quot;&gt;MDP&lt;/a&gt;. It also refers to approximate solution of the problem. See &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Model-based%20reinforcement%20learning&quot;&gt;Model-based reinforcement learning&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;http://www.cell.com/neuron/abstract/S0896-6273(16)30057-5&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Neural Mechanisms of Hierarchical Planning in a Virtual Subway Network&lt;/a&gt;&lt;/p&gt;&lt;hr&gt;&lt;p&gt;See &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Sutton-Barto&quot;&gt;Sutton-Barto&lt;/a&gt;, chapter 8.&lt;/p&gt;&lt;p&gt;â€“&amp;gt; &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Model-free%20reinforcement%20learning&quot;&gt;Model-free reinforcement learning&lt;/a&gt; methods can be used for planning, when trained using simulated experience&lt;/p&gt;&lt;h2 class=&quot;&quot;&gt;&lt;u&gt;State-space planning&lt;/u&gt;&lt;/h2&gt;&lt;h2 class=&quot;&quot;&gt;&lt;u&gt;Plan-space planning&lt;/u&gt;&lt;/h2&gt;&lt;hr&gt;&lt;h2 class=&quot;&quot;&gt;&lt;u&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-missing&quot; href=&quot;#Background%20planning&quot;&gt;Background planning&lt;/a&gt;&lt;/u&gt;&lt;/h2&gt;&lt;p&gt;When planning occurs in parallel and in a sense independently of other learning/acting/decisions processes.&lt;/p&gt;&lt;h2 class=&quot;&quot;&gt;&lt;u&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Decision-time%20planning&quot;&gt;Decision-time planning&lt;/a&gt;&lt;/u&gt;&lt;/h2&gt;&lt;p&gt;Planning which occurs when going to decide which action to take every time a new state is visited. The &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Value%20function%20backup&quot;&gt;backups&lt;/a&gt; performed focus forward from states which most affect the current state (i.e. those that are likely to occur in the future).&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Heuristic%20search&quot;&gt;Heuristic search&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Rollout%20algorithm&quot;&gt;Rollout algorithm&lt;/a&gt;&lt;ul&gt;&lt;li&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Monte%20Carlo%20tree%20search&quot;&gt;Monte Carlo tree search&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;</p>