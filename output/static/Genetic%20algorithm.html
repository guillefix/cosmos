<p>&lt;p&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Genetic%20programming&quot;&gt;Genetic programming&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://engineering.purdue.edu/~sudhoff/ee630/Lecture02.pdf&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;presentation&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=BBLJFYr7zB8&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;example&lt;/a&gt;&lt;/p&gt;&lt;p&gt;See Holland's work. For e.g.&lt;/p&gt;&lt;p&gt;Holland, J. H. (1992). Adaptation in Natural and Artificial Systems, MIT Press, Cambridge MA.&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;http://link.springer.com/chapter/10.1007/3-540-32444-5_3&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Three Elements of a Theory of Representations&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;http://www.mitpressjournals.org/doi/abs/10.1162/106365603322519288#.Vx6xwmqKHCI&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Redundant Representations in Evolutionary Computation&lt;/a&gt;
As a result, uniformly redundant representations do not change the behavior of GAs. Only by increasing r, which means overrepresenting the optimal solution, does GA performance increase. Therefore, non-uniformly redundant representations can only be used advantageously if a-priori information exists regarding the optimal solution. &amp;lt;&amp;gt; &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#No%20free%20lunch%20theorem&quot;&gt;No free lunch theorem&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Bias towards simplicity (see &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#MMathPhys%20oral%20presentation&quot;&gt;MMathPhys oral presentation&lt;/a&gt;) similar to regularization in &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Machine%20learning&quot;&gt;Machine learning&lt;/a&gt;?&lt;/p&gt;&lt;p&gt;First about genotype-phenotype maps in general, I have found that the literature on evolutionary computation/genetic algorithms has quite a lot of good research onto the effects of GP maps in evolution.Here is an example: &lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://link.springer.com/article/10.1007/s10710-012-9159-4&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;https://link.springer.com/article/10.1007/s10710-012-9159-4&lt;/a&gt; , they call &amp;quot;phenotypic robustness&amp;quot; to what we call the phenotype's frequency, on the arrival of the frequent. &lt;/p&gt;&lt;p&gt;This other one (&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://link.springer.com/chapter/10.1007/978-3-319-10762-2_42&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;https://link.springer.com/chapter/10.1007/978-3-319-10762-2_42&lt;/a&gt; ), whose conclusion is like a prelude to our current findings:
&amp;quot;We conjecture that genotype networks could be shaped very differently in other GP systems, however our current observations capture
many general properties of GP, and might even be applicable to other EC
systems. Specifically, the distribution of neutrality is very heterogenous among
various phenotypes. Some genotype networks, i.e. phenotypes, could be orders
of magnitude larger than others. Moreover, the mutational connections among
phenotypes are biased, where a phenotype has more potential to mutate to particular
phenotypes and is less likely to mutate to or is even disconnected from
some phenotypes. The success of an innovative evolutionary search crucially depends
on locating the target phenotype, i.e. whether it is accessible from many
other phenotypes, and on finding an efficient mutational path towards it.
In future studies, we expect to use our methodology in other GP- or ECsystems
and test if our observations and conjectures hold for a wider range of
applications. It would be helpful to look into how a particular EC representation
correlates with genotype network properties, such that we can gain a better
understanding of how a representation influences evolutionary search and how
we could improve the performance of an evolutionary algorithm by designing
more appropriate representations.&amp;quot;&lt;/p&gt;&lt;p&gt;This thesis ( &lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;http://etheses.whiterose.ac.uk/12035/1/thesis.pdf&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;http://etheses.whiterose.ac.uk/12035/1/thesis.pdf&lt;/a&gt; ), which mentions a particular bias found in Cartesian Genetic Programming, which is reminiscent of &amp;quot;bias towards simplicity&amp;quot;:
&amp;quot;However, for classification tasks, smaller solutions are often favoured over
larger as they typically perform better on unseen data; mirroring the concept of Occams
razor [30]. Additionally, smaller solutions are often favoured generally because (a) they
are quicker to execute and (b) they are easier to understand and reason about. Finally,
a bias towards certain topologies does not limit the topologies which can be found given
sufficient evolutionary pressure. In this regard if a task requires a number of nodes larger or
smaller than the number to which there is a bias, this is still possible. Therefore, although
results were presented which showed removing length bias produced better results on
problems specifically designed to require a very large percentage of the possible nodes to
be active [82, 84], on many real world applications, length bias may actually be of benefit.&amp;quot;&lt;/p&gt;&lt;p&gt;More significantly, a few of papers by Per Kristian Lehre, which show not only certain GP maps with bias, but explores their bias towards simplicity. He measures &amp;quot;phenotypic complexity&amp;quot; with LZW, and finds a negative correlation with &amp;quot;neutrality degree&amp;quot; (size of neutral networks):
&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;http://www.sciencedirect.com/science/article/pii/S0303264706001705&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;http://www.sciencedirect.com/science/article/pii/S0303264706001705&lt;/a&gt; 
&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://pdfs.semanticscholar.org/13ec/e15e53b3f6729d5f8cd79380d5dd4209d6d2.pdf&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;https://pdfs.semanticscholar.org/13ec/e15e53b3f6729d5f8cd79380d5dd4209d6d2.pdf&lt;/a&gt;
&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;http://sci-hub.cc/10.1109/eh.2005.26&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;http://sci-hub.cc/10.1109/eh.2005.26&lt;/a&gt;
I should read the second paper more carefuly, because it has plots that are similar to those showing &amp;quot;randomness deficit&amp;quot;. However, he is actually looking at &amp;quot;genotypic complexity&amp;quot;, and so the normal simplicity bias seems not to be there.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=_of6UVV4HGo&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;simple intro vid&lt;/a&gt;&lt;/p&gt;</p>