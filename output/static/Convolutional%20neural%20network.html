<p>&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=bEUX_56Lojc&amp;amp;list=PLjK8ddCbDMphIMSXn-w1IjyYpHU3DaUYw&amp;amp;index=10&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Nando's vid&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;http://cs231n.github.io/&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;http://cs231n.github.io/&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;http://cs231n.github.io/convolutional-networks/&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;http://cs231n.github.io/convolutional-networks/&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;http://cs231n.stanford.edu/syllabus.html&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;http://cs231n.stanford.edu/syllabus.html&lt;/a&gt;&lt;/p&gt;&lt;h3 class=&quot;&quot;&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;http://scs.ryerson.ca/~aharley/vis/conv/&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Convnet demo on the web!&lt;/a&gt; &lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;http://scs.ryerson.ca/~aharley/vis/&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;details here&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;See &lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;http://sci-hub.io/10.1109/msp.2017.2693418&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;this review&lt;/a&gt; of &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Geometric%20deep%20learning&quot;&gt;Geometric deep learning&lt;/a&gt; for understanding why CNNs work, and other new related models&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=SceY4Xnz104&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;[MISS 2016] Andrea Vedaldi - Advanced Convolutional Neural Networks&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://arxiv.org/abs/1506.02025&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Spatial transformer network&lt;/a&gt; – a variant to allow for more general invariances to spatial transformations of the data&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;http://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;ConvNet tute in PyTorch&lt;/a&gt;&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src=&quot;http://scs.ryerson.ca/~aharley/vis/images/convnet_480.png&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;http://deeplearning.net/tutorial/_images/mylenet.png&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Convolution&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://github.com/vdumoulin/conv_arithmetic&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Convolutional arithmetic&lt;/a&gt; – &lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;http://deeplearning.net/software/theano/tutorial/conv_arithmetic.html#transposed-convolution-arithmetic&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;more explanation here&lt;/a&gt; (includes deconv nets)&lt;/p&gt;&lt;p&gt;In The &amp;quot;c1 feature maps&amp;quot; are a set of 2D arrays of neurons. Each array looks for a feature, and a point in the array would represent the location of that feature. To accomplish this, that point of that array is connected to a set of pixels centered in the corresponding point in the input image (an array of pixels). We have much less parameters because for each of these 2D arrays we only specify the parameters for one of the neruons in that array, all other neurons are identical, just connected to displaced sets of pixels.&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=bEUX_56Lojc&amp;amp;list=PLjK8ddCbDMphIMSXn-w1IjyYpHU3DaUYw&amp;amp;index=10#t=14m35s&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;What is convolution&lt;/a&gt;. &lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=bEUX_56Lojc&amp;amp;list=PLjK8ddCbDMphIMSXn-w1IjyYpHU3DaUYw&amp;amp;index=10#t=18m39s&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Correlation&lt;/a&gt;. Flip parameters vector (or array..) and rewrite the correlation, &lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=bEUX_56Lojc&amp;amp;list=PLjK8ddCbDMphIMSXn-w1IjyYpHU3DaUYw&amp;amp;index=10#t=21m50s&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;we get a convolution&lt;/a&gt;. Of course, there's much more to &lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://en.wikipedia.org/wiki/Convolution&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;convolutions&lt;/a&gt;, including the convolution theorem for e.g.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Stride&lt;/strong&gt; How much you jump in pixel space (or in previous layer) when you move from one point to another in a feature layer.&lt;/p&gt;&lt;p&gt;Can also expand boundary (&lt;em&gt;zero padding&lt;/em&gt;) to keep layer gotten by convolution is of same size as original layer.&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=bEUX_56Lojc&amp;amp;list=PLjK8ddCbDMphIMSXn-w1IjyYpHU3DaUYw&amp;amp;index=10#t=27m06s&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Nice example&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=bEUX_56Lojc&amp;amp;list=PLjK8ddCbDMphIMSXn-w1IjyYpHU3DaUYw&amp;amp;index=10#t=35m06s&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;So many indices!&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Pooling&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=bEUX_56Lojc&amp;amp;list=PLjK8ddCbDMphIMSXn-w1IjyYpHU3DaUYw&amp;amp;index=10#t=9m56s&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;This is what it does&lt;/a&gt;. It downsamples. For memory, and invariance (being more insesitive to perturbations).&lt;/p&gt;&lt;p&gt;We can also apply non-linearities in between layers of course, like for contours enhacement&lt;/p&gt;&lt;p&gt;Use as many of these layers Iconvolutions and poolings) as we can train, 20+ (&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Deep%20learning&quot;&gt;Deep learning&lt;/a&gt;)&lt;/p&gt;&lt;p&gt;At the end we may have a fully connected neural layer, to do the classification, but researchers are questioning if it is that useful..&lt;/p&gt;&lt;p&gt;We may &lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=bEUX_56Lojc&amp;amp;list=PLjK8ddCbDMphIMSXn-w1IjyYpHU3DaUYw&amp;amp;index=10#t=13m30s&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;visualize the features&lt;/a&gt; in the feature maps by visualizing the matrices of parameters.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;MaxPooling&lt;/strong&gt; coarse grains by chosing the maximum value in a certain patch of a few pixels. Nearby pixels are likely to be similar, and it is useful to distinguish between the same pattern been seen several times by the filter convolving around it, or several distinct repetitions of the pattern. Maxpool tries to solve for the former fake repetition..&lt;/p&gt;&lt;h3 class=&quot;&quot;&gt;&lt;u&gt;Sentence ConvNets&lt;/u&gt;&lt;/h3&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=bEUX_56Lojc&amp;amp;list=PLjK8ddCbDMphIMSXn-w1IjyYpHU3DaUYw&amp;amp;index=10#t=44m55s&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Vid&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Sentence DynConvNet&lt;/p&gt;&lt;p&gt;Document models (Misha Denil)&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Natural%20language%20processing&quot;&gt;Natural language processing&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;http://www.vlfeat.org/matconvnet/&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;MatConvNet: CNNs for MATLAB&lt;/a&gt;&lt;/p&gt;&lt;h3 class=&quot;&quot;&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=7Wq-QmMT4gM&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;explanation vid&lt;/a&gt;&lt;/h3&gt;&lt;hr&gt;&lt;h2 class=&quot;&quot;&gt;&lt;u&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=GHVaaHESrlY&amp;amp;list=PL16j5WbGpaM0_Tj8CRmurZ8Kk1gEBc7fg&amp;amp;index=9&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Understanding and visualizing CNNs&lt;/a&gt;&lt;/u&gt;&lt;/h2&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=GHVaaHESrlY&amp;amp;list=PL16j5WbGpaM0_Tj8CRmurZ8Kk1gEBc7fg&amp;amp;index=9#t=2m30s&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Look at the raw activations&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=GHVaaHESrlY&amp;amp;list=PL16j5WbGpaM0_Tj8CRmurZ8Kk1gEBc7fg&amp;amp;index=9#t=3m25s&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Look at weights&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=GHVaaHESrlY&amp;amp;list=PL16j5WbGpaM0_Tj8CRmurZ8Kk1gEBc7fg&amp;amp;index=9#t=5m25s&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Visualizing the representation&lt;/a&gt; can use &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#t-SNE&quot;&gt;t-SNE&lt;/a&gt; to visualize&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=GHVaaHESrlY&amp;amp;list=PL16j5WbGpaM0_Tj8CRmurZ8Kk1gEBc7fg&amp;amp;index=9#t=8m38s&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Occlusion experiments&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=AgkfIQ4IGaM&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Deep Visualization Toolbox&lt;/a&gt; – &lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://github.com/yosinski/deep-visualization-toolbox&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;code&lt;/a&gt;&lt;/p&gt;&lt;h3 class=&quot;&quot;&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=GHVaaHESrlY&amp;amp;list=PL16j5WbGpaM0_Tj8CRmurZ8Kk1gEBc7fg&amp;amp;index=9#t=15m35s&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Deconv approach&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=GHVaaHESrlY&amp;amp;list=PL16j5WbGpaM0_Tj8CRmurZ8Kk1gEBc7fg&amp;amp;index=9#t=18m45s&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Guided backpropagation&lt;/a&gt; is like ReLu backwards, only &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Backpropagation&quot;&gt;backpropagating&lt;/a&gt; positive gradients.&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=GHVaaHESrlY&amp;amp;list=PL16j5WbGpaM0_Tj8CRmurZ8Kk1gEBc7fg&amp;amp;index=9#t=26m40s&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Deconvnets&lt;/a&gt;&lt;/p&gt;&lt;h3 class=&quot;&quot;&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=GHVaaHESrlY&amp;amp;list=PL16j5WbGpaM0_Tj8CRmurZ8Kk1gEBc7fg&amp;amp;index=9#t=29m40s&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Optimization method&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=GHVaaHESrlY&amp;amp;list=PL16j5WbGpaM0_Tj8CRmurZ8Kk1gEBc7fg&amp;amp;index=9#t=31m25s&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;They look pretty funny&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=GHVaaHESrlY&amp;amp;list=PL16j5WbGpaM0_Tj8CRmurZ8Kk1gEBc7fg&amp;amp;index=9#t=34m30s&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Combine with grabcut&lt;/a&gt; &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Image%20segmentation&quot;&gt;segmentation&lt;/a&gt; algorithm to cut out the important part of an image&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=GHVaaHESrlY&amp;amp;list=PL16j5WbGpaM0_Tj8CRmurZ8Kk1gEBc7fg&amp;amp;index=9#t=35m20s&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;can do optimization for any neuron&lt;/a&gt;. There are better ways of regularizing for images, they do it indirectly (kind of like &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Dropout&quot;&gt;Dropout&lt;/a&gt;), by blurring.&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=GHVaaHESrlY&amp;amp;list=PL16j5WbGpaM0_Tj8CRmurZ8Kk1gEBc7fg&amp;amp;index=9#t=40m&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;How much can you reconstruct an image from the code&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Deep%20dream&quot;&gt;Deep dream&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Neural%20style&quot;&gt;Neural style&lt;/a&gt;&lt;/p&gt;&lt;h3 class=&quot;&quot;&gt;&lt;u&gt;Stability to local input perturbations&lt;/u&gt;&lt;/h3&gt;&lt;p&gt;if one specifies the convolutional tensors to be complex wavelet decomposition operators and uses complex modulus as pointwise nonlinearities, one can provably obtain stability to local deformations &lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.di.ens.fr/~mallat/papiers/ScatCPAM.pdf&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;(17)&lt;/a&gt; . Although this stability is not rigorously proved for generic compactly supported convolutional tensors, it underpins the empirical success of CNN architectures across a variety of computer-vision applications [1] . See &lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;http://sci-hub.io/10.1109/msp.2017.2693418&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;here&lt;/a&gt;
.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://arxiv.org/pdf/1703.01513.pdf&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Genetic CNN&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://arxiv.org/pdf/1608.06993.pdf&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Densely Connected Convolutional Networks&lt;/a&gt;&lt;/p&gt;</p>