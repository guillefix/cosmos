<p>&lt;p&gt;A &lt;strong&gt;Markov network&lt;/strong&gt;, aka a &lt;strong&gt;Markov random field&lt;/strong&gt;, or &lt;strong&gt;undirected graphical model&lt;/strong&gt;, is a &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Network&quot;&gt;Network&lt;/a&gt; of &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Random%20variable&quot;&gt;Random variable&lt;/a&gt;s that satisfy a &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Markov%20property&quot;&gt;Markov property&lt;/a&gt;. In particular they satisfy the properties below (see General Markov network). It is a &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Graphical%20model&quot;&gt;Graphical model&lt;/a&gt; with undirected edges.&lt;/p&gt;&lt;p&gt;Markov networks have in general full expressive power, as in they can represent any probability distribution over the r.v.s. However, the standard &lt;strong&gt;network representation&lt;/strong&gt; doesn't have all the information contained in the &lt;strong&gt;factor representation&lt;/strong&gt;&lt;/p&gt;&lt;h3 class=&quot;&quot;&gt;&lt;u&gt;Product of factors construction&lt;/u&gt;&lt;/h3&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=SH1K4RtX9uQ&amp;amp;index=28&amp;amp;list=PL50E6E80E8525B59C&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Simple video introduction&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In general, we define factors, which are just functions of the random variables. Then the probability distribution is defined to be the normalized product of these factors.&lt;/p&gt;&lt;h3 class=&quot;&quot;&gt;&lt;u&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=SH1K4RtX9uQ&amp;amp;index=28&amp;amp;list=PL50E6E80E8525B59C#t=9m40s&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Pairwise Markov Network&lt;/a&gt;&lt;/u&gt;&lt;/h3&gt;&lt;p&gt;The simple case when every factor is just a function of two random variables. Then there is a one-to-one correspondence between the factor expansion and the network representation, unlike in the general case described below.&lt;/p&gt;&lt;p&gt;&lt;em&gt;Example&lt;/em&gt;: Lattice Markov networks, often used for &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Image%20processing&quot;&gt;Image processing&lt;/a&gt; (in particular &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Image%20segmentation&quot;&gt;Image segmentation&lt;/a&gt;). See &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Discrete%20optimization&quot;&gt;Discrete optimization&lt;/a&gt; (&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=SH1K4RtX9uQ&amp;amp;index=28&amp;amp;list=PL50E6E80E8525B59C#t=10m50s&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;c.f.&lt;/a&gt;)&lt;/p&gt;&lt;h3 class=&quot;&quot;&gt;&lt;u&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=oLJHOZmAxn0&amp;amp;list=PL50E6E80E8525B59C&amp;amp;index=33&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Log-linear representation&lt;/a&gt;&lt;/u&gt;&lt;/h3&gt;&lt;h2 class=&quot;&quot;&gt;&lt;u&gt;General Markov networks (&lt;small&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=kFcjl3A9QuA&amp;amp;index=29&amp;amp;list=PL50E6E80E8525B59C&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;General Gibbs distribution&lt;/a&gt;&lt;/small&gt;)&lt;/u&gt;&lt;/h2&gt;&lt;p&gt;We need more than pairwise edges, so that we are really talking now about &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Hypergraph&quot;&gt;Hypergraph&lt;/a&gt;s.&lt;/p&gt;&lt;h3 class=&quot;&quot;&gt;&lt;u&gt;Network representation&lt;/u&gt;&lt;/h3&gt;&lt;p&gt;However, &lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=kFcjl3A9QuA&amp;amp;index=29&amp;amp;list=PL50E6E80E8525B59C#t=5m25s&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;it can also be represented as a graph&lt;/a&gt;, and most often is.
It is called the &lt;strong&gt;induced Markov network&lt;/strong&gt;. To construct the network, we put an edge, whenever two variables appear together as arguments in some factor in the product of factors form.&lt;/p&gt;&lt;p&gt;However, &lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=kFcjl3A9QuA&amp;amp;index=29&amp;amp;list=PL50E6E80E8525B59C#t=9m50s&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;there is not a one-to-one correspondence between the factors and this graph representation&lt;/a&gt;, cannot read factorization from graph. &lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=kFcjl3A9QuA&amp;amp;index=29&amp;amp;list=PL50E6E80E8525B59C#t=12m5s&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;However, the graph is still useful&lt;/a&gt; find out the &lt;strong&gt;flow of influence&lt;/strong&gt;/dependencies b/w r.v.s in the network.&lt;/p&gt;&lt;p&gt;&lt;u&gt;Formal definition&lt;/u&gt;&lt;/p&gt;&lt;p&gt;There is a &lt;u&gt;node&lt;/u&gt; for each of the &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Random%20variable&quot;&gt;Random variable&lt;/a&gt;s. In the case of &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Conditional%20random%20field&quot;&gt;Conditional random field&lt;/a&gt;s, one for each output &lt;span&gt;&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;y_k&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.43056em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;strut bottom&quot; style=&quot;height:0.625em;vertical-align:-0.19444em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;base textstyle uncramped&quot;&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathit&quot; style=&quot;margin-right:0.03588em;&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;vlist&quot;&gt;&lt;span style=&quot;top:0.15em;margin-right:0.05em;margin-left:-0.03588em;&quot;&gt;&lt;span class=&quot;fontsize-ensurer reset-size5 size5&quot;&gt;&lt;span style=&quot;font-size:0em;&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;reset-textstyle scriptstyle cramped&quot;&gt;&lt;span class=&quot;mord mathit&quot; style=&quot;margin-right:0.03148em;&quot;&gt;k&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;baseline-fix&quot;&gt;&lt;span class=&quot;fontsize-ensurer reset-size5 size5&quot;&gt;&lt;span style=&quot;font-size:0em;&quot;&gt;​&lt;/span&gt;&lt;/span&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;, and each input &lt;span&gt;&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;x_k&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.43056em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;strut bottom&quot; style=&quot;height:0.58056em;vertical-align:-0.15em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;base textstyle uncramped&quot;&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathit&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;vlist&quot;&gt;&lt;span style=&quot;top:0.15em;margin-right:0.05em;margin-left:0em;&quot;&gt;&lt;span class=&quot;fontsize-ensurer reset-size5 size5&quot;&gt;&lt;span style=&quot;font-size:0em;&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;reset-textstyle scriptstyle cramped&quot;&gt;&lt;span class=&quot;mord mathit&quot; style=&quot;margin-right:0.03148em;&quot;&gt;k&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;baseline-fix&quot;&gt;&lt;span class=&quot;fontsize-ensurer reset-size5 size5&quot;&gt;&lt;span style=&quot;font-size:0em;&quot;&gt;​&lt;/span&gt;&lt;/span&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;.&lt;/p&gt;&lt;p&gt;Then we have an &lt;u&gt;edge&lt;/u&gt; between any two nodes that in such a way that the r.v. satisfy:&lt;/p&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr class=&quot;evenRow&quot;&gt;&lt;td&gt;&lt;u&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Global%20Markov%20property&quot;&gt;Global Markov property&lt;/a&gt;&lt;/u&gt;: Two nodes are conditionally independent if all paths between them contain at least one of the conditioning node. &lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=ZYUnyyVgtyA&amp;amp;list=PL6Xpj9I5qXYEcOhn7TqghAJ6NAPrNmUBH&amp;amp;index=25#t=5m40s&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Example&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;&lt;small&gt;More generally, given disjoint subsets of nodes A, B, and C, X&lt;sub&gt;A&lt;/sub&gt; is conditionally independent of X&lt;sub&gt;B&lt;/sub&gt; given X&lt;sub&gt;C&lt;/sub&gt; if there is no path from any node in A to any node in B that doesn't pass through a node of C.&lt;/small&gt;&lt;/p&gt;&lt;p&gt;–&amp;gt;This can be understood by defining &lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=kFcjl3A9QuA&amp;amp;index=29&amp;amp;list=PL50E6E80E8525B59C#t=14m&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Active trail&lt;/a&gt;s.&lt;/p&gt;&lt;h2 class=&quot;&quot;&gt;&lt;u&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Conditional%20random%20field&quot;&gt;Conditional random field&lt;/a&gt;&lt;/u&gt;&lt;/h2&gt;&lt;p&gt;A &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Conditional%20random%20field&quot;&gt;Conditional random field&lt;/a&gt;, is a Markov network, that models a conditional function &lt;span&gt;&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;∣&lt;/mi&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;p(y|x)&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.75em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;strut bottom&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;base textstyle uncramped&quot;&gt;&lt;span class=&quot;mord mathit&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathit&quot; style=&quot;margin-right:0.03588em;&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;mord mathrm&quot;&gt;∣&lt;/span&gt;&lt;span class=&quot;mord mathit&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;, they are thus called discriminative UGMs.&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=2BXoj778YU8&amp;amp;index=30&amp;amp;list=PL50E6E80E8525B59C&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Video&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.coursera.org/learn/probabilistic-graphical-models/lecture/UJ1Ke/conditional-random-fields&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;https://www.coursera.org/learn/probabilistic-graphical-models/lecture/UJ1Ke/conditional-random-fields&lt;/a&gt;&lt;/p&gt;&lt;hr&gt;&lt;p&gt;See also the generalized &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Factor%20graph&quot;&gt;Factor graph&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.cs.ubc.ca/~murphyk/MLbook/pml-print3-ch19.pdf&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Chapter from Murphy's book&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;http://homepages.inf.ed.ac.uk/rbf/CVonline/LOCAL_COPIES/AV0809/ORCHARD/&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Markov Random Field Optimisation&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=ZYUnyyVgtyA&amp;amp;list=PL6Xpj9I5qXYEcOhn7TqghAJ6NAPrNmUBH&amp;amp;index=25&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Neural networks [3.8] : Conditional random fields - Markov network&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.wikiwand.com/en/Markov_random_field#/Definition&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;wiki&lt;/a&gt;&lt;/p&gt;</p>