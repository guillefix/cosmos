<p>&lt;p&gt;Simplicity bias (also called Algorithmic randomness deficit) is a bias observed in many &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Genotype-phenotype%20map&quot;&gt;GP maps&lt;/a&gt; (see &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Bias%20in%20GP%20maps&quot;&gt;Bias in GP maps&lt;/a&gt;), and in many &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Complex%20systems&quot;&gt;Complex systems&lt;/a&gt; (which can often be seen as GP maps). Simplicity is defined as low &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Complexity%20theory&quot;&gt;complexity&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Simplicity%20bias%20in%20discrete%20systems&quot;&gt;Simplicity bias in discrete systems&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Simplicity%20bias%20in%20finite-state%20transducers&quot;&gt;Simplicity bias in finite-state transducers&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Simplicity%20bias%20in%20continuous%20systems&quot;&gt;Simplicity bias in continuous systems&lt;/a&gt;&lt;/p&gt;&lt;p&gt;See &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#MMathPhys%20oral%20presentation&quot;&gt;MMathPhys oral presentation&lt;/a&gt;, &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Simplicity&quot;&gt;Simplicity&lt;/a&gt;, &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Order&quot;&gt;Order&lt;/a&gt;&lt;/p&gt;&lt;h3 class=&quot;&quot;&gt;&lt;u&gt;Origin of the bias&lt;/u&gt;&lt;/h3&gt;&lt;p&gt;A map that shows simplicity bias seems to need to be simple itself (having short description / low &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Kolmogorov%20complexity&quot;&gt;Kolmogorov complexity&lt;/a&gt;).&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#A%20priori%20probability%20estimates%20from%20structural%20complexity&quot;&gt;A priori probability estimates from structural complexity&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Universal%20probability&quot;&gt;Universal probability&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Origin%20of%20bias%20in%20GP%20maps&quot;&gt;Origin of bias in GP maps&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Sloppy%20model&quot;&gt;Sloppy model&lt;/a&gt;s (&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;http://www.lassp.cornell.edu/sethna/Sloppy/WhyIsSciencePossible.html&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Why is science possible?&lt;/a&gt;)&lt;/p&gt;&lt;h3 class=&quot;&quot;&gt;&lt;u&gt;Types of bias&lt;/u&gt;&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;Algorithmic &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Randomness%20deficit&quot;&gt;Randomness deficit&lt;/a&gt; of the set of outputs (p-sampled) (ARD1).&lt;/li&gt;&lt;li&gt;Algorithmic &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Randomness%20deficit&quot;&gt;Randomness deficit&lt;/a&gt; over the g-sampled distribution of outputs (ARD2).&lt;/li&gt;&lt;/ul&gt;&lt;h3 class=&quot;&quot;&gt;&lt;u&gt;Other features of simple maps&lt;/u&gt;&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;Low probability â€“ low complexity outputs have inputs which are simple. This is because a description of the inputs can be constructed from a description of the output, plus an index, which is at most &lt;span&gt;&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;log&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;\log{A}&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.69444em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;strut bottom&quot; style=&quot;height:0.8888799999999999em;vertical-align:-0.19444em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;base textstyle uncramped&quot;&gt;&lt;span class=&quot;mop&quot;&gt;lo&lt;span style=&quot;margin-right:0.01389em;&quot;&gt;g&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mord textstyle uncramped&quot;&gt;&lt;span class=&quot;mord mathit&quot;&gt;A&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;, where &lt;span&gt;&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;A&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.68333em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;strut bottom&quot; style=&quot;height:0.68333em;vertical-align:0em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;base textstyle uncramped&quot;&gt;&lt;span class=&quot;mord mathit&quot;&gt;A&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; is the size of the input set producing that output. If the output has low probability, &lt;span&gt;&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;A&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.68333em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;strut bottom&quot; style=&quot;height:0.68333em;vertical-align:0em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;base textstyle uncramped&quot;&gt;&lt;span class=&quot;mord mathit&quot;&gt;A&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; is small, and so this term is small. If the output is simple, then its description is small. Both these terms are small, and therefore, the input set must be composed of simple strings.&lt;/li&gt;&lt;/ul&gt;&lt;h3 class=&quot;&quot;&gt;&lt;u&gt;Effects of simplicity bias&lt;/u&gt;&lt;/h3&gt;&lt;p&gt;Effectiveness of &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Learning&quot;&gt;Learning&lt;/a&gt;: &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Simplicity%20and%20learning&quot;&gt;Simplicity and learning&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Effectiveness of &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Evolution&quot;&gt;Evolution&lt;/a&gt; (see &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Biological%20complexity&quot;&gt;Biological complexity&lt;/a&gt;)&lt;/p&gt;</p>