<p><a name="Recurrent neural network">
<div class="tc-tiddler-frame tc-tiddler-view-frame tc-tiddler-exists   tc-tagged-Artificial%20neural%20network " data-tags="[[Artificial neural network]]" data-tiddler-title="Recurrent neural network"><div class="tc-tiddler-title">
<div class="tc-titlebar">
<span class="tc-tiddler-controls">
<span class=" tc-reveal"><button aria-label="more" class=" tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fmore-tiddler-actions" title="More actions"></button><div class=" tc-reveal" hidden="true"></div></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal"><button aria-label="edit" class=" tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fedit" title="Edit this tiddler"></button></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal"><button aria-label="close" class=" tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fclose" title="Close this tiddler"></button></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal" hidden="true"></span><span class=" tc-reveal"><button aria-label="tiddlymap" class=" tc-btn-%24%3A%2Fplugins%2Ffelixhayashi%2Ftiddlymap%2Fmisc%2FquickConnectButton " title="Toggle TiddlyMap actions">


</button></span>
</span>

<span>

<span class="tc-tiddler-title-icon" style="fill:;">

</span>



<h2 class="tc-title">
Recurrent neural network
</h2>

</span>

</div>

<div class="tc-tiddler-info tc-popup-handle tc-reveal" hidden="true"></div>
</div><div class=" tc-reveal" hidden="true"></div>
<div class=" tc-reveal">
<div class="tc-subtitle">
<a class="tc-tiddlylink tc-tiddlylink-missing" href="#cosmos">
cosmos
</a> 25th March 2017 at 11:11am
</div>
</div>
<div class=" tc-reveal">
<div class="tc-tags-wrapper"><span class="tc-tag-list-item">


<span class="tc-drop-down tc-reveal" hidden="true"></span>

</span>
</div>
</div>
<div class="tc-tiddler-body tc-reveal"><h2 class=""><u>Basic RNNs</u></h2><p><strong><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=56TYLaQN4N8&amp;index=12&amp;list=PLjK8ddCbDMphIMSXn-w1IjyYpHU3DaUYw#t=7m48s" rel="noopener noreferrer" target="_blank">Recurrent neural nets</a></strong>. Vanishing gradient problem, naively, RNNs don't give you long term memory.. so you have <a class="tc-tiddlylink tc-tiddlylink-resolves" href="#Long%20short-term%20memory">Long short-term memory</a> networks</p><p><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=mF5-tr7qAF4#t=21m25s" rel="noopener noreferrer" target="_blank">Recurrent neural networks -- Schmidhuber</a></p><p><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=Jkkjy7dVdaY" rel="noopener noreferrer" target="_blank">Recurrent Neural Network Writes Music and Shakespeare Novels - Two Minute Papers</a></p><h3 class=""><u>The vanishing gradients problem</u></h3><p><a class="tc-tiddlylink-external" href="http://people.idsia.ch/~juergen/SeppHochreiter1991ThesisAdvisorSchmidhuber.pdf" rel="noopener noreferrer" target="_blank">Hochreiter1991</a> â€“ <a class="tc-tiddlylink-external" href="http://www-dsi.ing.unifi.it/~paolo/ps/tnn-94-gradient.pdf" rel="noopener noreferrer" target="_blank">Bengio1994</a></p><h2 class=""><u><a class="tc-tiddlylink tc-tiddlylink-resolves" href="#Long%20short-term%20memory">Long short-term memory</a></u></h2><p>Proposed to solve the vanishing gradients problem</p><p><a class="tc-tiddlylink-external" href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/" rel="noopener noreferrer" target="_blank">http://colah.github.io/posts/2015-08-Understanding-LSTMs/</a></p><p>See also <a class="tc-tiddlylink tc-tiddlylink-resolves" href="#Neural%20networks%20with%20memory">Neural networks with memory</a>,  <a class="tc-tiddlylink tc-tiddlylink-resolves" href="#Deep%20learning">Deep learning</a></p><h2 class=""><u>Gated recurrent unit</u></h2><p>A variation of the <a class="tc-tiddlylink tc-tiddlylink-resolves" href="#Long%20short-term%20memory">Long short-term memory</a> network</p><h2 class=""><u>More <a class="tc-tiddlylink tc-tiddlylink-resolves" href="#Augmented%20RNN">Augmented RNN</a>s</u></h2><hr><p>Nice curated list of RNNs: <a class="tc-tiddlylink-external" href="https://github.com/kjw0612/awesome-rnn" rel="noopener noreferrer" target="_blank">https://github.com/kjw0612/awesome-rnn</a></p><hr><p><u><a class="tc-tiddlylink-external" href="https://arxiv.org/pdf/1605.00064.pdf" rel="noopener noreferrer" target="_blank">Higher Order Recurrent Neural Networks</a></u> . We propose to use more memory
units to keep track of more preceding states
in recurrent neural networks (RNNs), which are
all recurrently fed to the hidden layers as feedback
through different weighted path</p></div>


</div>


</a></p>