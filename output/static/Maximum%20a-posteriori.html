<p>A learning principle that can be viewed as approximating the expected value of the output from a model, using <a class="tc-tiddlylink tc-tiddlylink-resolves" href="#Bayesian%20statistics">Bayesian statistics</a>, by only considering the hypothesis with maximum a-posteriori probability (the most likely).</p><p><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=sQ8T9b-uGVE&amp;list=PLA89DCFA6ADACE599&amp;index=11#t=9m36s" rel="noopener noreferrer" target="_blank">video</a></p><p>It can be seen as formally equivalent to <a class="tc-tiddlylink tc-tiddlylink-resolves" href="#Maximum%20likelihood">Maximum likelihood</a> by multiplying the likelihood by the prior (adds the log of the prior to the log likelihood).
</p>