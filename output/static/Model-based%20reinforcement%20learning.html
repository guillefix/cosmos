<p><code>&lt;!doctype html&gt;
&lt;html&gt;
&lt;head&gt;
&lt;meta http-equiv=&quot;Content-Type&quot; content=&quot;text/html;charset=utf-8&quot; /&gt;
&lt;meta name=&quot;generator&quot; content=&quot;TiddlyWiki&quot; /&gt;
&lt;meta name=&quot;tiddlywiki-version&quot; content=&quot;</code>5.1.17<code>&quot; /&gt;
&lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot; /&gt;
&lt;meta name=&quot;apple-mobile-web-app-capable&quot; content=&quot;yes&quot; /&gt;
&lt;meta name=&quot;apple-mobile-web-app-status-bar-style&quot; content=&quot;black-translucent&quot; /&gt;
&lt;meta name=&quot;mobile-web-app-capable&quot; content=&quot;yes&quot;/&gt;
&lt;meta name=&quot;format-detection&quot; content=&quot;telephone=no&quot;&gt;
&lt;link id=&quot;faviconLink&quot; rel=&quot;shortcut icon&quot; href=&quot;favicon.ico&quot;&gt;
&lt;link rel=&quot;stylesheet&quot; href=&quot;static.css&quot;&gt;
&lt;title&gt;</code>Model-based reinforcement learning: Cosmos — Everything there was, there is, <span class="subtitle-dark">and there will be</span><code>&lt;/title&gt;
&lt;/head&gt;
&lt;body class=&quot;tc-body&quot;&gt;
</code><code>
&lt;section class=&quot;tc-story-river&quot;&gt;
</code>
&lt;p&gt;&lt;div class=&quot;tc-tiddler-frame tc-tiddler-view-frame tc-tiddler-exists   tc-tagged-Reinforcement%20learning &quot; data-tags=&quot;[[Reinforcement learning]]&quot; data-tiddler-title=&quot;Model-based reinforcement learning&quot;&gt;&lt;div class=&quot;tc-tiddler-title&quot;&gt;
&lt;div class=&quot;tc-titlebar&quot;&gt;
&lt;span class=&quot;tc-tiddler-controls&quot;&gt;
&lt;span class=&quot; tc-reveal&quot;&gt;&lt;button aria-label=&quot;more&quot; class=&quot;tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fmore-tiddler-actions&quot; title=&quot;More actions&quot;&gt;&lt;/button&gt;&lt;div class=&quot; tc-reveal&quot; hidden=&quot;true&quot;&gt;&lt;/div&gt;&lt;/span&gt;&lt;span class=&quot; tc-reveal&quot; hidden=&quot;true&quot;&gt;&lt;/span&gt;&lt;span class=&quot; tc-reveal&quot; hidden=&quot;true&quot;&gt;&lt;/span&gt;&lt;span class=&quot; tc-reveal&quot; hidden=&quot;true&quot;&gt;&lt;/span&gt;&lt;span class=&quot; tc-reveal&quot; hidden=&quot;true&quot;&gt;&lt;/span&gt;&lt;span class=&quot; tc-reveal&quot; hidden=&quot;true&quot;&gt;&lt;/span&gt;&lt;span class=&quot; tc-reveal&quot;&gt;&lt;button aria-label=&quot;edit&quot; class=&quot;tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fedit&quot; title=&quot;Edit this tiddler&quot;&gt;&lt;/button&gt;&lt;/span&gt;&lt;span class=&quot; tc-reveal&quot; hidden=&quot;true&quot;&gt;&lt;/span&gt;&lt;span class=&quot; tc-reveal&quot; hidden=&quot;true&quot;&gt;&lt;/span&gt;&lt;span class=&quot; tc-reveal&quot; hidden=&quot;true&quot;&gt;&lt;/span&gt;&lt;span class=&quot; tc-reveal&quot; hidden=&quot;true&quot;&gt;&lt;/span&gt;&lt;span class=&quot; tc-reveal&quot; hidden=&quot;true&quot;&gt;&lt;/span&gt;&lt;span class=&quot; tc-reveal&quot;&gt;&lt;button aria-label=&quot;close&quot; class=&quot;tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fclose&quot; title=&quot;Close this tiddler&quot;&gt;&lt;/button&gt;&lt;/span&gt;&lt;span class=&quot; tc-reveal&quot; hidden=&quot;true&quot;&gt;&lt;/span&gt;&lt;span class=&quot; tc-reveal&quot; hidden=&quot;true&quot;&gt;&lt;/span&gt;&lt;span class=&quot; tc-reveal&quot; hidden=&quot;true&quot;&gt;&lt;/span&gt;&lt;span class=&quot; tc-reveal&quot;&gt;&lt;button aria-label=&quot;tiddlymap&quot; class=&quot;tc-btn-invisible tc-btn-%24%3A%2Fplugins%2Ffelixhayashi%2Ftiddlymap%2Fmisc%2FquickConnectButton &quot; title=&quot;Toggle TiddlyMap actions&quot;&gt;


&lt;/button&gt;&lt;/span&gt;
&lt;/span&gt;

&lt;span&gt;

&lt;span class=&quot;tc-tiddler-title-icon&quot; style=&quot;fill:;&quot;&gt;

&lt;/span&gt;



&lt;h2 class=&quot;tc-title&quot;&gt;
Model-based reinforcement learning
&lt;/h2&gt;

&lt;/span&gt;

&lt;/div&gt;

&lt;div class=&quot;tc-tiddler-info tc-popup-handle tc-reveal&quot; hidden=&quot;true&quot;&gt;&lt;/div&gt;
&lt;/div&gt;&lt;div class=&quot; tc-reveal&quot; hidden=&quot;true&quot;&gt;&lt;/div&gt;
&lt;div class=&quot; tc-reveal&quot;&gt;
&lt;div class=&quot;tc-subtitle&quot;&gt;
&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-missing&quot; href=&quot;cosmos.html&quot;&gt;
cosmos
&lt;/a&gt; 23rd May 2018 at 6:39am
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot; tc-reveal&quot;&gt;
&lt;div class=&quot;tc-tags-wrapper&quot;&gt;&lt;span class=&quot;tc-tag-list-item&quot;&gt;


&lt;span class=&quot;tc-tag-label tc-btn-invisible&quot; draggable=&quot;true&quot; style=&quot;background-color:;
fill:#333333;
color:#333333;&quot;&gt;
 Reinforcement learning
&lt;/span&gt;

&lt;span class=&quot;tc-drop-down tc-reveal&quot; hidden=&quot;true&quot;&gt;&lt;/span&gt;

&lt;/span&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;tc-tiddler-body tc-reveal&quot;&gt;&lt;p&gt;&lt;em&gt;aka &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;Planning.html&quot;&gt;Planning&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;Solving the &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;Bellman%2520equation.html&quot;&gt;Bellman equation&lt;/a&gt;s&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://worldmodels.github.io&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;https://worldmodels.github.io&lt;/a&gt;&lt;/p&gt;&lt;h2 class=&quot;&quot;&gt;&lt;u&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;Linear%2520programming.html&quot;&gt;Linear programming&lt;/a&gt;&lt;/u&gt;&lt;/h2&gt;&lt;h2 class=&quot;&quot;&gt;&lt;u&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;Dynamic%2520programming.html&quot;&gt;Dynamic programming&lt;/a&gt;&lt;/u&gt;&lt;/h2&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=dV80NAlEins&amp;amp;list=PLjK8ddCbDMphIMSXn-w1IjyYpHU3DaUYw&amp;amp;index=16#t=13m05&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;idea&lt;/a&gt;
 – &lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=RtxI449ZjSc&amp;amp;list=PLA89DCFA6ADACE599&amp;amp;index=16#t=1h01m45s&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Tradeoffs&lt;/a&gt;. The idea is to solve consistency equations (derived by a &lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=Nd1-UUMVfz4&amp;amp;list=PL7-jPKtc4r78-wCZcQn5IqyuWhBZ8fOxT&amp;amp;index=3#t=1h4m25s&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;look ahead tree&lt;/a&gt; and &lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=Nd1-UUMVfz4&amp;amp;list=PL7-jPKtc4r78-wCZcQn5IqyuWhBZ8fOxT&amp;amp;index=3#t=1h1m48s&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;principle of optimality&lt;/a&gt;) iteratively (see &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;Fixed-point%2520iteration.html&quot;&gt;Fixed-point iteration&lt;/a&gt;). – &lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=Nd1-UUMVfz4&amp;amp;list=PL7-jPKtc4r78-wCZcQn5IqyuWhBZ8fOxT&amp;amp;index=3#t=1h23m55s&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Summary of methods&lt;/a&gt;&lt;/p&gt;&lt;h3 class=&quot;&quot;&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=dV80NAlEins&amp;amp;list=PLjK8ddCbDMphIMSXn-w1IjyYpHU3DaUYw&amp;amp;index=16#t=3m&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Neuro-dynamic programming&lt;/a&gt;&lt;/h3&gt;&lt;h3 class=&quot;&quot;&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;Policy%2520iteration.html&quot;&gt;Policy iteration&lt;/a&gt;&lt;/h3&gt;&lt;h3 class=&quot;&quot;&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;Value%2520iteration.html&quot;&gt;Value iteration&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=Nd1-UUMVfz4&amp;amp;list=PL7-jPKtc4r78-wCZcQn5IqyuWhBZ8fOxT&amp;amp;index=3#t=1h29m&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Extensions to dynamic programming&lt;/a&gt;:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=Nd1-UUMVfz4&amp;amp;list=PL7-jPKtc4r78-wCZcQn5IqyuWhBZ8fOxT&amp;amp;index=3#t=1h29m35s&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Asynchronous dynamic programming (DP)&lt;/a&gt;&lt;ul&gt;&lt;li&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=Nd1-UUMVfz4&amp;amp;list=PL7-jPKtc4r78-wCZcQn5IqyuWhBZ8fOxT&amp;amp;index=3#t=1h30m52s&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;In-place DP&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=Nd1-UUMVfz4&amp;amp;list=PL7-jPKtc4r78-wCZcQn5IqyuWhBZ8fOxT&amp;amp;index=3#t=1h33m30s&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Prioritized sweeping&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=Nd1-UUMVfz4&amp;amp;list=PL7-jPKtc4r78-wCZcQn5IqyuWhBZ8fOxT&amp;amp;index=3#t=1h35m38s&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Real-time dynamic programming&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;There are other algorithms described in the &lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.wikiwand.com/en/Reinforcement_learning&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Wiki page&lt;/a&gt;:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Trust Region Policy Optimization [1]&lt;/li&gt;&lt;li&gt;Proximal Policy Optimization (i.e., TRPO, but using a penalty instead of a constraint on KL divergence), where each subproblem is solved with either SGD or L-BFGS&lt;/li&gt;&lt;li&gt;Cross Entropy Method&lt;/li&gt;&lt;/ul&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr class=&quot;evenRow&quot;&gt;&lt;td&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=Nd1-UUMVfz4&amp;amp;list=PL7-jPKtc4r78-wCZcQn5IqyuWhBZ8fOxT&amp;amp;index=3#t=1h36m30s&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;final comment on DP methods&lt;/a&gt;, DP uses full-width look ahead, plus it assumes we know dynamics. Instead we can &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;Monte%2520Carlo.html&quot;&gt;sample&lt;/a&gt;) –&amp;gt; leads to &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;Model-free%2520reinforcement%2520learning.html&quot;&gt;Model-free reinforcement learning&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;h3 class=&quot;&quot;&gt;&lt;u&gt;Asynchronous DP&lt;/u&gt;&lt;/h3&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;Real-time%2520dynamic%2520programming.html&quot;&gt;Real-time dynamic programming&lt;/a&gt; (RTDP), which uses &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;On-policy%2520trajectory%2520sampling.html&quot;&gt;On-policy trajectory sampling&lt;/a&gt;&lt;/p&gt;&lt;hr&gt;&lt;h2 class=&quot;&quot;&gt;&lt;u&gt;Combining &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;Model-free%2520reinforcement%2520learning.html&quot;&gt;model-free&lt;/a&gt; with model-based RL&lt;/u&gt;&lt;/h2&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://deepmind.com/blog/agents-imagine-and-plan/&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;https://deepmind.com/blog/agents-imagine-and-plan/&lt;/a&gt; – &lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://arxiv.org/abs/1707.06170&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Learning model-based planning from scratch&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Using &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;Generative%2520model.html&quot;&gt;Generative model&lt;/a&gt;s, and &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;Environment%2520model.html&quot;&gt;Environment model&lt;/a&gt;s&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;Empowerment.html&quot;&gt;Empowerment&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;


&lt;/div&gt;

&lt;/p&gt;
<code>
&lt;/section&gt;
&lt;/body&gt;
&lt;/html&gt;
</code></p>