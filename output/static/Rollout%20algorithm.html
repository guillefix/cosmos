<p><a class="tc-tiddlylink tc-tiddlylink-resolves" href="#Decision-time%20planning">Decision-time planning</a> where the value of possible actions is estimated by <a class="tc-tiddlylink tc-tiddlylink-resolves" href="#Monte%20Carlo">Monte Carlo</a> sampling of future trajectories, for each of which we compute the cumulative reward (see <a class="tc-tiddlylink tc-tiddlylink-resolves" href="#Reinforcement%20learning">Reinforcement learning</a>), and averaging. We then often choose the most rewarding action (but with some probability we may not <a class="tc-tiddlylink tc-tiddlylink-resolves" href="#Exploration-exploitation%20trade-off">to allow some exploration</a>.</p><p><a class="tc-tiddlylink tc-tiddlylink-resolves" href="#Monte%20Carlo%20tree%20search">Monte Carlo tree search</a> is an example of this.</p>