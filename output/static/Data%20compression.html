<p>&lt;p&gt;See &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Information%20theory&quot;&gt;Information theory&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Data compression refers to the problem of finding a &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Coding%20theory&quot;&gt;code&lt;/a&gt; that makes the average length of an encoded message as short as possible. This is sometimes called &amp;quot;source coding&amp;quot; because the most compressed code depends on the properties of the &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Information%20source&quot;&gt;Information source&lt;/a&gt; producing the message.&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://en.wikipedia.org/wiki/Data_compression&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;https://en.wikipedia.org/wiki/Data_compression&lt;/a&gt;&lt;/p&gt;&lt;h2 class=&quot;&quot;&gt;Data compression theory&lt;/h2&gt;&lt;p&gt;&lt;u&gt;Lossless compression&lt;/u&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Source%20coding%20theorem&quot;&gt;Source coding theorem&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;u&gt;Lossy compression&lt;/u&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Rate-distortion%20theory&quot;&gt;Rate-distortion theory&lt;/a&gt; &lt;/p&gt;&lt;p&gt;&lt;u&gt;Why does data compression work?&lt;/u&gt;&lt;/p&gt;&lt;p&gt;Because real-world data very often has &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Order&quot;&gt;Order&lt;/a&gt; (i.e. structure), and is thus compressible. One measure for such order is &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Randomness%20deficit&quot;&gt;Randomness deficit&lt;/a&gt;, and one explanation for it is that Nature is algorithmic, i.e. the data we observe often is a result of some (relatively simple) &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Algorithms&quot;&gt;algorithm&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;&lt;sub&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?annotation_id=annotation_4140410753&amp;amp;feature=iv&amp;amp;src_vid=goOa3DGezUA&amp;amp;v=Lto-ajuqW3w&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Compression - Computerphile&lt;/a&gt; &lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=M5c_RFKVkko&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Entropy in Compression - Computerphile&lt;/a&gt;&lt;/sub&gt;&lt;/p&gt;&lt;h2 class=&quot;&quot;&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Data%20compression%20codes&quot;&gt;Data compression codes&lt;/a&gt;&lt;/h2&gt;&lt;hr&gt;&lt;p&gt;&lt;em&gt;Related&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.eng.tau.ac.il/~meir/articles/32%20Universal%20Prediction.pdf&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Universal prediction&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Algorithmics%20on%20compressed%20objects&quot;&gt;Algorithmics on compressed objects&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Compressed%20sensing&quot;&gt;Compressed sensing&lt;/a&gt;&lt;/p&gt;</p>