<p><a class="tc-tiddlylink tc-tiddlylink-resolves" href="#Gaussian%20discriminant%20analysis">Gaussian discriminant analysis</a> where the covariant matrices are the same for all classes, but the means are different. Reduces the number of parameters, which may prevent <a class="tc-tiddlylink tc-tiddlylink-resolves" href="#Overfitting">Overfitting</a>.</p><p>The decision boundaries are linear unlike in GDA</p><p>See <a class="tc-tiddlylink-external" href="http://www.cs.ox.ac.uk/people/varun.kanade/teaching/ML-MT2016/slides/slides07.pdf" rel="noopener noreferrer" target="_blank">here</a></p><p>The predictivion distribution <span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>p</mi><mo>(</mo><mi>y</mi><mi mathvariant="normal">∣</mi><mi>x</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">p(y|x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord mathit">p</span><span class="mopen">(</span><span class="mord mathit" style="margin-right:0.03588em;">y</span><span class="mord mathrm">∣</span><span class="mord mathit">x</span><span class="mclose">)</span></span></span></span></span> has the form of <a class="tc-tiddlylink tc-tiddlylink-resolves" href="#Logistic%20regression">Logistic regression</a>, i.e. a <a class="tc-tiddlylink tc-tiddlylink-resolves" href="#Softmax">Softmax</a> with a linear model. The difference is in the training as we have a prior, which we fit also.</p><hr><p>null subspace algorithm</p>