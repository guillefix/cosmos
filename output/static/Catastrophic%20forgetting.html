<p>&lt;p&gt;Stabilizing in RL &amp;lt;&amp;gt; catastrophic forgetting&lt;/p&gt;&lt;h1 class=&quot;&quot;&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;http://www.pnas.org/content/114/13/3521.full.pdf&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Elastic weight consolidation&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;A recently proposed way of avoiding it.&lt;/p&gt;&lt;p&gt;Use &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Fisher%20information%20matrix&quot;&gt;Fisher information matrix&lt;/a&gt; of log likelihood of previous tasks to give a prior when learning new tasks, to ensure that new tasks are learned while remembering previously learned tasks.&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;http://www.pnas.org/content/suppl/2017/03/14/1611835114.DCSupplemental/pnas.201611835SI.pdf#nameddest=STXT&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Supplementary information&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Any performance gains w.r.t. to the shuffled way of &amp;quot;multi-task&amp;quot; training.&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;http://www.inference.vc/comment-on-overcoming-catastrophic-forgetting-in-nns-are-multiple-penalties-needed-2/&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;nice blog post with detail&lt;/a&gt;&lt;/p&gt;&lt;h2 class=&quot;&quot;&gt;&lt;u&gt;EWC on &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Reinforcement%20learning&quot;&gt;Reinforcement learning&lt;/a&gt;&lt;/u&gt;&lt;/h2&gt;&lt;p&gt;In the primate brain,
the prefrontal cortex is widely viewed as supporting these capabilities
by sustaining neural representations of task context that
exert top–down gating influences on sensory processing, working
memory, and action selection (30–33).&lt;/p&gt;&lt;p&gt;Knowledge
of which task is being performed is required for the EWC algorithm
as it informs which quadratic constraints are currently
active and also which quadratic constraint to update when the
task context changes. To infer the task context, we implemented
an online clustering algorithm that is trained without supervision based on the forget-me-not process&lt;/p&gt;&lt;p&gt;We also allowed the
DQN agents to maintain separate short-term memory buffers for
each inferred task. These allow action values for each task to be
learned off-policy, using an experience replay mechanism (25).
As such, the overall system has memory on two timescales: Over
short timescales, the experience replay mechanism allows learning
in the DQN to be based on the interleaved and uncorrelated
experiences (25). At longer timescales, know-how across tasks is
consolidated by using EWC.&lt;/p&gt;&lt;p&gt;In particular, we
allowed each layer of the network to have biases and per-element
multiplicative gains that were specific to each game.&lt;/p&gt;&lt;p&gt;&lt;small&gt;
we consolidated weights for each game
based on a tractable approximation of parameter uncertainty, the
Fisher information. We therefore sought to test the quality of
our estimates empirically. To do so, we trained an agent on a single
game and measured how perturbing the network parameters
affected the agent’s score. Regardless of which game the agent
was trained on, we observed the same patterns, shown in Fig. 4C.
First, the agent was always more robust to parameter perturbations
shaped by the inverse of the diagonal of the Fisher information
(blue), as opposed to uniform perturbations (black). This
validates that the diagonal of the Fisher information is a good
estimate of how important a parameter is. &lt;/small&gt;&lt;/p&gt;&lt;p&gt;Perturbing on null space also affects performance. This suggests that we are overconfi-
dent about certain parameters being unimportant: It is therefore
likely that the chief limitation of the current implementation is
that it underestimates parameter uncertainty. &lt;mark&gt;Hm?&lt;/mark&gt;&lt;/p&gt;&lt;p&gt;In this respect, the perspective we offer here aligns with a
recent proposal that each synapse stores not only its current
weight, but also an implicit representation of its uncertainty
about that weight (39). This idea is grounded in observations that
postsynaptic potentials are highly variable in amplitude (suggestive
of sampling from the weight posterior during computation)
and those synapses that are more variable are more amenable
to potentiation or depression (suggestive of updating the weight
posterior). Although we do not explore the computational benefits
of sampling from a posterior here, our work aligns with
the notion that &lt;strong&gt;weight uncertainty should inform learning rates&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;With EWC, three values have to be stored for each
synapse: the weight itself, its variance, and its mean. Interestingly,
synapses in the brain also carry more than one piece of
information.&lt;/p&gt;</p>