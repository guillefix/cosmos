<p>&lt;hr&gt;&lt;p&gt;Fairness and bias in ML systems. &lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://arxiv.org/pdf/1802.08139.pdf&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/pdf/1802.08139.pdf&lt;/a&gt;&lt;/p&gt;&lt;p&gt;It has been argued that sing a &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Causal%20inference&quot;&gt;Causal inference&lt;/a&gt; framework would lead to a more intuitive, powerful, and less error-prone way of reasoning about fairness.&lt;/p&gt;&lt;p&gt;Kusner et al. (2017) recently introduced a causal definition
of fairness, called counterfactual fairness, which states that
a decision is fair toward an individual if it coincides with the
one that would have been taken in a counterfactual world in
which the sensitive attribute were different, and suggested
a general algorithm to achieve this notion&lt;/p&gt;</p>