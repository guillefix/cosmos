<p><code>&lt;!doctype html&gt;
&lt;html&gt;
&lt;head&gt;
&lt;meta http-equiv=&quot;Content-Type&quot; content=&quot;text/html;charset=utf-8&quot; /&gt;
&lt;meta name=&quot;generator&quot; content=&quot;TiddlyWiki&quot; /&gt;
&lt;meta name=&quot;tiddlywiki-version&quot; content=&quot;</code>5.1.17<code>&quot; /&gt;
&lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot; /&gt;
&lt;meta name=&quot;apple-mobile-web-app-capable&quot; content=&quot;yes&quot; /&gt;
&lt;meta name=&quot;apple-mobile-web-app-status-bar-style&quot; content=&quot;black-translucent&quot; /&gt;
&lt;meta name=&quot;mobile-web-app-capable&quot; content=&quot;yes&quot;/&gt;
&lt;meta name=&quot;format-detection&quot; content=&quot;telephone=no&quot;&gt;
&lt;link id=&quot;faviconLink&quot; rel=&quot;shortcut icon&quot; href=&quot;favicon.ico&quot;&gt;
&lt;link rel=&quot;stylesheet&quot; href=&quot;static.css&quot;&gt;
&lt;title&gt;</code>Computer vision: Cosmos — Everything there was, there is, <span class="subtitle-dark">and there will be</span><code>&lt;/title&gt;
&lt;/head&gt;
&lt;body class=&quot;tc-body&quot;&gt;
</code><code>
&lt;section class=&quot;tc-story-river&quot;&gt;
</code>
&lt;p&gt;&lt;div class=&quot;tc-tiddler-frame tc-tiddler-view-frame tc-tiddler-exists   tc-tagged-Vision tc-tagged-Artificial%20intelligence &quot; data-tags=&quot;Vision [[Artificial intelligence]]&quot; data-tiddler-title=&quot;Computer vision&quot;&gt;&lt;div class=&quot;tc-tiddler-title&quot;&gt;
&lt;div class=&quot;tc-titlebar&quot;&gt;
&lt;span class=&quot;tc-tiddler-controls&quot;&gt;
&lt;span class=&quot; tc-reveal&quot;&gt;&lt;button aria-label=&quot;more&quot; class=&quot;tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fmore-tiddler-actions&quot; title=&quot;More actions&quot;&gt;&lt;/button&gt;&lt;div class=&quot; tc-reveal&quot; hidden=&quot;true&quot;&gt;&lt;/div&gt;&lt;/span&gt;&lt;span class=&quot; tc-reveal&quot; hidden=&quot;true&quot;&gt;&lt;/span&gt;&lt;span class=&quot; tc-reveal&quot; hidden=&quot;true&quot;&gt;&lt;/span&gt;&lt;span class=&quot; tc-reveal&quot; hidden=&quot;true&quot;&gt;&lt;/span&gt;&lt;span class=&quot; tc-reveal&quot; hidden=&quot;true&quot;&gt;&lt;/span&gt;&lt;span class=&quot; tc-reveal&quot; hidden=&quot;true&quot;&gt;&lt;/span&gt;&lt;span class=&quot; tc-reveal&quot;&gt;&lt;button aria-label=&quot;edit&quot; class=&quot;tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fedit&quot; title=&quot;Edit this tiddler&quot;&gt;&lt;/button&gt;&lt;/span&gt;&lt;span class=&quot; tc-reveal&quot; hidden=&quot;true&quot;&gt;&lt;/span&gt;&lt;span class=&quot; tc-reveal&quot; hidden=&quot;true&quot;&gt;&lt;/span&gt;&lt;span class=&quot; tc-reveal&quot; hidden=&quot;true&quot;&gt;&lt;/span&gt;&lt;span class=&quot; tc-reveal&quot; hidden=&quot;true&quot;&gt;&lt;/span&gt;&lt;span class=&quot; tc-reveal&quot; hidden=&quot;true&quot;&gt;&lt;/span&gt;&lt;span class=&quot; tc-reveal&quot;&gt;&lt;button aria-label=&quot;close&quot; class=&quot;tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fclose&quot; title=&quot;Close this tiddler&quot;&gt;&lt;/button&gt;&lt;/span&gt;&lt;span class=&quot; tc-reveal&quot; hidden=&quot;true&quot;&gt;&lt;/span&gt;&lt;span class=&quot; tc-reveal&quot; hidden=&quot;true&quot;&gt;&lt;/span&gt;&lt;span class=&quot; tc-reveal&quot; hidden=&quot;true&quot;&gt;&lt;/span&gt;&lt;span class=&quot; tc-reveal&quot;&gt;&lt;button aria-label=&quot;tiddlymap&quot; class=&quot;tc-btn-invisible tc-btn-%24%3A%2Fplugins%2Ffelixhayashi%2Ftiddlymap%2Fmisc%2FquickConnectButton &quot; title=&quot;Toggle TiddlyMap actions&quot;&gt;


&lt;/button&gt;&lt;/span&gt;
&lt;/span&gt;

&lt;span&gt;

&lt;span class=&quot;tc-tiddler-title-icon&quot; style=&quot;fill:;&quot;&gt;

&lt;/span&gt;



&lt;h2 class=&quot;tc-title&quot;&gt;
Computer vision
&lt;/h2&gt;

&lt;/span&gt;

&lt;/div&gt;

&lt;div class=&quot;tc-tiddler-info tc-popup-handle tc-reveal&quot; hidden=&quot;true&quot;&gt;&lt;/div&gt;
&lt;/div&gt;&lt;div class=&quot; tc-reveal&quot; hidden=&quot;true&quot;&gt;&lt;/div&gt;
&lt;div class=&quot; tc-reveal&quot;&gt;
&lt;div class=&quot;tc-subtitle&quot;&gt;
&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-missing&quot; href=&quot;cosmos.html&quot;&gt;
cosmos
&lt;/a&gt; 22nd July 2018 at 9:53am
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot; tc-reveal&quot;&gt;
&lt;div class=&quot;tc-tags-wrapper&quot;&gt;&lt;span class=&quot;tc-tag-list-item&quot;&gt;


&lt;span class=&quot;tc-tag-label tc-btn-invisible&quot; draggable=&quot;true&quot; style=&quot;background-color:;
fill:#333333;
color:#333333;&quot;&gt;
 Artificial intelligence
&lt;/span&gt;

&lt;span class=&quot;tc-drop-down tc-reveal&quot; hidden=&quot;true&quot;&gt;&lt;/span&gt;

&lt;/span&gt;
&lt;span class=&quot;tc-tag-list-item&quot;&gt;


&lt;span class=&quot;tc-tag-label tc-btn-invisible&quot; draggable=&quot;true&quot; style=&quot;background-color:;
fill:#333333;
color:#333333;&quot;&gt;
 Vision
&lt;/span&gt;

&lt;span class=&quot;tc-drop-down tc-reveal&quot; hidden=&quot;true&quot;&gt;&lt;/span&gt;

&lt;/span&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;tc-tiddler-body tc-reveal&quot;&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;http://www.movidius.com/&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;http://www.movidius.com/&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;Convolutional%2520neural%2520network.html&quot;&gt;Convolutional neural network&lt;/a&gt;, &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;Image%2520processing.html&quot;&gt;Image processing&lt;/a&gt;, &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;Computer%2520graphics.html&quot;&gt;Computer graphics&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=eve8DkkVdhI&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Cloud vision API&lt;/a&gt;&lt;/p&gt;&lt;h2 class=&quot;&quot;&gt;&lt;u&gt;Problems&lt;/u&gt;&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;Image%2520classification.html&quot;&gt;Image classification&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;Image%2520captioning.html&quot;&gt;Image captioning&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-missing&quot; href=&quot;Image%2520generation.html&quot;&gt;Image generation&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;Object%2520detection.html&quot;&gt;Object detection&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;Image%2520segmentation.html&quot;&gt;Image segmentation&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;Video%2520understanding.html&quot;&gt;Video understanding&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;Camera%2520callibration.html&quot;&gt;Camera callibration&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-missing&quot; href=&quot;Deep%2520multi-scale%2520video%2520prediction%2520beyond%2520mean%2520square%2520error%257Chttp%253A%252F%252Farxiv.org%252Fabs%252F1511.05440.html&quot;&gt;Multi-scale networks&lt;/a&gt; and &lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;http://yann.lecun.com/exdb/publis/pdf/sermanet-ijcnn-11.pdf&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;an application&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;http://arxiv.org/abs/1202.2160&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Scene Parsing with Multiscale Feature Learning, Purity Trees, and Optimal Covers&lt;/a&gt; &lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;http://www.robots.ox.ac.uk/~vgg/hzbook/&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;http://www.robots.ox.ac.uk/~vgg/hzbook/&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;http://www.clement.farabet.net/research.html#parsing&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;http://www.clement.farabet.net/research.html#parsing&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Hand-eye coordination&lt;/strong&gt;. See work on grabbing objects in &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;Robotics.html&quot;&gt;Robotics&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;http://opencv.org/&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;http://opencv.org/&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://pdfs.semanticscholar.org/1123/579e01563e7732fd91cfd4afa029c4fdbd50.pdf&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Nice notes on mathematical optimization for computer graphics and computer vision&lt;/a&gt;&lt;/p&gt;&lt;h2 class=&quot;&quot;&gt;&lt;u&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;Spiking%2520neural%2520network.html&quot;&gt;Spiking neural network&lt;/a&gt; models&lt;/u&gt;&lt;/h2&gt;&lt;h3 class=&quot;&quot;&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;http://www.sciencedirect.com/science/article/pii/S0925231216302880&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Bio-inspired unsupervised learning of visual features leads to robust invariant object recognition&lt;/a&gt;&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;feedforward feature extraction&lt;/strong&gt;. studies have suggested that the feedforward information is usually sufficient for invariant object categorization, leading to models like &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;Convolutional%2520neural%2520network.html&quot;&gt;Convolutional neural network&lt;/a&gt;s.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;biologically plausible learning rules&lt;/strong&gt; the way that biological visual systems learn the appropriate features has attracted much less attention. Yet the ability of the visual cortex to wire itself, mostly in an unsupervised manner, is remarkable [18] and [19]. Here, we propose that adding bio-inspired learning to bio-inspired architectures could improve the models׳ behavior.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;u&gt;algorithm&lt;/u&gt;&lt;/p&gt;&lt;p&gt;The algorithm we used here is a scaled-up version of the one presented in [24] (&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.0030031&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Unsupervised Learning of Visual Features through Spike Timing Dependent Plasticity&lt;/a&gt;).  We used a five-layer hierarchical network, with a classifier at the end, similar to HMAX model. &lt;sub&gt; Specifically, we alternated simple cells that gain selectivity through a sum operation, and complex cells that gain shift and scale invariance through a max operation. &lt;/sub&gt; Spike timing -coding (stronger signal fires first). Weight sharing, as in CNNs.&lt;/p&gt;&lt;p&gt;The image is copied and scaled, and presented to copies of the network (like &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-missing&quot; href=&quot;Cortical%2520column.html&quot;&gt;Cortical column&lt;/a&gt;s).  To increase the sparsity at a given scale and location (corresponding to one cortical column), only the spike corresponding to the best matching orientation is propagated (i.e. a winner-take-all inhibition is employed). &lt;/p&gt;&lt;p&gt;See also &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;Human%2520vision.html&quot;&gt;Human vision&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;http://www.sciencedirect.com/science/article/pii/S0925231215000326&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;A biologically inspired spiking model of visual processing for image feature detection&lt;/a&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Gabon filters.&lt;/li&gt;&lt;li&gt;receptive fields.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Dynamic vision cameras!!&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://arxiv.org/abs/1603.04223&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Investigation of event-based memory surfaces for high-speed tracking, unsupervised feature extraction and object recognition&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.0030031&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Unsupervised Learning of Visual Features through Spike Timing Dependent Plasticity&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;http://ai.stanford.edu/~haosu/&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;http://ai.stanford.edu/~haosu/&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.wikiwand.com/en/Image-based_modeling_and_rendering&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;https://www.wikiwand.com/en/Image-based_modeling_and_rendering&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;


&lt;/div&gt;

&lt;/p&gt;
<code>
&lt;/section&gt;
&lt;/body&gt;
&lt;/html&gt;
</code></p>