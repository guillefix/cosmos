<p>&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://en.wikipedia.org/wiki/Thompson_sampling&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Thompsom sampling&lt;/a&gt; is a heuristic for choosing actions that addresses the exploration-exploitation dilemma in the multi-armed bandit problem. It consists in choosing the action that maximizes the expected reward with respect to a randomly drawn belief.
&lt;/p&gt;</p>