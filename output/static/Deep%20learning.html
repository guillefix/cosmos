<p>&lt;p&gt;Deep learning &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Machine%20learning&quot;&gt;Machine learning&lt;/a&gt; in a modular way using &lt;strong&gt;layers&lt;/strong&gt;, like in &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Torch%20(Deep%20learning%20framework)&quot;&gt;Torch&lt;/a&gt;. &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Artificial%20neural%20network&quot;&gt;Artificial neural network&lt;/a&gt;s, with many layers..&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;http://www.abigailsee.com/2018/02/21/deep-learning-structure-and-innate-priors.html&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;http://www.abigailsee.com/2018/02/21/deep-learning-structure-and-innate-priors.html&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=He4t7Zekob0&amp;amp;index=5&amp;amp;list=PLujxSBD-JXglGL3ERdDOhthD3jTlfudC2&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Two+ Minute Papers - How Does Deep Learning Work?&lt;/a&gt;
– 
&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=g-dKXOlsf98&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;The computer that mastered Go&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.cs.ox.ac.uk/people/nando.defreitas/machinelearning/&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Oxford course (with video)&lt;/a&gt; on lecture 12&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://uk.mathworks.com/discovery/deep-learning.html&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;matlab&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The idea is also that layers are &lt;em&gt;recursive&lt;/em&gt;, i.e. layers can be made up of layers.&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=x1kf4Zojtb0#t=43m05&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;future&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Concepts as programs; programs as networks&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Probabilistic%20programming&quot;&gt;Probabilistic programming&lt;/a&gt;, &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Program%20induction&quot;&gt;Program induction&lt;/a&gt;&lt;/p&gt;&lt;p&gt;trainning models based on demonstration&lt;/p&gt;&lt;p&gt;Multi-agents, and &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Communication&quot;&gt;Communication&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Generating programs is not that different from generating &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Explainable%20artificial%20intelligence&quot;&gt;explanations&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Augmented%20RNN&quot;&gt;Augmented RNN&lt;/a&gt;s&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;http://www.thespermwhale.com/jaseweston/&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;http://www.thespermwhale.com/jaseweston/&lt;/a&gt;&lt;/p&gt;&lt;p&gt;NIPS2016&lt;/p&gt;&lt;hr&gt;&lt;h2 class=&quot;&quot;&gt;Deep learning methods&lt;/h2&gt;&lt;h3 class=&quot;&quot;&gt;&lt;u&gt;Neural networks for spatially structured data&lt;/u&gt;&lt;/h3&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Convolutional%20neural%20network&quot;&gt;Convolutional neural network&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-missing&quot; href=&quot;#Deep%20multi-scale%20video%20prediction%20beyond%20mean%20square%20error%7Chttp%3A%2F%2Farxiv.org%2Fabs%2F1511.05440&quot;&gt;Multi-scale networks&lt;/a&gt; and &lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;http://yann.lecun.com/exdb/publis/pdf/sermanet-ijcnn-11.pdf&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;an application&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;http://arxiv.org/abs/1202.2160&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Scene Parsing with Multiscale Feature Learning, Purity Trees, and Optimal Covers&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;http://www.clement.farabet.net/research.html#parsing&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;http://www.clement.farabet.net/research.html#parsing&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Computer%20vision&quot;&gt;Computer vision&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Residual%20neural%20network&quot;&gt;Residual neural network&lt;/a&gt;&lt;/p&gt;&lt;h3 class=&quot;&quot;&gt;&lt;u&gt;Neural networks for &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Sequence&quot;&gt;sequential&lt;/a&gt; data&lt;/u&gt;&lt;/h3&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Recurrent%20neural%20network&quot;&gt;Recurrent neural network&lt;/a&gt;&lt;/p&gt;&lt;h3 class=&quot;&quot;&gt;&lt;u&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Transfer%20learning&quot;&gt;Transfer learning&lt;/a&gt;&lt;/u&gt;&lt;/h3&gt;&lt;p&gt;good for generalizing models, &lt;strong&gt;transfer learning&lt;/strong&gt;, &lt;strong&gt;multi-task learning&lt;/strong&gt;. Good when don't have much supervision data.&lt;/p&gt;&lt;h3 class=&quot;&quot;&gt;&lt;u&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Neural%20networks%20with%20memory&quot;&gt;Neural networks with memory&lt;/a&gt;&lt;/u&gt;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;Memory&lt;/strong&gt; is good for recognizing time sequence data. See &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Long%20short-term%20memory&quot;&gt;Long short-term memory&lt;/a&gt;.&lt;/p&gt;&lt;h3 class=&quot;&quot;&gt;&lt;u&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Attention%20in%20machine%20learning&quot;&gt;Attention in machine learning&lt;/a&gt;&lt;/u&gt;&lt;/h3&gt;&lt;h3 class=&quot;&quot;&gt;&lt;u&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Integrating%20symbols%20into%20deep%20learning&quot;&gt;Integrating symbols into deep learning&lt;/a&gt;&lt;/u&gt;&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Neural%20Turing%20machine&quot;&gt;Neural Turing machine&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Neural%20programmer-interpreter&quot;&gt;Neural programmer-interpreter&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Deep%20symbolic%20reinforcement%20learning&quot;&gt;Deep symbolic reinforcement learning&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3 class=&quot;&quot;&gt;&lt;u&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Deep%20reinforcement%20learning&quot;&gt;Deep reinforcement learning&lt;/a&gt;&lt;/u&gt;&lt;/h3&gt;&lt;p&gt;&lt;em&gt;more...&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=x1kf4Zojtb0#t=20m&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Structured learning&lt;/a&gt; – Learning to learn and compositionality with deep recurrent neural networks&lt;/p&gt;&lt;hr&gt;&lt;h3 class=&quot;&quot;&gt;Some techniques for deep learning&lt;/h3&gt;&lt;p&gt;&lt;u&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Layers%20for%20deep%20learning&quot;&gt;Layers for deep learning&lt;/a&gt;&lt;/u&gt;&lt;/p&gt;&lt;h2 class=&quot;&quot;&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#New%20advances%20in%20deep%20learning&quot;&gt;New advances in deep learning&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Dropout&quot;&gt;Dropout&lt;/a&gt;. &lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=NUKp0c4xb8w&amp;amp;list=PLjK8ddCbDMphIMSXn-w1IjyYpHU3DaUYw&amp;amp;index=9#t=50m20s&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;usefulness of dropout&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Batch%20normalization&quot;&gt;Batch normalization&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;file:///home/guillefix/Dropbox/Oxford/Systems%20Biology%20DPhil/Research/DeFreitas-NIPS2013_5025.pdf&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Predicting Parameters in Deep Learning&lt;/a&gt; The intuition motivating the techniques in this paper is the well known observation that the first layer features of a neural network trained on natural image patches tend to be globally smooth with local edge features, similar to local Gabor features [6, 13]. I.e. they are seizing the &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Simplicity&quot;&gt;Simplicity&lt;/a&gt; often found in real-world structures. Given this structure, representing the value of each pixel in the feature separately is redundant, since it is highly likely that the value of a pixel will be equal to a weighted average of its neighbours.  &lt;/p&gt;&lt;p&gt;The core of the technique is based on representing the weight matrix as a low rank product of two smaller matrices. &lt;/p&gt;&lt;hr&gt;&lt;h2 class=&quot;&quot;&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Deep%20learning%20theory&quot;&gt;Deep learning theory&lt;/a&gt;&lt;/h2&gt;&lt;h2 class=&quot;&quot;&gt;Deep learning applications&lt;/h2&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Deep%20art&quot;&gt;Deep art&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Applications%20of%20AI&quot;&gt;Applications of AI&lt;/a&gt;&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;u&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Hardware%20for%20deep%20learning&quot;&gt;Hardware for deep learning&lt;/a&gt;&lt;/u&gt;&lt;/p&gt;&lt;p&gt;&lt;u&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Software%20for%20deep%20learning&quot;&gt;Software for deep learning&lt;/a&gt;&lt;/u&gt;&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;u&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#People%20in%20deep%20learning&quot;&gt;People in deep learning&lt;/a&gt;&lt;/u&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#History%20of%20deep%20learning&quot;&gt;History of deep learning&lt;/a&gt;&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;u&gt;Books and reources&lt;/u&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;http://www.sciencedirect.com/science/article/pii/S0893608014002135&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Deep learning in neural networks: An overview&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://deepmind.com/publications.html&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;https://deepmind.com/publications.html&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;http://www.deeplearningbook.org/&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;http://www.deeplearningbook.org/&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;http://carpedm20.github.io/&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;http://carpedm20.github.io/&lt;/a&gt;&lt;/p&gt;&lt;hr&gt;&lt;p&gt;Work on giving prior knowledge to deep learning: &lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://yani.io/annou/thesis_online.pdf&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;https://yani.io/annou/thesis_online.pdf&lt;/a&gt;&lt;/p&gt;</p>