<p><code>&lt;!doctype html&gt;
&lt;html&gt;
&lt;head&gt;
&lt;meta http-equiv=&quot;Content-Type&quot; content=&quot;text/html;charset=utf-8&quot; /&gt;
&lt;meta name=&quot;generator&quot; content=&quot;TiddlyWiki&quot; /&gt;
&lt;meta name=&quot;tiddlywiki-version&quot; content=&quot;</code>5.1.17<code>&quot; /&gt;
&lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot; /&gt;
&lt;meta name=&quot;apple-mobile-web-app-capable&quot; content=&quot;yes&quot; /&gt;
&lt;meta name=&quot;apple-mobile-web-app-status-bar-style&quot; content=&quot;black-translucent&quot; /&gt;
&lt;meta name=&quot;mobile-web-app-capable&quot; content=&quot;yes&quot;/&gt;
&lt;meta name=&quot;format-detection&quot; content=&quot;telephone=no&quot;&gt;
&lt;link id=&quot;faviconLink&quot; rel=&quot;shortcut icon&quot; href=&quot;favicon.ico&quot;&gt;
&lt;link rel=&quot;stylesheet&quot; href=&quot;static.css&quot;&gt;
&lt;title&gt;</code>Deep learning: Cosmos — Everything there was, there is, <span class="subtitle-dark">and there will be</span><code>&lt;/title&gt;
&lt;/head&gt;
&lt;body class=&quot;tc-body&quot;&gt;
</code><code>
&lt;section class=&quot;tc-story-river&quot;&gt;
</code>
&lt;p&gt;&lt;div class=&quot;tc-tiddler-frame tc-tiddler-view-frame tc-tiddler-exists   tc-tagged-Machine%20learning &quot; data-tags=&quot;[[Machine learning]]&quot; data-tiddler-title=&quot;Deep learning&quot;&gt;&lt;div class=&quot;tc-tiddler-title&quot;&gt;
&lt;div class=&quot;tc-titlebar&quot;&gt;
&lt;span class=&quot;tc-tiddler-controls&quot;&gt;
&lt;span class=&quot; tc-reveal&quot;&gt;&lt;button aria-label=&quot;more&quot; class=&quot;tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fmore-tiddler-actions&quot; title=&quot;More actions&quot;&gt;&lt;/button&gt;&lt;div class=&quot; tc-reveal&quot; hidden=&quot;true&quot;&gt;&lt;/div&gt;&lt;/span&gt;&lt;span class=&quot; tc-reveal&quot; hidden=&quot;true&quot;&gt;&lt;/span&gt;&lt;span class=&quot; tc-reveal&quot; hidden=&quot;true&quot;&gt;&lt;/span&gt;&lt;span class=&quot; tc-reveal&quot; hidden=&quot;true&quot;&gt;&lt;/span&gt;&lt;span class=&quot; tc-reveal&quot; hidden=&quot;true&quot;&gt;&lt;/span&gt;&lt;span class=&quot; tc-reveal&quot; hidden=&quot;true&quot;&gt;&lt;/span&gt;&lt;span class=&quot; tc-reveal&quot;&gt;&lt;button aria-label=&quot;edit&quot; class=&quot;tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fedit&quot; title=&quot;Edit this tiddler&quot;&gt;&lt;/button&gt;&lt;/span&gt;&lt;span class=&quot; tc-reveal&quot; hidden=&quot;true&quot;&gt;&lt;/span&gt;&lt;span class=&quot; tc-reveal&quot; hidden=&quot;true&quot;&gt;&lt;/span&gt;&lt;span class=&quot; tc-reveal&quot; hidden=&quot;true&quot;&gt;&lt;/span&gt;&lt;span class=&quot; tc-reveal&quot; hidden=&quot;true&quot;&gt;&lt;/span&gt;&lt;span class=&quot; tc-reveal&quot; hidden=&quot;true&quot;&gt;&lt;/span&gt;&lt;span class=&quot; tc-reveal&quot;&gt;&lt;button aria-label=&quot;close&quot; class=&quot;tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fclose&quot; title=&quot;Close this tiddler&quot;&gt;&lt;/button&gt;&lt;/span&gt;&lt;span class=&quot; tc-reveal&quot; hidden=&quot;true&quot;&gt;&lt;/span&gt;&lt;span class=&quot; tc-reveal&quot; hidden=&quot;true&quot;&gt;&lt;/span&gt;&lt;span class=&quot; tc-reveal&quot; hidden=&quot;true&quot;&gt;&lt;/span&gt;&lt;span class=&quot; tc-reveal&quot;&gt;&lt;button aria-label=&quot;tiddlymap&quot; class=&quot;tc-btn-invisible tc-btn-%24%3A%2Fplugins%2Ffelixhayashi%2Ftiddlymap%2Fmisc%2FquickConnectButton &quot; title=&quot;Toggle TiddlyMap actions&quot;&gt;


&lt;/button&gt;&lt;/span&gt;
&lt;/span&gt;

&lt;span&gt;

&lt;span class=&quot;tc-tiddler-title-icon&quot; style=&quot;fill:;&quot;&gt;

&lt;/span&gt;



&lt;h2 class=&quot;tc-title&quot;&gt;
Deep learning
&lt;/h2&gt;

&lt;/span&gt;

&lt;/div&gt;

&lt;div class=&quot;tc-tiddler-info tc-popup-handle tc-reveal&quot; hidden=&quot;true&quot;&gt;&lt;/div&gt;
&lt;/div&gt;&lt;div class=&quot; tc-reveal&quot; hidden=&quot;true&quot;&gt;&lt;/div&gt;
&lt;div class=&quot; tc-reveal&quot;&gt;
&lt;div class=&quot;tc-subtitle&quot;&gt;
&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-missing&quot; href=&quot;cosmos.html&quot;&gt;
cosmos
&lt;/a&gt; 26th February 2018 at 8:42am
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot; tc-reveal&quot;&gt;
&lt;div class=&quot;tc-tags-wrapper&quot;&gt;&lt;span class=&quot;tc-tag-list-item&quot;&gt;


&lt;span class=&quot;tc-tag-label tc-btn-invisible&quot; draggable=&quot;true&quot; style=&quot;background-color:;
fill:#333333;
color:#333333;&quot;&gt;
 Machine learning
&lt;/span&gt;

&lt;span class=&quot;tc-drop-down tc-reveal&quot; hidden=&quot;true&quot;&gt;&lt;/span&gt;

&lt;/span&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;tc-tiddler-body tc-reveal&quot;&gt;&lt;p&gt;Deep learning &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;Machine%2520learning.html&quot;&gt;Machine learning&lt;/a&gt; in a modular way using &lt;strong&gt;layers&lt;/strong&gt;, like in &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;Torch%2520(Deep%2520learning%2520framework).html&quot;&gt;Torch&lt;/a&gt;. &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;Artificial%2520neural%2520network.html&quot;&gt;Artificial neural network&lt;/a&gt;s, with many layers..&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;http://www.abigailsee.com/2018/02/21/deep-learning-structure-and-innate-priors.html&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;http://www.abigailsee.com/2018/02/21/deep-learning-structure-and-innate-priors.html&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=He4t7Zekob0&amp;amp;index=5&amp;amp;list=PLujxSBD-JXglGL3ERdDOhthD3jTlfudC2&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Two+ Minute Papers - How Does Deep Learning Work?&lt;/a&gt;
– 
&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=g-dKXOlsf98&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;The computer that mastered Go&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.cs.ox.ac.uk/people/nando.defreitas/machinelearning/&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Oxford course (with video)&lt;/a&gt; on lecture 12&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://uk.mathworks.com/discovery/deep-learning.html&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;matlab&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The idea is also that layers are &lt;em&gt;recursive&lt;/em&gt;, i.e. layers can be made up of layers.&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=x1kf4Zojtb0#t=43m05&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;future&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Concepts as programs; programs as networks&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;Probabilistic%2520programming.html&quot;&gt;Probabilistic programming&lt;/a&gt;, &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;Program%2520induction.html&quot;&gt;Program induction&lt;/a&gt;&lt;/p&gt;&lt;p&gt;trainning models based on demonstration&lt;/p&gt;&lt;p&gt;Multi-agents, and &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;Communication.html&quot;&gt;Communication&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Generating programs is not that different from generating &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;Explainable%2520artificial%2520intelligence.html&quot;&gt;explanations&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;Augmented%2520RNN.html&quot;&gt;Augmented RNN&lt;/a&gt;s&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;http://www.thespermwhale.com/jaseweston/&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;http://www.thespermwhale.com/jaseweston/&lt;/a&gt;&lt;/p&gt;&lt;p&gt;NIPS2016&lt;/p&gt;&lt;hr&gt;&lt;h2 class=&quot;&quot;&gt;Deep learning methods&lt;/h2&gt;&lt;h3 class=&quot;&quot;&gt;&lt;u&gt;Neural networks for spatially structured data&lt;/u&gt;&lt;/h3&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;Convolutional%2520neural%2520network.html&quot;&gt;Convolutional neural network&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-missing&quot; href=&quot;Deep%2520multi-scale%2520video%2520prediction%2520beyond%2520mean%2520square%2520error%257Chttp%253A%252F%252Farxiv.org%252Fabs%252F1511.05440.html&quot;&gt;Multi-scale networks&lt;/a&gt; and &lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;http://yann.lecun.com/exdb/publis/pdf/sermanet-ijcnn-11.pdf&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;an application&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;http://arxiv.org/abs/1202.2160&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Scene Parsing with Multiscale Feature Learning, Purity Trees, and Optimal Covers&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;http://www.clement.farabet.net/research.html#parsing&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;http://www.clement.farabet.net/research.html#parsing&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;Computer%2520vision.html&quot;&gt;Computer vision&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;Residual%2520neural%2520network.html&quot;&gt;Residual neural network&lt;/a&gt;&lt;/p&gt;&lt;h3 class=&quot;&quot;&gt;&lt;u&gt;Neural networks for &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;Sequence.html&quot;&gt;sequential&lt;/a&gt; data&lt;/u&gt;&lt;/h3&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;Recurrent%2520neural%2520network.html&quot;&gt;Recurrent neural network&lt;/a&gt;&lt;/p&gt;&lt;h3 class=&quot;&quot;&gt;&lt;u&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;Transfer%2520learning.html&quot;&gt;Transfer learning&lt;/a&gt;&lt;/u&gt;&lt;/h3&gt;&lt;p&gt;good for generalizing models, &lt;strong&gt;transfer learning&lt;/strong&gt;, &lt;strong&gt;multi-task learning&lt;/strong&gt;. Good when don't have much supervision data.&lt;/p&gt;&lt;h3 class=&quot;&quot;&gt;&lt;u&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;Neural%2520networks%2520with%2520memory.html&quot;&gt;Neural networks with memory&lt;/a&gt;&lt;/u&gt;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;Memory&lt;/strong&gt; is good for recognizing time sequence data. See &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;Long%2520short-term%2520memory.html&quot;&gt;Long short-term memory&lt;/a&gt;.&lt;/p&gt;&lt;h3 class=&quot;&quot;&gt;&lt;u&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;Attention%2520in%2520machine%2520learning.html&quot;&gt;Attention in machine learning&lt;/a&gt;&lt;/u&gt;&lt;/h3&gt;&lt;h3 class=&quot;&quot;&gt;&lt;u&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;Integrating%2520symbols%2520into%2520deep%2520learning.html&quot;&gt;Integrating symbols into deep learning&lt;/a&gt;&lt;/u&gt;&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;Neural%2520Turing%2520machine.html&quot;&gt;Neural Turing machine&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;Neural%2520programmer-interpreter.html&quot;&gt;Neural programmer-interpreter&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;Deep%2520symbolic%2520reinforcement%2520learning.html&quot;&gt;Deep symbolic reinforcement learning&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3 class=&quot;&quot;&gt;&lt;u&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;Deep%2520reinforcement%2520learning.html&quot;&gt;Deep reinforcement learning&lt;/a&gt;&lt;/u&gt;&lt;/h3&gt;&lt;p&gt;&lt;em&gt;more...&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=x1kf4Zojtb0#t=20m&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Structured learning&lt;/a&gt; – Learning to learn and compositionality with deep recurrent neural networks&lt;/p&gt;&lt;hr&gt;&lt;h3 class=&quot;&quot;&gt;Some techniques for deep learning&lt;/h3&gt;&lt;p&gt;&lt;u&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;Layers%2520for%2520deep%2520learning.html&quot;&gt;Layers for deep learning&lt;/a&gt;&lt;/u&gt;&lt;/p&gt;&lt;h2 class=&quot;&quot;&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;New%2520advances%2520in%2520deep%2520learning.html&quot;&gt;New advances in deep learning&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;Dropout.html&quot;&gt;Dropout&lt;/a&gt;. &lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=NUKp0c4xb8w&amp;amp;list=PLjK8ddCbDMphIMSXn-w1IjyYpHU3DaUYw&amp;amp;index=9#t=50m20s&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;usefulness of dropout&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;Batch%2520normalization.html&quot;&gt;Batch normalization&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;file:///home/guillefix/Dropbox/Oxford/Systems%20Biology%20DPhil/Research/DeFreitas-NIPS2013_5025.pdf&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Predicting Parameters in Deep Learning&lt;/a&gt; The intuition motivating the techniques in this paper is the well known observation that the first layer features of a neural network trained on natural image patches tend to be globally smooth with local edge features, similar to local Gabor features [6, 13]. I.e. they are seizing the &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;Simplicity.html&quot;&gt;Simplicity&lt;/a&gt; often found in real-world structures. Given this structure, representing the value of each pixel in the feature separately is redundant, since it is highly likely that the value of a pixel will be equal to a weighted average of its neighbours.  &lt;/p&gt;&lt;p&gt;The core of the technique is based on representing the weight matrix as a low rank product of two smaller matrices. &lt;/p&gt;&lt;hr&gt;&lt;h2 class=&quot;&quot;&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;Deep%2520learning%2520theory.html&quot;&gt;Deep learning theory&lt;/a&gt;&lt;/h2&gt;&lt;h2 class=&quot;&quot;&gt;Deep learning applications&lt;/h2&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;Deep%2520art.html&quot;&gt;Deep art&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;Applications%2520of%2520AI.html&quot;&gt;Applications of AI&lt;/a&gt;&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;u&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;Hardware%2520for%2520deep%2520learning.html&quot;&gt;Hardware for deep learning&lt;/a&gt;&lt;/u&gt;&lt;/p&gt;&lt;p&gt;&lt;u&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;Software%2520for%2520deep%2520learning.html&quot;&gt;Software for deep learning&lt;/a&gt;&lt;/u&gt;&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;u&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;People%2520in%2520deep%2520learning.html&quot;&gt;People in deep learning&lt;/a&gt;&lt;/u&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;History%2520of%2520deep%2520learning.html&quot;&gt;History of deep learning&lt;/a&gt;&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;u&gt;Books and reources&lt;/u&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;http://www.sciencedirect.com/science/article/pii/S0893608014002135&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Deep learning in neural networks: An overview&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://deepmind.com/publications.html&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;https://deepmind.com/publications.html&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;http://www.deeplearningbook.org/&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;http://www.deeplearningbook.org/&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;http://carpedm20.github.io/&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;http://carpedm20.github.io/&lt;/a&gt;&lt;/p&gt;&lt;hr&gt;&lt;p&gt;Work on giving prior knowledge to deep learning: &lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://yani.io/annou/thesis_online.pdf&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;https://yani.io/annou/thesis_online.pdf&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;


&lt;/div&gt;

&lt;/p&gt;
<code>
&lt;/section&gt;
&lt;/body&gt;
&lt;/html&gt;
</code></p>