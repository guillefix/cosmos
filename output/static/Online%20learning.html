<p>&lt;p&gt;This takes the distribution-free bounds of &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Statistical%20learning%20theory&quot;&gt;Statistical learning theory&lt;/a&gt; and goes one step further, by assuming that the data does not necessarily follow a distribution at all. Instead we consider it &lt;em&gt;arbitrary&lt;/em&gt; so that to obtain bounds on the &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-missing&quot; href=&quot;#Regret%20(Online%20learning)&quot;&gt;Regret (Online learning)&lt;/a&gt;, we need to consider the worst-case data.&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;http://courses.cs.washington.edu/courses/cse599s/12sp/scribes.html&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;lecture notes&lt;/a&gt; â€“ &lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;http://sbubeck.com/BubeckLectureNotes.pdf&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;intro notes&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;http://www.cs.ox.ac.uk/people/varun.kanade/teaching/AML-HT2017/lectures/mistakebound-online.pdf&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Other notes&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Prediction%20with%20expert%20advice&quot;&gt;Prediction with expert advice&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Can relate to &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Learning%20boosting&quot;&gt;Learning boosting&lt;/a&gt;&lt;/p&gt;&lt;p&gt;he essential difference be-tween online learning and statistical learning, in addition to the sequential aspect,is the fact that no probabilistic assumption is made on the dataset.&lt;/p&gt;&lt;p&gt;Online learnability (worst-case regret) is stronger (it implies) &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Probably%20approximately%20correct&quot;&gt;PAC learnability&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;u&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-missing&quot; href=&quot;#Bandit%20problem&quot;&gt;Bandit problem&lt;/a&gt;&lt;/u&gt;&lt;/p&gt;&lt;p&gt;An example of an online learning problem with &lt;em&gt;limited feedback&lt;/em&gt;: instead of observing the adversary's action, we observe only the incurred loss in the case of bandits.&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;http://www.jmlr.org/proceedings/papers/v35/kale14a.pdf&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Multiarmed Bandits With Limited Expert Advice&lt;/a&gt;&lt;/p&gt;&lt;hr&gt;&lt;hr&gt;&lt;p&gt;Adversarial online learning is about being probability-free, but solution requires stochastic agent, so needs probability at the end..&lt;/p&gt;&lt;p&gt;Is the usefulness of adversarial/agnostic analyses that they tend to imply non-worst case learnability often..?&lt;/p&gt;&lt;p&gt;Adversarial analysis of the agent. we have control over it. Doesn't make so much sense
&lt;/p&gt;</p>