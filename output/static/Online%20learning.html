<p>This takes the distribution-free bounds of <a class="tc-tiddlylink tc-tiddlylink-resolves" href="#Statistical%20learning%20theory">Statistical learning theory</a> and goes one step further, by assuming that the data does not necessarily follow a distribution at all. Instead we consider it <em>arbitrary</em> so that to obtain bounds on the <a class="tc-tiddlylink tc-tiddlylink-missing" href="#Regret%20(Online%20learning)">Regret (Online learning)</a>, we need to consider the worst-case data.</p><p><a class="tc-tiddlylink-external" href="http://courses.cs.washington.edu/courses/cse599s/12sp/scribes.html" rel="noopener noreferrer" target="_blank">lecture notes</a> â€“ <a class="tc-tiddlylink-external" href="http://sbubeck.com/BubeckLectureNotes.pdf" rel="noopener noreferrer" target="_blank">intro notes</a></p><p><a class="tc-tiddlylink-external" href="http://www.cs.ox.ac.uk/people/varun.kanade/teaching/AML-HT2017/lectures/mistakebound-online.pdf" rel="noopener noreferrer" target="_blank">Other notes</a></p><p><a class="tc-tiddlylink tc-tiddlylink-resolves" href="#Prediction%20with%20expert%20advice">Prediction with expert advice</a></p><p>Can relate to <a class="tc-tiddlylink tc-tiddlylink-resolves" href="#Learning%20boosting">Learning boosting</a></p><p>he essential difference be-tween online learning and statistical learning, in addition to the sequential aspect,is the fact that no probabilistic assumption is made on the dataset.</p><p>Online learnability (worst-case regret) is stronger (it implies) <a class="tc-tiddlylink tc-tiddlylink-resolves" href="#Probably%20approximately%20correct">PAC learnability</a></p><p><u><a class="tc-tiddlylink tc-tiddlylink-missing" href="#Bandit%20problem">Bandit problem</a></u></p><p>An example of an online learning problem with <em>limited feedback</em>: instead of observing the adversary's action, we observe only the incurred loss in the case of bandits.</p><p><a class="tc-tiddlylink-external" href="http://www.jmlr.org/proceedings/papers/v35/kale14a.pdf" rel="noopener noreferrer" target="_blank">Multiarmed Bandits With Limited Expert Advice</a></p><hr><hr><p>Adversarial online learning is about being probability-free, but solution requires stochastic agent, so needs probability at the end..</p><p>Is the usefulness of adversarial/agnostic analyses that they tend to imply non-worst case learnability often..?</p><p>Adversarial analysis of the agent. we have control over it. Doesn't make so much sense
</p>