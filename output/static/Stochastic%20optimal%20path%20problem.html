<p>See sec 8.7 of <a class="tc-tiddlylink tc-tiddlylink-resolves" href="#Sutton-Barto">Sutton-Barto</a></p><p>A minimization problem which can be formulated as a <a class="tc-tiddlylink tc-tiddlylink-resolves" href="#Reinforcement%20learning">Reinforcement learning</a> problem which satisfies these conditions: </p><ul><li>The inital value of every goal state is zero</li><li>there exists at least one policy that guarantees that a goal state will be reached with probability one from any start state</li><li>all rewards for transitions from non-goal states are strictly negative </li><li>all the initial values are equal to, or greater than, their optimal values (which can be satisfied by simply setting the initial values to zero)</li></ul><p><a class="tc-tiddlylink tc-tiddlylink-resolves" href="#Real-time%20dynamic%20programming">Real-time dynamic programming</a> converges for these problems</p>