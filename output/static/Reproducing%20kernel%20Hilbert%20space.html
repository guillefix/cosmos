<p>&lt;p&gt;&lt;em&gt;aka RKHS&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=9-oxo_k69qs&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Video&lt;/a&gt; – &lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=e1ittn0B2iQ&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Video2&lt;/a&gt; – &lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=bBRX3OqNC9c&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;video3&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=9-oxo_k69qs#t=51m50s&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Definition&lt;/a&gt; A &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Hilbert%20space&quot;&gt;Hilbert space&lt;/a&gt; with a condition: &lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://en.wikipedia.org/wiki/Reproducing_kernel_Hilbert_space&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Evaluation linear functional at point x is continuous&lt;/a&gt;. &lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://youtu.be/e1ittn0B2iQ?t=47m7s&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Properties of RKHS and connections&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;small&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=9-oxo_k69qs#t=53m&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;video&lt;/a&gt; for being a reproducing kernel Hilbert space (he missplaced the x, and missed the for all f. See &lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://en.wikipedia.org/wiki/Reproducing_kernel_Hilbert_space&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;here&lt;/a&gt; for right definition. Written correctly in &lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=e1ittn0B2iQ&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;next lecture&lt;/a&gt;).&lt;/small&gt;&lt;/p&gt;&lt;h3 class=&quot;&quot;&gt;&lt;u&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Reproducing%20kernel&quot;&gt;Reproducing kernel&lt;/a&gt; perspective&lt;/u&gt;&lt;/h3&gt;&lt;p&gt;The above condition (&lt;small&gt;Evaluation linear functional at point x is continuous&lt;/small&gt;) is equivalent to having a &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Reproducing%20kernel&quot;&gt;Reproducing kernel&lt;/a&gt;. That is, the Hilbert space has a kernel (that is a function from two copies of the input space to the reals), such that &lt;/p&gt;&lt;ul&gt;&lt;li&gt;the function you get from fixing one argument of the kernel must be a member of the Hilbert space we are considering&lt;/li&gt;&lt;li&gt;the kernel is reproducing, that is Evaluation is done by inner producting with the kernel function with one argument fixed. see &lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://youtu.be/9-oxo_k69qs?t=1h14s&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Theorem&lt;/a&gt;. &lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Note: feature vectors (see below) and functions in the RKHS are in 1-to-1 correspondence (so they can be seen to be the &lt;em&gt;same&lt;/em&gt;). They can thus both be seen as the elements of the Hilbert space that is the RKHS.&lt;/p&gt;&lt;h3 class=&quot;&quot;&gt;&lt;u&gt;Positive definite kernel perspective&lt;/u&gt;&lt;/h3&gt;&lt;p&gt;An RKHS can be constructed given a kernel, defined to be just a function with two arguments from an input space, to the Reals, with some properties (positive definitiness). See &lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://youtu.be/e1ittn0B2iQ?t=1h5m59s&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;here&lt;/a&gt; and &lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://youtu.be/e1ittn0B2iQ?t=1h41s&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;here&lt;/a&gt;&lt;/p&gt;&lt;h3 class=&quot;&quot;&gt;&lt;u&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-missing&quot; href=&quot;#Feature%20map&quot;&gt;Feature map&lt;/a&gt;s perspective&lt;/u&gt;&lt;/h3&gt;&lt;p&gt;A feature map is just a map from an input set to a &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Hilbert%20space&quot;&gt;Hilbert space&lt;/a&gt;!&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://youtu.be/bBRX3OqNC9c?t=19m48s&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Video&lt;/a&gt; – &lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;http://www.gatsby.ucl.ac.uk/~gretton/coursefiles/lecture4_introToRKHS.pdf#page=3&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;notes&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Idea&lt;/strong&gt;: you map inputs to an &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Inner%20product%20space&quot;&gt;Inner product space&lt;/a&gt; feature space (vector of numbers, which could be a function..). This is the feature map. Then you can define functions on inputs by defining them to be vectors in this same space, and defining their evaluation at x to be this vector inner producted with &lt;span&gt;&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;ϕ&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;\phi(x)&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.75em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;strut bottom&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;base textstyle uncramped&quot;&gt;&lt;span class=&quot;mord mathit&quot;&gt;ϕ&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathit&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;. The kernel function just tells you the value of the feature map at a point, with the feature map at another point.&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;This means that: by just giving an feature map, we get an induced RKHS, where the functions are represented (in 1-to-1 correspondence) with linear combinations of feature vectors. The function is really defined by taking the inner product of the feature vector of x with the feature vector representing the function.&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;See here: &lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://youtu.be/bBRX3OqNC9c?t=27m29s&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;The RKHS is taken by taking linear combinations of feature functions&lt;/a&gt; – see also &lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;http://www.gatsby.ucl.ac.uk/~gretton/coursefiles/lecture4_introToRKHS.pdf#page=9&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;here&lt;/a&gt;&lt;/p&gt;&lt;p&gt;A typical kernel is the &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-missing&quot; href=&quot;#Gaussian%20kernel&quot;&gt;Gaussian kernel&lt;/a&gt;, and in that case the feature map &lt;span&gt;&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;ϕ&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;\phi(a)&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.75em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;strut bottom&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;base textstyle uncramped&quot;&gt;&lt;span class=&quot;mord mathit&quot;&gt;ϕ&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathit&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; is just a &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Gaussian&quot;&gt;Gaussian&lt;/a&gt; centered around &lt;span&gt;&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;a&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.43056em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;strut bottom&quot; style=&quot;height:0.43056em;vertical-align:0em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;base textstyle uncramped&quot;&gt;&lt;span class=&quot;mord mathit&quot;&gt;a&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;, namely the function &lt;span&gt;&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;msup&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mrow&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;−&lt;/mo&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;msup&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;Ae^{-(x-a)^2}&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.9393199999999999em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;strut bottom&quot; style=&quot;height:0.9393199999999999em;vertical-align:0em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;base textstyle uncramped&quot;&gt;&lt;span class=&quot;mord mathit&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathit&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;vlist&quot;&gt;&lt;span style=&quot;top:-0.363em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;fontsize-ensurer reset-size5 size5&quot;&gt;&lt;span style=&quot;font-size:0em;&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;reset-textstyle scriptstyle uncramped&quot;&gt;&lt;span class=&quot;mord scriptstyle uncramped&quot;&gt;&lt;span class=&quot;mord&quot;&gt;−&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathit&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;mbin&quot;&gt;−&lt;/span&gt;&lt;span class=&quot;mord mathit&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;vlist&quot;&gt;&lt;span style=&quot;top:-0.363em;margin-right:0.07142857142857144em;&quot;&gt;&lt;span class=&quot;fontsize-ensurer reset-size5 size5&quot;&gt;&lt;span style=&quot;font-size:0em;&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;reset-scriptstyle scriptscriptstyle uncramped&quot;&gt;&lt;span class=&quot;mord mathrm&quot;&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;baseline-fix&quot;&gt;&lt;span class=&quot;fontsize-ensurer reset-size5 size5&quot;&gt;&lt;span style=&quot;font-size:0em;&quot;&gt;​&lt;/span&gt;&lt;/span&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;baseline-fix&quot;&gt;&lt;span class=&quot;fontsize-ensurer reset-size5 size5&quot;&gt;&lt;span style=&quot;font-size:0em;&quot;&gt;​&lt;/span&gt;&lt;/span&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;.&lt;/p&gt;&lt;p&gt;Indeed the reproducing kernels can be seen as the inner products of a basis functions/vectors. So the basis functions can be seen as just the kernels, with one argument fixed. One can easily check that the inner product of two Gaussian functions (defined using the usual inner product for functions, which can be gotten by looking at functions as vectors..) is the Gaussian kernel, one can also check that this is a reproducing kernel.&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;Consider a weird example of the above explanation. We can map elements of R^2 to functions on R^2 which look like pyramids centered around the input point. The space of functions has a standard inner product. Then we define a new function on R^2 given by taking the inner product of the function associated with point x with the function associated with point y for any y. Then we define the inner product of two such functions to be the inner product of the original pyramids, which makes them work like evaluating functionals. Therefore, we have defined an RKHS (the space of functions over R^2 with the inner product defined as later), via an intermediate not-necessarily-RK &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Hilbert%20space&quot;&gt;HS&lt;/a&gt;.&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;u&gt;Connection with &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Regularization&quot;&gt;Regularization&lt;/a&gt;&lt;/u&gt;&lt;/p&gt;&lt;p&gt;—&amp;gt; &lt;u&gt;Nice&lt;/u&gt;. This whole class of RKHS turn out to be basically spaces where we bound a norm different from the L^2, and which basically can be interpreted as &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Regularization&quot;&gt;Regularization&lt;/a&gt;! (see &lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=e1ittn0B2iQ#t=41m30s&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;video&lt;/a&gt;). The regularization term can be, for instance the norm of the derviative!&lt;/p&gt;&lt;p&gt;Norm of a function in the space is like a measure of &amp;quot;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Complexity&quot;&gt;Complexity&lt;/a&gt;&amp;quot; of that function&lt;/p&gt;&lt;hr&gt;&lt;p&gt;Applied to &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Kernel%20method&quot;&gt;Kernel method&lt;/a&gt;s&lt;/p&gt;&lt;h3 class=&quot;&quot;&gt;&lt;u&gt;Examples&lt;/u&gt;&lt;/h3&gt;&lt;p&gt;Space of functions in &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Dictionary%20learning&quot;&gt;Dictionary learning&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Band-limited%20function&quot;&gt;Band-limited function&lt;/a&gt;s, and some relaxations of it where kernel is gaussian or exponential.. &lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=e1ittn0B2iQ#t=37m30s&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;These generalizations are just RKHS with translational invariance kernels&lt;/a&gt;, very common in signal analysis, etc. These are &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Sobolev%20space&quot;&gt;Sobolev space&lt;/a&gt;s!&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-missing&quot; href=&quot;#Spline&quot;&gt;Spline&lt;/a&gt;s are also a special case! noice&lt;/p&gt;&lt;h3 class=&quot;&quot;&gt;&lt;u&gt;Properties of &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Kernel&quot;&gt;Kernel&lt;/a&gt;s&lt;/u&gt;&lt;/h3&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;http://www.gatsby.ucl.ac.uk/~gretton/coursefiles/lecture4_introToRKHS.pdf#page=5&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Sums and products of kernels are still kernels&lt;/a&gt;&lt;/p&gt;</p>