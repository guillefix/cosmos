<p>&lt;p&gt;&lt;em&gt;aka convex programming&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Convex optimization&lt;/strong&gt; refers to an &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Optimization&quot;&gt;Optimization&lt;/a&gt; problem in which the objective and constraint functions are both &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Convex%20function&quot;&gt;convex&lt;/a&gt;. This implies that the domain of the optimization variable is a convex set. The convexity property can make optimization in some sense &amp;quot;easier&amp;quot; than the general case - for example, any local minimum must be a global minimum. It is a generalization of &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Linear%20programming&quot;&gt;Linear programming&lt;/a&gt;&lt;/p&gt;&lt;p&gt;See &lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;http://mpawankumar.info/teaching/cdt-optimization/lecture1_2.pdf&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;slides&lt;/a&gt;, and &lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://github.com/damaru2/optimization17/&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;these notes&lt;/a&gt; (in particular Part I)&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.stats.ox.ac.uk/~lienart/blog_optimization.html&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;https://www.stats.ox.ac.uk/~lienart/blog_optimization.html&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.wikiwand.com/en/Convex_optimization&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;https://www.wikiwand.com/en/Convex_optimization&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;http://web.stanford.edu/~boyd/cvxbook/bv_cvxbook.pdf&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Convex optimization&lt;/a&gt; &lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;file:///home/guillefix/Dropbox/COSMOS/Mathematics/Mathematical%20methods/bv_cvxbook.pdf&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;pdf&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Convex optimization problems include least-squares fitting (see &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Linear%20regression&quot;&gt;Linear regression&lt;/a&gt;), and &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Linear%20programming&quot;&gt;Linear programming&lt;/a&gt; problems.&lt;/p&gt;&lt;p&gt;See &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Learning%20theory&quot;&gt;Learning theory&lt;/a&gt;, &lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=s8B4A5ubw6c&amp;amp;index=7&amp;amp;list=PLA89DCFA6ADACE599#t=23m30s&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Andrew Ng video&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=s8B4A5ubw6c&amp;amp;index=7&amp;amp;list=PLA89DCFA6ADACE599#t=34m30s&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Dual problem&lt;/a&gt;, uses &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-missing&quot; href=&quot;#Max%E2%80%93min%20inequality&quot;&gt;Maxâ€“min inequality&lt;/a&gt;&lt;/p&gt;&lt;h2 class=&quot;&quot;&gt;&lt;u&gt;Solution methods&lt;/u&gt;&lt;/h2&gt;&lt;p&gt;Log-barrier methods. See page 51 &lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;http://mpawankumar.info/teaching/cdt-optimization/lecture1_2.pdf&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;here&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Projected%20gradient%20descent&quot;&gt;Projected subgradients&lt;/a&gt;, conditional gradients&lt;/p&gt;&lt;p&gt;Newton's method, quasi-Newton&lt;/p&gt;&lt;p&gt;conjugate-gradient&lt;/p&gt;&lt;p&gt;bundle algorithms&lt;/p&gt;&lt;p&gt;cutting-plane algorithz&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-missing&quot; href=&quot;#Interior-point%20method&quot;&gt;Interior-point method&lt;/a&gt;s, like in linear programming.&lt;/p&gt;&lt;h3 class=&quot;&quot;&gt;&lt;u&gt;Applications of convex optimazation to nonconvex optimization problems&lt;/u&gt;&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;http://i.imgur.com/y90QRNA.jpg&quot;&gt;&lt;/p&gt;&lt;p&gt;See more on this theory here: &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Convex%20optimization%20heuristics%20for%20linear%20inverse%20problems&quot;&gt;Convex optimization heuristics for linear inverse problems&lt;/a&gt;, &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Linear%20inverse%20problem&quot;&gt;Linear inverse problem&lt;/a&gt;&lt;/p&gt;</p>