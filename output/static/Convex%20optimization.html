<p><em>aka convex programming</em></p><p><strong>Convex optimization</strong> refers to an <a class="tc-tiddlylink tc-tiddlylink-resolves" href="#Optimization">Optimization</a> problem in which the objective and constraint functions are both <a class="tc-tiddlylink tc-tiddlylink-resolves" href="#Convex%20function">convex</a>. This implies that the domain of the optimization variable is a convex set. The convexity property can make optimization in some sense &quot;easier&quot; than the general case - for example, any local minimum must be a global minimum. It is a generalization of <a class="tc-tiddlylink tc-tiddlylink-resolves" href="#Linear%20programming">Linear programming</a></p><p>See <a class="tc-tiddlylink-external" href="http://mpawankumar.info/teaching/cdt-optimization/lecture1_2.pdf" rel="noopener noreferrer" target="_blank">slides</a>, and <a class="tc-tiddlylink-external" href="https://github.com/damaru2/optimization17/" rel="noopener noreferrer" target="_blank">these notes</a> (in particular Part I)</p><p><a class="tc-tiddlylink-external" href="https://www.stats.ox.ac.uk/~lienart/blog_optimization.html" rel="noopener noreferrer" target="_blank">https://www.stats.ox.ac.uk/~lienart/blog_optimization.html</a></p><p><a class="tc-tiddlylink-external" href="https://www.wikiwand.com/en/Convex_optimization" rel="noopener noreferrer" target="_blank">https://www.wikiwand.com/en/Convex_optimization</a></p><p><a class="tc-tiddlylink-external" href="http://web.stanford.edu/~boyd/cvxbook/bv_cvxbook.pdf" rel="noopener noreferrer" target="_blank">Convex optimization</a> <a class="tc-tiddlylink-external" href="file:///home/guillefix/Dropbox/COSMOS/Mathematics/Mathematical%20methods/bv_cvxbook.pdf" rel="noopener noreferrer" target="_blank">pdf</a></p><p>Convex optimization problems include least-squares fitting (see <a class="tc-tiddlylink tc-tiddlylink-resolves" href="#Linear%20regression">Linear regression</a>), and <a class="tc-tiddlylink tc-tiddlylink-resolves" href="#Linear%20programming">Linear programming</a> problems.</p><p>See <a class="tc-tiddlylink tc-tiddlylink-resolves" href="#Learning%20theory">Learning theory</a>, <a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=s8B4A5ubw6c&amp;index=7&amp;list=PLA89DCFA6ADACE599#t=23m30s" rel="noopener noreferrer" target="_blank">Andrew Ng video</a></p><p><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=s8B4A5ubw6c&amp;index=7&amp;list=PLA89DCFA6ADACE599#t=34m30s" rel="noopener noreferrer" target="_blank">Dual problem</a>, uses <a class="tc-tiddlylink tc-tiddlylink-missing" href="#Max%E2%80%93min%20inequality">Maxâ€“min inequality</a></p><h2 class=""><u>Solution methods</u></h2><p>Log-barrier methods. See page 51 <a class="tc-tiddlylink-external" href="http://mpawankumar.info/teaching/cdt-optimization/lecture1_2.pdf" rel="noopener noreferrer" target="_blank">here</a></p><p><a class="tc-tiddlylink tc-tiddlylink-resolves" href="#Projected%20gradient%20descent">Projected subgradients</a>, conditional gradients</p><p>Newton's method, quasi-Newton</p><p>conjugate-gradient</p><p>bundle algorithms</p><p>cutting-plane algorithz</p><p><a class="tc-tiddlylink tc-tiddlylink-missing" href="#Interior-point%20method">Interior-point method</a>s, like in linear programming.</p><h3 class=""><u>Applications of convex optimazation to nonconvex optimization problems</u></h3><p><img src="http://i.imgur.com/y90QRNA.jpg"></p><p>See more on this theory here: <a class="tc-tiddlylink tc-tiddlylink-resolves" href="#Convex%20optimization%20heuristics%20for%20linear%20inverse%20problems">Convex optimization heuristics for linear inverse problems</a>, <a class="tc-tiddlylink tc-tiddlylink-resolves" href="#Linear%20inverse%20problem">Linear inverse problem</a></p>