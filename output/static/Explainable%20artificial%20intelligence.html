<p><strong>Explainable AI</strong>  (XAI) refers to <a class="tc-tiddlylink tc-tiddlylink-resolves" href="#Artificial%20intelligence">Artificial intelligence</a> systems that are able to communicate their internal models and functioning to humans.</p><p>See also <a class="tc-tiddlylink tc-tiddlylink-resolves" href="#Integrating%20symbols%20into%20deep%20learning">Integrating symbols into deep learning</a> for some discussion and ideas.</p><p>DARPA is starting a projecg for this: <a class="tc-tiddlylink-external" href="http://www.darpa.mil/program/explainable-artificial-intelligence" rel="noopener noreferrer" target="_blank">article</a></p><p><a class="tc-tiddlylink-external" href="http://blog.shakirm.com/2017/02/cognitive-machine-learning-1-learning-to-explain/" rel="noopener noreferrer" target="_blank">Cognitive Machine Learning (1): Learning to Explain</a></p><p><img src="http://www.darpa.mil/ddm_gallery/xai-flowchart-inline-2.png"></p><h3 class=""><a class="tc-tiddlylink-external" href="https://distill.pub/2017/feature-visualization/" rel="noopener noreferrer" target="_blank">Feature visualization</a></h3><p><a class="tc-tiddlylink-external" href="https://research.googleblog.com/2017/11/interpreting-deep-neural-networks-with.html?m=1" rel="noopener noreferrer" target="_blank">Interpreting Deep Neural Networks with SVCCA</a></p><hr><p>Any sufficiently complex solution becomes incomprehensible to a fixed type of intelligence.
Any sufficiently complex problem requires a solution complex enough that is incomprehensible.</p><p>Maybe, regarding neural networks/deep learning for AI, we either:
* Decide we aren't gonna tackle the most difficult problems (not gonna happen)
* Give up on needing to understand our solutions to problems (extreme pragmatism)
* Become more intelligent to have some chance to understand the solutions, though there will always be things beyond our grasp. (neuralink/transhuman approach)</p>