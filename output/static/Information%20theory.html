<p>&lt;p&gt;&lt;strong&gt;Information theory&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/playlist?list=PLE125425EC837021F&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Information Theory&lt;/a&gt;, &lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/playlist?list=PLJfu_xpF92pvTfcJAILr5Kg1ptMvHUnft&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Information Theory (CUHK)&lt;/a&gt;&lt;/p&gt;&lt;h2 class=&quot;&quot;&gt;Entropy/Information&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Asymptotic equipartition property&lt;/strong&gt;&lt;/li&gt;&lt;li&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Information%20measures&quot;&gt;Information measures&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Data%20processing%20theorem&quot;&gt;Data processing theorem&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Fano's%20inequality&quot;&gt;Fano's inequality&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2 class=&quot;&quot;&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Coding%20theory&quot;&gt;Coding theory&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;A code is a representation of information/data. &lt;/p&gt;&lt;p&gt;Coding theory (and/or coding methods) is the study of the properties of codes and their fitness for a specific application. These applications include &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Data%20transmission&quot;&gt;Data transmission&lt;/a&gt;, &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Data%20compression&quot;&gt;Data compression&lt;/a&gt;, &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Cryptography&quot;&gt;Cryptography&lt;/a&gt;, and &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-missing&quot; href=&quot;#Network%20information%20theory&quot;&gt;Network information theory&lt;/a&gt;&lt;/p&gt;&lt;h2 class=&quot;&quot;&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Data%20transmission&quot;&gt;Data transmission&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;See &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Source-channel%20separation%20theorem&quot;&gt;Source-channel separation theorem&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The main problem of study in data transmission theory is: for a particular &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Communication%20channel&quot;&gt;Communication channel&lt;/a&gt;, find code so that data transmission rate is as high as possible, while receiver receives the information with negligible probability of error.&lt;/p&gt;&lt;p&gt;The limit in data transmission rate turns out to be the &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Channel%20capacity&quot;&gt;Channel capacity&lt;/a&gt;, as established by the &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Channel%20coding%20theorem&quot;&gt;Channel coding theorem&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;Data transmission is part of the broader area of study called &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Communication%20theory&quot;&gt;Communication theory&lt;/a&gt;, which includes consideration of the information source and destination.&lt;/p&gt;&lt;h2 class=&quot;&quot;&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Data%20compression&quot;&gt;Data compression&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Study of theoretical limits and implementation of codes that make average length of the value of a random variable as short as possible, whether in a lossless, or lossy way.&lt;/p&gt;&lt;p&gt;The limit in the average length of codewords in a lossless code turns out to be the entropy, as established  by the &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Source%20coding%20theorem&quot;&gt;Source coding theorem&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Limits in lossy codes are established in &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-missing&quot; href=&quot;#Rate%20compression%20theory&quot;&gt;Rate compression theory&lt;/a&gt;&lt;/p&gt;&lt;h2 class=&quot;&quot;&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Cryptography&quot;&gt;Cryptography&lt;/a&gt;&lt;/h2&gt;&lt;h2 class=&quot;&quot;&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-missing&quot; href=&quot;#Network%20information%20theory&quot;&gt;Network information theory&lt;/a&gt;&lt;/h2&gt;&lt;h2 class=&quot;&quot;&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Algorithmic%20information%20theory&quot;&gt;Algorithmic information theory&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Kolmogorov%20complexity&quot;&gt;Kolmogorov complexity&lt;/a&gt;&lt;/strong&gt;. Shortest program that will produced desired output in Turing machine. Occam's razor&lt;/p&gt;&lt;hr&gt;&lt;h3 class=&quot;&quot;&gt;More related areas&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Ergodic theory&lt;/strong&gt;. A dynamical system is ergodic if it has a unique probabliy distribution in the long time limit, I think Asymptotic equipartition theorem gives probability of each typical sequence.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Hypothesis testing&lt;/strong&gt; (See &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Statistics&quot;&gt;Statistics&lt;/a&gt;).&lt;/li&gt;&lt;li&gt;&lt;strong&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Statistical%20physics&quot;&gt;Statistical mechanics&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Quantum%20information%20theory&quot;&gt;Quantum information theory&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Inference&lt;/strong&gt;. Kolmogorov complexity is often applied to extrapolate from data. See also Solomonoff's algorithmic probability, and &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Machine%20learning&quot;&gt;Machine learning&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Signal%20processing&quot;&gt;Signal processing&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Gambling and investment&lt;/strong&gt;. Theory of investment in stock markets. See &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Game%20theory&quot;&gt;Game theory&lt;/a&gt;.&lt;ul&gt;&lt;li&gt;Doubling rate. Has parallels with entropy&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Probability%20theory&quot;&gt;Probability theory&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;&lt;li&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Sequence%20space&quot;&gt;Sequence space&lt;/a&gt;s and &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Symbolic%20dynamics&quot;&gt;Symbolic dynamics&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Complexity%20theory&quot;&gt;Complexity theory&lt;/a&gt;&lt;ul&gt;&lt;li&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Descriptional%20complexity&quot;&gt;Descriptional complexity&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;&lt;hr&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;http://worrydream.com/refs/Shannon - A Mathematical Theory of Communication.pdf&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Shannon - A Mathematical Theory of Communication&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;http://www.sciencedirect.com/science/article/pii/S0166218X07002326&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;General theory of information transfer: Updated&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Entropy%20reduction&quot;&gt;Entropy reduction&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://books.google.co.uk/books?hl=en&amp;amp;lr=&amp;amp;id=EZ6KAwAAQBAJ&amp;amp;oi=fnd&amp;amp;pg=PP5&amp;amp;ots=bqpF4UZhji&amp;amp;sig=fmxtdgsKYFUjKFcYDe9bxdoagFM#v=onepage&amp;amp;q&amp;amp;f=false&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Storing and Transmitting Data: Rudolf Ahlswedeâ€™s Lectures on Information ...&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;http://download.springer.com/static/pdf/860/bok%253A978-3-642-36899-8.pdf?originUrl=http%3A%2F%2Flink.springer.com%2Fbook%2F10.1007%2F978-3-642-36899-8&amp;amp;token2=exp=1467511400~acl=%2Fstatic%2Fpdf%2F860%2Fbok%25253A978-3-642-36899-8.pdf%3ForiginUrl%3Dhttp%253A%252F%252Flink.springer.com%252Fbook%252F10.1007%252F978-3-642-36899-8*~hmac=07f9d2ad15fce4ba4ad13e57c22b7ffbbbabc694ce1928057668a650bdd9c175&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Information Theory, Combinatorics, and Search Theory&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-missing&quot; href=&quot;#Theory%20of%20identification&quot;&gt;Theory of identification&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-missing&quot; href=&quot;#Theory%20of%20ordering&quot;&gt;Theory of ordering&lt;/a&gt; (see &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Entropy%20reduction&quot;&gt;Entropy reduction&lt;/a&gt;)&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-missing&quot; href=&quot;#Search%20theory&quot;&gt;Search theory&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/user/cse6222yorku/videos?view=0&amp;amp;shelf_id=4&amp;amp;sort=dd&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;YB videos&lt;/a&gt;
â€“ &lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-050j-information-and-entropy-spring-2008/videos-homework-and-readings/&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;MIT videos&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;http://ieeexplore.ieee.org/abstract/document/612919/&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Back from infinity: a constrained resources approach to information theory&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/user/cse6222yorku/playlists&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Video lectures&lt;/a&gt;&lt;/p&gt;</p>