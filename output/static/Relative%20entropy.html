<p><em>aka Kullback–Leibler divergence, KL divergence</em></p><p><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=fc5FyE41zeo#t=3m15s" rel="noopener noreferrer" target="_blank">video</a></p><p><a class="tc-tiddlylink tc-tiddlylink-resolves" href="#Mutual%20information">Mutual information</a> is a special case. Defines a measure of &quot;distance&quot; between probabiliy distributions. Applications in estimating hypothesis testing errors and in large deviation theory.</p><p><span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>D</mi><mrow><mrow><mi mathvariant="normal">K</mi><mi mathvariant="normal">L</mi></mrow></mrow></msub><mo>(</mo><mi>P</mi><mi mathvariant="normal">∥</mi><mi>Q</mi><mo>)</mo><mo>=</mo><msub><mo>∑</mo><mi>i</mi></msub><mi>P</mi><mo>(</mo><mi>i</mi><mo>)</mo><mspace width="0.16667em"></mspace><mi>log</mi><mfrac><mrow><mi>P</mi><mo>(</mo><mi>i</mi><mo>)</mo></mrow><mrow><mi>Q</mi><mo>(</mo><mi>i</mi><mo>)</mo></mrow></mfrac><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">D_{\mathrm{KL}}(P\|Q) = \sum_i P(i) \, \log\frac{P(i)}{Q(i)}.</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:1.01em;"></span><span class="strut bottom" style="height:1.53em;vertical-align:-0.52em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit" style="margin-right:0.02778em;">D</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.02778em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathrm">K</span><span class="mord mathrm">L</span></span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mopen">(</span><span class="mord mathit" style="margin-right:0.13889em;">P</span><span class="mord mathrm">∥</span><span class="mord mathit">Q</span><span class="mclose">)</span><span class="mrel">=</span><span class="mop"><span class="op-symbol small-op mop" style="top:-0.0000050000000000050004em;">∑</span><span class="vlist"><span style="top:0.30001em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathit">i</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mord mathit" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathit">i</span><span class="mclose">)</span><span class="mord mspace thinspace"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mord reset-textstyle textstyle uncramped"><span class="sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"></span><span class="mfrac"><span class="vlist"><span style="top:0.34500000000000003em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathit">Q</span><span class="mopen">(</span><span class="mord mathit">i</span><span class="mclose">)</span></span></span></span><span style="top:-0.22999999999999998em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle textstyle uncramped frac-line"></span></span><span style="top:-0.485em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord scriptstyle uncramped"><span class="mord mathit" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathit">i</span><span class="mclose">)</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"></span></span><span class="mord mathrm">.</span></span></span></span></span></p><p><a class="tc-tiddlylink-external" href="https://www.wikiwand.com/en/Kullback%E2%80%93Leibler_divergence" rel="noopener noreferrer" target="_blank">https://www.wikiwand.com/en/Kullback%E2%80%93Leibler_divergence</a></p><p><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=QPkb5VcgXAM#t=20m55" rel="noopener noreferrer" target="_blank">https://www.youtube.com/watch?v=QPkb5VcgXAM#t=20m55</a></p><p>the Kullback–Leibler divergence is not a true metric. It does not obey the triangle inequality, and in general DKL(P‖Q) does not equal DKL(Q‖P). However, its infinitesimal form, specifically its Hessian, gives a metric tensor known as the <a class="tc-tiddlylink tc-tiddlylink-resolves" href="#Fisher%20information%20matrix">Fisher information metric</a>.</p>