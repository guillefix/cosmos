<p><code>&lt;!doctype html&gt;
&lt;html&gt;
&lt;head&gt;
&lt;meta http-equiv=&quot;Content-Type&quot; content=&quot;text/html;charset=utf-8&quot; /&gt;
&lt;meta name=&quot;generator&quot; content=&quot;TiddlyWiki&quot; /&gt;
&lt;meta name=&quot;tiddlywiki-version&quot; content=&quot;</code>5.1.17<code>&quot; /&gt;
&lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot; /&gt;
&lt;meta name=&quot;apple-mobile-web-app-capable&quot; content=&quot;yes&quot; /&gt;
&lt;meta name=&quot;apple-mobile-web-app-status-bar-style&quot; content=&quot;black-translucent&quot; /&gt;
&lt;meta name=&quot;mobile-web-app-capable&quot; content=&quot;yes&quot;/&gt;
&lt;meta name=&quot;format-detection&quot; content=&quot;telephone=no&quot;&gt;
&lt;link id=&quot;faviconLink&quot; rel=&quot;shortcut icon&quot; href=&quot;favicon.ico&quot;&gt;
&lt;link rel=&quot;stylesheet&quot; href=&quot;static.css&quot;&gt;
&lt;title&gt;</code>Policy search: Cosmos — Everything there was, there is, <span class="subtitle-dark">and there will be</span><code>&lt;/title&gt;
&lt;/head&gt;
&lt;body class=&quot;tc-body&quot;&gt;
</code><code>
&lt;section class=&quot;tc-story-river&quot;&gt;
</code>
&lt;p&gt;&lt;div class=&quot;tc-tiddler-frame tc-tiddler-view-frame tc-tiddler-exists   tc-tagged-Reinforcement%20learning &quot; data-tags=&quot;[[Reinforcement learning]]&quot; data-tiddler-title=&quot;Policy search&quot;&gt;&lt;div class=&quot;tc-tiddler-title&quot;&gt;
&lt;div class=&quot;tc-titlebar&quot;&gt;
&lt;span class=&quot;tc-tiddler-controls&quot;&gt;
&lt;span class=&quot; tc-reveal&quot;&gt;&lt;button aria-label=&quot;more&quot; class=&quot;tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fmore-tiddler-actions&quot; title=&quot;More actions&quot;&gt;&lt;/button&gt;&lt;div class=&quot; tc-reveal&quot; hidden=&quot;true&quot;&gt;&lt;/div&gt;&lt;/span&gt;&lt;span class=&quot; tc-reveal&quot; hidden=&quot;true&quot;&gt;&lt;/span&gt;&lt;span class=&quot; tc-reveal&quot; hidden=&quot;true&quot;&gt;&lt;/span&gt;&lt;span class=&quot; tc-reveal&quot; hidden=&quot;true&quot;&gt;&lt;/span&gt;&lt;span class=&quot; tc-reveal&quot; hidden=&quot;true&quot;&gt;&lt;/span&gt;&lt;span class=&quot; tc-reveal&quot; hidden=&quot;true&quot;&gt;&lt;/span&gt;&lt;span class=&quot; tc-reveal&quot;&gt;&lt;button aria-label=&quot;edit&quot; class=&quot;tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fedit&quot; title=&quot;Edit this tiddler&quot;&gt;&lt;/button&gt;&lt;/span&gt;&lt;span class=&quot; tc-reveal&quot; hidden=&quot;true&quot;&gt;&lt;/span&gt;&lt;span class=&quot; tc-reveal&quot; hidden=&quot;true&quot;&gt;&lt;/span&gt;&lt;span class=&quot; tc-reveal&quot; hidden=&quot;true&quot;&gt;&lt;/span&gt;&lt;span class=&quot; tc-reveal&quot; hidden=&quot;true&quot;&gt;&lt;/span&gt;&lt;span class=&quot; tc-reveal&quot; hidden=&quot;true&quot;&gt;&lt;/span&gt;&lt;span class=&quot; tc-reveal&quot;&gt;&lt;button aria-label=&quot;close&quot; class=&quot;tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fclose&quot; title=&quot;Close this tiddler&quot;&gt;&lt;/button&gt;&lt;/span&gt;&lt;span class=&quot; tc-reveal&quot; hidden=&quot;true&quot;&gt;&lt;/span&gt;&lt;span class=&quot; tc-reveal&quot; hidden=&quot;true&quot;&gt;&lt;/span&gt;&lt;span class=&quot; tc-reveal&quot; hidden=&quot;true&quot;&gt;&lt;/span&gt;&lt;span class=&quot; tc-reveal&quot;&gt;&lt;button aria-label=&quot;tiddlymap&quot; class=&quot;tc-btn-invisible tc-btn-%24%3A%2Fplugins%2Ffelixhayashi%2Ftiddlymap%2Fmisc%2FquickConnectButton &quot; title=&quot;Toggle TiddlyMap actions&quot;&gt;


&lt;/button&gt;&lt;/span&gt;
&lt;/span&gt;

&lt;span&gt;

&lt;span class=&quot;tc-tiddler-title-icon&quot; style=&quot;fill:;&quot;&gt;

&lt;/span&gt;



&lt;h2 class=&quot;tc-title&quot;&gt;
Policy search
&lt;/h2&gt;

&lt;/span&gt;

&lt;/div&gt;

&lt;div class=&quot;tc-tiddler-info tc-popup-handle tc-reveal&quot; hidden=&quot;true&quot;&gt;&lt;/div&gt;
&lt;/div&gt;&lt;div class=&quot; tc-reveal&quot; hidden=&quot;true&quot;&gt;&lt;/div&gt;
&lt;div class=&quot; tc-reveal&quot;&gt;
&lt;div class=&quot;tc-subtitle&quot;&gt;
&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-missing&quot; href=&quot;cosmos.html&quot;&gt;
cosmos
&lt;/a&gt; 4th November 2016 at 9:43am
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot; tc-reveal&quot;&gt;
&lt;div class=&quot;tc-tags-wrapper&quot;&gt;&lt;span class=&quot;tc-tag-list-item&quot;&gt;


&lt;span class=&quot;tc-tag-label tc-btn-invisible&quot; draggable=&quot;true&quot; style=&quot;background-color:;
fill:#333333;
color:#333333;&quot;&gt;
 Reinforcement learning
&lt;/span&gt;

&lt;span class=&quot;tc-drop-down tc-reveal&quot; hidden=&quot;true&quot;&gt;&lt;/span&gt;

&lt;/span&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;tc-tiddler-body tc-reveal&quot;&gt;&lt;p&gt;A class of &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;Reinforcement%2520learning.html&quot;&gt;Reinforcement learning&lt;/a&gt; algorithms. &lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=yCqPMD6coO8&amp;amp;index=20&amp;amp;list=PLA89DCFA6ADACE599#t=9m&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;These are also known as direct search algorithms&lt;/a&gt;, in contrast with algorithms where our aim is to find the optimal value function &lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=yCqPMD6coO8&amp;amp;index=20&amp;amp;list=PLA89DCFA6ADACE599#t=6m25s&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;intro vid&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=yCqPMD6coO8&amp;amp;index=20&amp;amp;list=PLA89DCFA6ADACE599#t=7m35s&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;General aim&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Stochastic policy&lt;/strong&gt; – &lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=yCqPMD6coO8&amp;amp;index=20&amp;amp;list=PLA89DCFA6ADACE599#t=11m23s&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Definition&lt;/a&gt;&lt;/p&gt;&lt;h3 class=&quot;&quot;&gt;&lt;u&gt;Algorithm&lt;/u&gt;&lt;/h3&gt;&lt;p&gt;Sometimes called the &lt;strong&gt;reinforce algorithm&lt;/strong&gt;, and is a form of &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;Stochastic%2520gradient%2520descent.html&quot;&gt;Stochastic gradient descent&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=yCqPMD6coO8&amp;amp;index=20&amp;amp;list=PLA89DCFA6ADACE599#t=23m&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Goal&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=yCqPMD6coO8&amp;amp;index=20&amp;amp;list=PLA89DCFA6ADACE599#t=27m&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Algorithm&lt;/a&gt; – &lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=yCqPMD6coO8&amp;amp;index=20&amp;amp;list=PLA89DCFA6ADACE599#t=28m45s&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;explanation&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=yCqPMD6coO8&amp;amp;index=20&amp;amp;list=PLA89DCFA6ADACE599#t=33m&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Derivation&lt;/a&gt;, using the &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-missing&quot; href=&quot;Product%2520rule.html&quot;&gt;Product rule&lt;/a&gt;&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=yCqPMD6coO8&amp;amp;index=20&amp;amp;list=PLA89DCFA6ADACE599#t=36m05s&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Differentiation&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=yCqPMD6coO8&amp;amp;index=20&amp;amp;list=PLA89DCFA6ADACE599#t=38m&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Factor out joint probability from terms in sum&lt;/a&gt; &lt;/li&gt;&lt;li&gt;Rewrite as expectation –&amp;gt; &lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=yCqPMD6coO8&amp;amp;index=20&amp;amp;list=PLA89DCFA6ADACE599#t=40m05s&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;On expectation, reinforce algorithm updates parameters in the direction of the gradient of the expected payout&lt;/a&gt;. This shows the algorithm is an &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;Stochastic%2520gradient%2520descent.html&quot;&gt;Stochastic gradient descent&lt;/a&gt; algorithm!&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;With direct policy search, &lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=kUiR0RLmGCo&amp;amp;index=15&amp;amp;list=PLjK8ddCbDMphIMSXn-w1IjyYpHU3DaUYw#t=40m50s&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;rewards may be combined in other ways other than by summing them&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=kUiR0RLmGCo&amp;amp;index=15&amp;amp;list=PLjK8ddCbDMphIMSXn-w1IjyYpHU3DaUYw#t=42m43s&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Derivation by Nando&lt;/a&gt; – &lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=kUiR0RLmGCo&amp;amp;index=15&amp;amp;list=PLjK8ddCbDMphIMSXn-w1IjyYpHU3DaUYw#t=46m50&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;comment on reward function not being really needed&lt;/a&gt; –&amp;gt; &lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=kUiR0RLmGCo&amp;amp;index=15&amp;amp;list=PLjK8ddCbDMphIMSXn-w1IjyYpHU3DaUYw#t=49m05s&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;result&lt;/a&gt;&lt;/p&gt;&lt;p&gt;What we use for the gradient descent is do a &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;Monte%2520Carlo.html&quot;&gt;Monte Carlo&lt;/a&gt; estimate, which makes it stochastic.&lt;/p&gt;&lt;h2 class=&quot;&quot;&gt;&lt;u&gt;Pegasus&lt;/u&gt;&lt;/h2&gt;&lt;p&gt;-—&amp;gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=yCqPMD6coO8&amp;amp;index=20&amp;amp;list=PLA89DCFA6ADACE599#t=48m&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;vid&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=kUiR0RLmGCo&amp;amp;index=15&amp;amp;list=PLjK8ddCbDMphIMSXn-w1IjyYpHU3DaUYw#t=52m&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Nando's vid&lt;/a&gt;&lt;/p&gt;&lt;h2 class=&quot;&quot;&gt;&lt;u&gt;Policy gradient methods&lt;/u&gt;&lt;/h2&gt;&lt;h3 class=&quot;&quot;&gt;&lt;u&gt;Deterministic Policy Gradient Algorithms&lt;/u&gt;&lt;/h3&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;http://jmlr.org/proceedings/papers/v32/silver14.pdf&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;paper&lt;/a&gt;&lt;/p&gt;&lt;h3 class=&quot;&quot;&gt;&lt;u&gt;Natural policy gradient&lt;/u&gt;&lt;/h3&gt;&lt;h2 class=&quot;&quot;&gt;&lt;u&gt;Other variations&lt;/u&gt;&lt;/h2&gt;&lt;p&gt;Can approach it as an &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;Inference.html&quot;&gt;Inference&lt;/a&gt; problem, or in other ways. See &lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=dV80NAlEins&amp;amp;list=PLjK8ddCbDMphIMSXn-w1IjyYpHU3DaUYw&amp;amp;index=16#t=1m47&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;comment&lt;/a&gt;&lt;/p&gt;&lt;h3 class=&quot;&quot;&gt;&lt;u&gt;pair-wise policy comparisons&lt;/u&gt;&lt;/h3&gt;&lt;h3 class=&quot;&quot;&gt;&lt;u&gt;probabilistic policy search approaches&lt;/u&gt;&lt;/h3&gt;&lt;p&gt;&lt;u&gt;based on EM &lt;/u&gt;&lt;/p&gt;&lt;p&gt;&lt;u&gt;based on probabilistic modeling &lt;/u&gt;&lt;/p&gt;&lt;h3 class=&quot;&quot;&gt;&lt;u&gt; Relative Entropy Policy Search &lt;/u&gt;&lt;/h3&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://is.tuebingen.mpg.de/fileadmin/user_upload/files/publications/2012/AISTATS-2012-Daniel.pdf&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Hierarchical Relative Entropy Policy Search&lt;/a&gt; – &lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;http://jmlr.org/papers/volume17/15-188/15-188.pdf&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;extended version&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;


&lt;/div&gt;

&lt;/p&gt;
<code>
&lt;/section&gt;
&lt;/body&gt;
&lt;/html&gt;
</code></p>