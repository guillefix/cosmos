<p>&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://blog.openai.com/adversarial-example-research/&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Attacking Machine Learning with Adversarial Examples&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://arxiv.org/abs/1610.04563&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Are Accuracy and Robustness Correlated?&lt;/a&gt; We find that adversarial examples are mostly transferable across similar network topologies, and we demonstrate that better machine learning models are less vulnerable to adversarial examples.&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;file:///home/guillefix/downloads/Deep%20learning.pdf&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;EXPLAINING AND HARNESSING ADVERSARIAL EXAMPLES&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=M2IebCN9Ht4&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Deep Neural Networks are Easily Fooled&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Numerical accuracy may help against adversarial attacks: &lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://arxiv.org/abs/1704.01547&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/1704.01547&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=hDlHpBBGaKs&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;https://www.youtube.com/watch?v=hDlHpBBGaKs&lt;/a&gt;&lt;/p&gt;</p>