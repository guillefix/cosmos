<p>&lt;p&gt;An type of &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Reinforcement%20learning%20in%20continuous%20state%20space&quot;&gt;Reinforcement learning in continuous state space&lt;/a&gt;&lt;/p&gt;&lt;p&gt;–&amp;gt;using &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Dynamic%20programming&quot;&gt;Dynamic programming&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=-ff6l5D8-j8&amp;amp;index=18&amp;amp;list=PLA89DCFA6ADACE599#t=27m50s&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;intro&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=-ff6l5D8-j8&amp;amp;index=18&amp;amp;list=PLA89DCFA6ADACE599#t=30m&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;State transition probabilites&lt;/a&gt;. These matrices can be obtained by &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Linear%20regression&quot;&gt;Linear regression&lt;/a&gt; from samples of the real or simulated dynamics of the system; or they can be a linearization of a non-linear transition function, derived from physics, or other assumptions. This constitutes the linear model neede for LQR&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=-ff6l5D8-j8&amp;amp;index=18&amp;amp;list=PLA89DCFA6ADACE599#t=33m10s&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Reward function&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Goal: &lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=-ff6l5D8-j8&amp;amp;index=18&amp;amp;list=PLA89DCFA6ADACE599#t=53m20s&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Finding optimal policy&lt;/a&gt;, modelling world as a finite-horizon &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Markov%20decision%20process&quot;&gt;MDP&lt;/a&gt;, which can be solved recursively, using &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Dynamic%20programming&quot;&gt;Dynamic programming&lt;/a&gt;. It turns out that the optimal action is a linear function of the current state, in this case.&lt;/p&gt;&lt;p&gt;The recursive equation for calculating the optimal value function at time &lt;span&gt;&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;t&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.61508em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;strut bottom&quot; style=&quot;height:0.61508em;vertical-align:0em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;base textstyle uncramped&quot;&gt;&lt;span class=&quot;mord mathit&quot;&gt;t&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;, given its value at time &lt;span&gt;&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;t+1&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.64444em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;strut bottom&quot; style=&quot;height:0.72777em;vertical-align:-0.08333em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;base textstyle uncramped&quot;&gt;&lt;span class=&quot;mord mathit&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;mbin&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mord mathrm&quot;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; is known as the discrete-time &lt;strong&gt;Riccati equation&lt;/strong&gt;.&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=-ff6l5D8-j8&amp;amp;index=18&amp;amp;list=PLA89DCFA6ADACE599#t=1h12m05s&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;algorithm&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=-ff6l5D8-j8&amp;amp;index=18&amp;amp;list=PLA89DCFA6ADACE599#t=1h15m20s&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Advantage over discretization methods&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=UFH5ibWnA7g&amp;amp;index=19&amp;amp;list=PLA89DCFA6ADACE599#t=18m50&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;recap&lt;/a&gt; –&amp;gt; &lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=UFH5ibWnA7g&amp;amp;index=19&amp;amp;list=PLA89DCFA6ADACE599#t=31m30s&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;some comments&lt;/a&gt;, don't need covariance.&lt;/p&gt;&lt;p&gt;&lt;u&gt;Differential dynamic programming (DDP)&lt;/u&gt;&lt;/p&gt;&lt;p&gt;Turns out to be a form of local search algorithm&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=UFH5ibWnA7g&amp;amp;index=19&amp;amp;list=PLA89DCFA6ADACE599#t=35m&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;video&lt;/a&gt;&lt;/p&gt;</p>