<p>&lt;p&gt;Comparison of &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Generative%20supervised%20learning&quot;&gt;Generative supervised learning&lt;/a&gt; and &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Discriminative%20learning&quot;&gt;Discriminative learning&lt;/a&gt;&lt;/p&gt;&lt;p&gt;If you have enough data, and you only care about &lt;span&gt;&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;∣&lt;/mi&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;p(y|x)&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.75em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;strut bottom&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;base textstyle uncramped&quot;&gt;&lt;span class=&quot;mord mathit&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathit&quot; style=&quot;margin-right:0.03588em;&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;mord mathrm&quot;&gt;∣&lt;/span&gt;&lt;span class=&quot;mord mathit&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; (prediction), &lt;strong&gt;discriminative models&lt;/strong&gt; tend to be best, because you are modelling what you care directly, and not constraining other aspects of the system.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Generative models&lt;/strong&gt; model more about the system producing the data. This means one is often constraining more (by focusing on a particular family of models for more aspects of the system), so that the model is less flexible, but if the assumptions are OK, the model can work well with much less data. Also, one may want to model these extra aspects of the system because one is interested in more than just prediction, but also generation of samples, for instance.&lt;/p&gt;&lt;p&gt;See &lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=qRJ3GKMOFrE&amp;amp;index=5&amp;amp;list=PLA89DCFA6ADACE599#t=38m&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;here&lt;/a&gt; (Andrew Ng lec), and &lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=bPGr5kFQbaw#t=5m20s&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;here&lt;/a&gt; from graphical model lectures. Use discriminative when you don't care about input data distribution, for instance.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;I'd be interested, however, on knowing under what circumstances the two approaches give the same result or differ. For instance, if you make an equivalent set of assumptions, they should give the same result, as you are then maximizing the same quantity (&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Likelihood%20function&quot;&gt;likelihood&lt;/a&gt;), &lt;mark&gt;right?&lt;/mark&gt; So the only difference is in the set of assumptions, i.e. the family of models describing your system, that you consider, and parametrize.&lt;/p&gt;&lt;p&gt;See &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Learning%20theory&quot;&gt;Learning theory&lt;/a&gt;.&lt;/p&gt;</p>