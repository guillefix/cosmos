<p>&lt;p&gt;&lt;small&gt;Aka artificial neural network..&lt;/small&gt;&lt;/p&gt;&lt;p&gt;A particularly useful way of representing nonlinear functions, for problems in &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Machine%20learning&quot;&gt;Machine learning&lt;/a&gt;. It is a very good model for many problems, and learning algorithms produce very good results with them. In particular &lt;u&gt;deep learning&lt;/u&gt; (which uses ANNs with many layers). It is a nonlinear &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-missing&quot; href=&quot;#Classifier&quot;&gt;classifier&lt;/a&gt;, and &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Regression%20analysis&quot;&gt;Regression analysis&lt;/a&gt; model.&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=aircAruvnKk&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;But what *is* a Neural Network? -- Deep learning, Part 1&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=apPiZd-qnZ8&amp;amp;list=PL6Xpj9I5qXYEcOhn7TqghAJ6NAPrNmUBH&amp;amp;index=4&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Hugo Larochelle class videos&lt;/a&gt; (&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;http://info.usherbrooke.ca/hlarochelle/neural_networks/content.html&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;website&lt;/a&gt;). &lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=qyyJKd-zXRE&amp;amp;index=6&amp;amp;list=PLA89DCFA6ADACE599#t=26m&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Andrew Ng intro&lt;/a&gt;. &lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=qyyJKd-zXRE&amp;amp;index=6&amp;amp;list=PLA89DCFA6ADACE599#t=29m&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;NN&lt;/a&gt;. Learning parameters in a NN is generally a &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Convex%20optimization&quot;&gt;non-convex optimization problem&lt;/a&gt;, which makes it very hard to reach global optima. â€“ &lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://archive.org/details/NeuralNetworks_201810/page/n11&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;book&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=3JQ3hYko51Y&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;nice visualization&lt;/a&gt;&lt;/p&gt;&lt;h2 class=&quot;&quot;&gt;&lt;u&gt;Definition&lt;/u&gt;&lt;/h2&gt;&lt;p&gt;Neuron has:&lt;/p&gt;&lt;p&gt;1) &lt;strong&gt;inputs&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;2) &lt;strong&gt;weight vectors&lt;/strong&gt;, that multiplies the input vector or activation vector of hidden layers.&lt;/p&gt;&lt;p&gt;3) &lt;strong&gt;bias&lt;/strong&gt;, that is added to result&lt;/p&gt;&lt;p&gt;4) &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Activation%20function&quot;&gt;Activation function&lt;/a&gt; takes as argument the result of the above (called pre-activation or input activation)&lt;/p&gt;&lt;p&gt;5) The result (called &lt;strong&gt;activation&lt;/strong&gt;) may be the input of other neurons in the next &lt;strong&gt;layer&lt;/strong&gt;, in a &lt;strong&gt;multilayer feedforward neural network&lt;/strong&gt;.&lt;/p&gt;&lt;p&gt;6) The activation of the last layer, is the &lt;strong&gt;output&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Overall... we are multiplying by matrices and applying simple nonlinear function&lt;/p&gt;&lt;h3 class=&quot;&quot;&gt;See &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Neural%20network%20theory&quot;&gt;Neural network theory&lt;/a&gt;, &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Mathematical%20modelling%20of%20neural%20networks&quot;&gt;Mathematical modelling of neural networks&lt;/a&gt;, for more on the theory&lt;/h3&gt;&lt;h2 class=&quot;&quot;&gt;&lt;u&gt;Learning by &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Optimization&quot;&gt;optimization&lt;/a&gt;&lt;/u&gt;&lt;/h2&gt;&lt;p&gt;Learning by minimizing cost function (see &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Learning%20theory&quot;&gt;Learning theory&lt;/a&gt;)&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=Bver7Ttgb9M&amp;amp;list=PL6Xpj9I5qXYEcOhn7TqghAJ6NAPrNmUBH&amp;amp;index=17&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Training neural networks - optimization&lt;/a&gt;. There are several global optima, and plateaus. Uses &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Gradient%20descent&quot;&gt;Gradient descent&lt;/a&gt;, in particular &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Stochastic%20gradient%20descent&quot;&gt;SGD&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;An efficient algorithm to compute the gradients of the loss function for (SGD) w.r.t. the ANN's parameters is &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Backpropagation&quot;&gt;Backpropagation&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;see more at &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Learning%20theory&quot;&gt;Learning theory&lt;/a&gt;&lt;/p&gt;&lt;h3 class=&quot;&quot;&gt;&lt;u&gt;Parameter initialization for NNs&lt;/u&gt;&lt;/h3&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=sLfogkzFNfc&amp;amp;list=PL6Xpj9I5qXYEcOhn7TqghAJ6NAPrNmUBH&amp;amp;index=15&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Neural networks [2.9] : Training neural networks - parameter initialization&lt;/a&gt;&lt;/p&gt;&lt;h3 class=&quot;&quot;&gt;&lt;u&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Model%20selection&quot;&gt;Model selection&lt;/a&gt; for neural networks&lt;/u&gt;&lt;/h3&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=Fs-raHUnF2M&amp;amp;list=PL6Xpj9I5qXYEcOhn7TqghAJ6NAPrNmUBH&amp;amp;index=16&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Neural networks [2.10] : Training neural networks - model selection&lt;/a&gt;. How to set the hyperparameters. Can use &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Cross-validation&quot;&gt;Cross-validation&lt;/a&gt;.&lt;/p&gt;&lt;h2 class=&quot;&quot;&gt;&lt;u&gt;Types of neural networks&lt;/u&gt;&lt;/h2&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;http://www.asimovinstitute.org/neural-network-zoo/&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;NN Zoo&lt;/a&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Feedforward%20neural%20network&quot;&gt;Feedforward neural network&lt;/a&gt; (basic)&lt;/li&gt;&lt;li&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Convolutional%20neural%20network&quot;&gt;Convolutional neural network&lt;/a&gt;. Good for image recognition for e.g.&lt;/li&gt;&lt;li&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Recurrent%20neural%20network&quot;&gt;Recurrent&lt;/a&gt;. Good for sequences in time&lt;/li&gt;&lt;li&gt;Long-Short term memory NN.&lt;/li&gt;&lt;li&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Spiking%20neural%20network&quot;&gt;Spiking neural network&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Residual%20neural%20network&quot;&gt;Residual neural network&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Boltzmann%20machine&quot;&gt;Boltzmann machine&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Autoencoder&quot;&gt;Autoencoder&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Deep%20belief%20network&quot;&gt;Deep belief network&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Generative%20adversarial%20network&quot;&gt;Generative adversarial network&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Hopfield%20network&quot;&gt;Hopfield network&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Binarized%20neural%20network&quot;&gt;Binarized neural network&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;http://www.ntu.edu.sg/home/egbhuang/&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Extreme learning machine&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Many models in &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Machine%20learning&quot;&gt;Machine learning&lt;/a&gt; can be seen as neural networks&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;http://www.asimovinstitute.org/wp-content/uploads/2016/09/neuralnetworks.png&quot;&gt;&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=qyyJKd-zXRE&amp;amp;list=PLA89DCFA6ADACE599&amp;amp;index=6#t=41m23s&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Early video that created about TTS&lt;/a&gt; using ANNs (NetTalk), see &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Speech%20synthesis&quot;&gt;Speech synthesis&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;http://fossbytes.com/a-neural-network-in-11-lines-of-python/&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;A Neural Network in 11 Lines of Python&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;u&gt;More models, and generalizations&lt;/u&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;Backpropagation&lt;/em&gt;, temporal networks, etc..&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=ghEmQSxT6tw&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Visualizing and Understanding Deep Neural Networks by Matt Zeiler&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=bLFISzfQCDQ&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Two Minute Papers - Estimating Matrix Rank With Neural Networks&lt;/a&gt;&lt;/p&gt;&lt;hr&gt;&lt;p&gt;Physical implementations:&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;http://www.dna.caltech.edu/courses/cs191/paperscs191/PNAS(88)10983.pdf&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Chemical implementations of neural networks and Turing machines&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;http://knowmtech.com/&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;http://knowmtech.com/&lt;/a&gt;&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;em&gt;More&lt;/em&gt;&lt;/p&gt;&lt;p&gt;Layerless neural networks? See Chico Calmagro's work with Ard Louis.&lt;/p&gt;&lt;p&gt;On the complex backpropagation algorithm&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;http://www.sciencedirect.com/science/article/pii/000510989290053I&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Neural networks for control systemsâ€”A survey&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;http://ieeexplore.ieee.org/xpl/login.jsp?tp=&amp;amp;arnumber=7364099&amp;amp;url=http%3A%2F%2Fieeexplore.ieee.org%2Fxpls%2Fabs_all.jsp%3Farnumber%3D7364099&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Genetic deep neural networks using different activation functions for financial data mining&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;http://www.merl.com/publications/docs/TR2015-032.pdf&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Structure Discovery of Deep Neural Network Based on Evolutionary Algorithms&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;http://dl.acm.org/citation.cfm?id=2602287&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Genetic algorithms for evolving deep neural networks&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;http://polar.lsi.uned.es/revista/index.php/ia/article/viewFile/532/516&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Busqueda de la estructura optima de redes neurales con Algoritmos Geneticos y Simulated Annealing. Verificacion con el benchmark PROBEN1&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;http://ceur-ws.org/Vol-1315/paper15.pdf&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Implementation of Evolutionary Algorithms for Deep Architectures&lt;/a&gt;&lt;/p&gt;&lt;p&gt;See ideas here: Idea for neural network for chemical synethesis and manufacturing etc. Facebook post: &lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.facebook.com/guillermovalleperez/posts/10153853693416223?&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;https://www.facebook.com/guillermovalleperez/posts/10153853693416223?&lt;/a&gt;&lt;/p&gt;&lt;h3 class=&quot;&quot;&gt;&lt;u&gt;Statistical mechanics of neural networks&lt;/u&gt;&lt;/h3&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;http://www.pnas.org/content/79/8/2554.short&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Neural networks and physical systems with emergent collective computational abilities&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;http://journals.aps.org/pra/abstract/10.1103/PhysRevA.32.1007&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Spin-glass models of neural networks&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;http://link.springer.com/article/10.1007/BF01304440&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Learning and pattern recognition in spin glass models&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;http://ir.library.oregonstate.edu/xmlui/handle/1957/28802&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Neural nets : classical results and current problems&lt;/a&gt;&lt;/p&gt;</p>