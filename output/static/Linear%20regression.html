<p>&lt;p&gt;See &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Regression%20analysis&quot;&gt;Regression analysis&lt;/a&gt;.&lt;/p&gt;&lt;h2 class=&quot;&quot;&gt;&lt;strong&gt;Least mean squares&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;See &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Least-squares&quot;&gt;Least-squares&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Use &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Matrix%20calculus&quot;&gt;Matrix calculus&lt;/a&gt; for optimization: leads to &lt;strong&gt;normal equations&lt;/strong&gt; (analytical solution to least squares), etc.&lt;/p&gt;&lt;p&gt;See &lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;http://cs229.stanford.edu/notes/cs229-notes1.pdf&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;here&lt;/a&gt;&lt;/p&gt;&lt;h3 class=&quot;&quot;&gt;&lt;u&gt;Probabilitistic interpretation&lt;/u&gt;&lt;/h3&gt;&lt;p&gt;See &lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=HZ4cvaztQEs&amp;amp;index=3&amp;amp;list=PLA89DCFA6ADACE599#t=28m40s&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;here&lt;/a&gt;. We assume the errors between model values and actual values follow a &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Normal%20distribution&quot;&gt;Normal distribution&lt;/a&gt;. This implies the data would be distributed as a Gaussian with mean &lt;span&gt;&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msup&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;Θ&lt;/mi&gt;&lt;mi&gt;T&lt;/mi&gt;&lt;/msup&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;\Theta^T x&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:0.8413309999999999em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;strut bottom&quot; style=&quot;height:0.8413309999999999em;vertical-align:0em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;base textstyle uncramped&quot;&gt;&lt;span class=&quot;mord&quot;&gt;&lt;span class=&quot;mord mathrm&quot;&gt;Θ&lt;/span&gt;&lt;span class=&quot;vlist&quot;&gt;&lt;span style=&quot;top:-0.363em;margin-right:0.05em;&quot;&gt;&lt;span class=&quot;fontsize-ensurer reset-size5 size5&quot;&gt;&lt;span style=&quot;font-size:0em;&quot;&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;reset-textstyle scriptstyle uncramped&quot;&gt;&lt;span class=&quot;mord mathit&quot; style=&quot;margin-right:0.13889em;&quot;&gt;T&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;baseline-fix&quot;&gt;&lt;span class=&quot;fontsize-ensurer reset-size5 size5&quot;&gt;&lt;span style=&quot;font-size:0em;&quot;&gt;​&lt;/span&gt;&lt;/span&gt;​&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;mord mathit&quot;&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;, and a certain &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Variance&quot;&gt;Variance&lt;/a&gt;. See &lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=HZ4cvaztQEs&amp;amp;index=3&amp;amp;list=PLA89DCFA6ADACE599#t=33m&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;here&lt;/a&gt;. With this we &lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=HZ4cvaztQEs&amp;amp;index=3&amp;amp;list=PLA89DCFA6ADACE599#t=41m20s&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;define&lt;/a&gt; the &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Likelihood%20function&quot;&gt;Likelihood function&lt;/a&gt;. One can then derive that &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Maximum%20likelihood&quot;&gt;maximizing likelihood&lt;/a&gt; is the same as mimimizing mean squares.&lt;/p&gt;&lt;p&gt;&lt;u&gt;Doing linear regression in Python with &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Sklearn&quot;&gt;Sklearn&lt;/a&gt;&lt;/u&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=JcI5Vnw0b2c&amp;amp;index=2&amp;amp;list=PLQVvvaa0QuDfKTOs3Keq_kaG2P55YRn5v&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Regression Intro - Practical Machine Learning Tutorial with Python p.2&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;sub&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=V59bYfIomVk&amp;amp;list=PLQVvvaa0QuDfKTOs3Keq_kaG2P55YRn5v&amp;amp;index=7&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Regression How it Works - Practical Machine Learning Tutorial with Python p.7&lt;/a&gt;&lt;/sub&gt;&lt;/p&gt;&lt;hr&gt;&lt;p&gt;There exists a &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Nonparametric%20statistics&quot;&gt;nonparametric&lt;/a&gt; generalization of linear regression: &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Locally-weighted%20linear%20regression&quot;&gt;Locally-weighted linear regression&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The different features should not be linearly dependent in linear models, as parameters would be badly behaved&lt;/p&gt;</p>