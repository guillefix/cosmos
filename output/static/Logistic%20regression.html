<p>A type of <a class="tc-tiddlylink tc-tiddlylink-resolves" href="#Classification">Classification</a> method.</p><p><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=FYgsztDxSvE&amp;list=PLjK8ddCbDMphIMSXn-w1IjyYpHU3DaUYw&amp;index=7" rel="noopener noreferrer" target="_blank">Logistic regression</a> <a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=FYgsztDxSvE&amp;list=PLjK8ddCbDMphIMSXn-w1IjyYpHU3DaUYw&amp;index=7#t=14m42s" rel="noopener noreferrer" target="_blank">Definition</a></p><p><a class="tc-tiddlylink-external" href="http://www.gaussianprocess.org/gpml/chapters/RW3.pdf#page=5" rel="noopener noreferrer" target="_blank">pdf</a></p><p>See <a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=HZ4cvaztQEs&amp;index=3&amp;list=PLA89DCFA6ADACE599#t=50m" rel="noopener noreferrer" target="_blank">also here</a> for intro</p><p><u><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=HZ4cvaztQEs&amp;index=3&amp;list=PLA89DCFA6ADACE599#t=57m17s" rel="noopener noreferrer" target="_blank">Probabilistic interpretation</a></u>. Logitistic regression can also be interpretedas a <a class="tc-tiddlylink tc-tiddlylink-resolves" href="#Maximum%20likelihood">Maximum likelihood</a> estimate assuming the Logistic funciton (sigmoid) gives the probability of belonging to a given class. We can then use <a class="tc-tiddlylink tc-tiddlylink-resolves" href="#Gradient%20descent">Gradient descent</a>. More theoretical understanding can be acquired from the theory of <a class="tc-tiddlylink tc-tiddlylink-resolves" href="#Generalized%20linear%20model">Generalized linear model</a>s</p><p>A simpler version: <a class="tc-tiddlylink tc-tiddlylink-resolves" href="#Perceptron">Perceptron</a></p><p>See <a class="tc-tiddlylink-external" href="http://www.cs.ox.ac.uk/people/varun.kanade/teaching/ML-MT2016/slides/slides08.pdf" rel="noopener noreferrer" target="_blank">here</a></p><p><a class="tc-tiddlylink-external" href="http://mathgotchas.blogspot.co.uk/2011/10/why-is-error-function-minimized-in.html" rel="noopener noreferrer" target="_blank">Why is it convex</a></p><h2 class=""><u>Training</u></h2><p>Maximum likelihood. Log likelihood turns out to be cross-entropy.</p><p>To see if problem is convex, we test if the <a class="tc-tiddlylink tc-tiddlylink-resolves" href="#Hessian">Hessian</a> is positive semi-definite, and it is. See <a class="tc-tiddlylink-external" href="http://www.cs.ox.ac.uk/people/varun.kanade/teaching/ML-MT2016/slides/slides08.pdf" rel="noopener noreferrer" target="_blank">here</a> for form of Hessian</p><h2 class=""><u><a class="tc-tiddlylink tc-tiddlylink-resolves" href="#Kernel%20method">Kernel</a> logistic regression</u></h2><p><a class="tc-tiddlylink-external" href="https://youtu.be/Vm5QE54y6mw?t=26m57s" rel="noopener noreferrer" target="_blank">Video</a></p>