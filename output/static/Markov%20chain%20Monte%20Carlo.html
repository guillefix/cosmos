<p><a class="tc-tiddlylink tc-tiddlylink-resolves" href="#Markov%20chain">Markov chain</a>s to <a class="tc-tiddlylink tc-tiddlylink-resolves" href="#Sampling">sample</a> in <a class="tc-tiddlylink tc-tiddlylink-resolves" href="#Monte%20Carlo">Monte Carlo</a> methods, useful for <a class="tc-tiddlylink tc-tiddlylink-resolves" href="#Bayesian%20inference">Bayesian inference</a></p><h3 class=""><a class="tc-tiddlylink tc-tiddlylink-resolves" href="#Metropolis-Hastings%20algorithm">Metropolis-Hastings algorithm</a></h3><p><a class="tc-tiddlylink tc-tiddlylink-resolves" href="#Random%20walk%20Metropolis">Random walk Metropolis</a></p><p>Convergence results (<a class="tc-tiddlylink tc-tiddlylink-missing" href="#Ergodic%20theorem">Ergodic theorem</a>s, etc) can be shown using results in <a class="tc-tiddlylink tc-tiddlylink-resolves" href="#Discrete-time%20Markov%20chain">Discrete-time Markov chain</a></p><p><strong>Measure of convergence</strong>: Gelman and Rubin’s <span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mover accent="true"><mrow><mi>R</mi></mrow><mo>^</mo></mover></mrow><annotation encoding="application/x-tex">\hat{R}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.9467699999999999em;"></span><span class="strut bottom" style="height:0.9467699999999999em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord accent"><span class="vlist"><span style="top:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="mord textstyle cramped"><span class="mord mathit" style="margin-right:0.00773em;">R</span></span></span><span style="top:-0.25233em;margin-left:0.16668em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="accent-body"><span>^</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span></span>, but must start the ensemble of walkers/chains well dispersed on the sampling space.</p><p><strong>Performance of samplers</strong>: number of effective samples per unit time. Need effective sample size (number of samples that need to pass so that the new sample is approx independent). We are interested on this because independence samplers often converge to the stationary distribution faster. However, <a class="tc-tiddlylink tc-tiddlylink-missing" href="#Antithetic%20sampling">Antithetic sampling</a> (where new samples are anti-correlated to current samples) can converge faster than independence sampling! Can estimate effective sample size experimentally.. any theroy?</p><h2 class=""><a class="tc-tiddlylink tc-tiddlylink-resolves" href="#Gibbs%20sampling">Gibbs sampling</a></h2><p><a class="tc-tiddlylink tc-tiddlylink-resolves" href="#Hamiltonian%20Monte%20Carlo">Hamiltonian Monte Carlo</a></p><p>Stan programming language</p><p><a class="tc-tiddlylink-external" href="https://dl.dropboxusercontent.com/content_link/lhtGgsRvzc4BtfOcExAoepNFLHiyrUKuXt87v9L8Lg2RTO3MdK05SdsxdzB3YZbL/file" rel="noopener noreferrer" target="_blank">dropbox</a></p>