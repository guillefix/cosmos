<p>This includes <a class="tc-tiddlylink tc-tiddlylink-resolves" href="#Model%20evaluation">Model evaluation</a>, which is the way models are selected...</p><p><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=0kWZoyNRxTY&amp;index=10&amp;list=PLA89DCFA6ADACE599#t=36m40s" rel="noopener noreferrer" target="_blank">Introduction</a>, see overfitting and underfitting below. Model selection algorithms provide methods to automatically choose optimal bias/variance tradeoffs. <a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=0kWZoyNRxTY&amp;index=10&amp;list=PLA89DCFA6ADACE599#t=40m10s" rel="noopener noreferrer" target="_blank">Explanation</a></p><h2 class=""><u><a class="tc-tiddlylink tc-tiddlylink-missing" href="#Predictive%20posterior">Predictive posterior</a></u></h2><p>Predictive posterior checks. Likelihood of data, mostly on test data (see <a class="tc-tiddlylink tc-tiddlylink-resolves" href="#Cross-validation">Cross-validation</a>).</p><p>Check distribution of extreme values</p><h2 class=""><u>Information criteria</u></h2><ul><li><a class="tc-tiddlylink tc-tiddlylink-resolves" href="#Akaike%20information%20criterion">Akaike information criterion</a> (AIC)</li><li><a class="tc-tiddlylink tc-tiddlylink-resolves" href="#Bayesian%20information%20criterion">Bayesian information criterion</a> (BIC)</li><li><a class="tc-tiddlylink tc-tiddlylink-missing" href="#Widely%20applicable%20information%20criterion">Widely applicable information criterion</a> (WAIC)</li><li><a class="tc-tiddlylink tc-tiddlylink-missing" href="#Approximate%20leave-one-out%20cross-validation">Approximate leave-one-out cross-validation</a> (LOO) using Pareto smoothed importance sampling (PSIS), a new procedure for regularizing importance weights. (<a class="tc-tiddlylink-external" href="https://cran.r-project.org/web/packages/loo/index.html" rel="noopener noreferrer" target="_blank">R package</a>)</li></ul><p><a class="tc-tiddlylink-external" href="http://www.stat.columbia.edu/~gelman/research/unpublished/loo_stan.pdf" rel="noopener noreferrer" target="_blank">Paper</a></p><h2 class=""><u><a class="tc-tiddlylink tc-tiddlylink-resolves" href="#Cross-validation">Cross-validation</a></u></h2><h2 class=""><u><a class="tc-tiddlylink tc-tiddlylink-resolves" href="#Feature%20selection">Feature selection</a></u></h2><h2 class=""><u><a class="tc-tiddlylink tc-tiddlylink-resolves" href="#Structural%20risk%20minimization">Structural risk minimization</a></u></h2><hr><p>A lot of these methods are very much related to <a class="tc-tiddlylink tc-tiddlylink-resolves" href="#Regularization">Regularization</a> methods, as both try to make our model better. Often we want the model to be better at generalizing, and this is done by reducing model complexity.</p><p>Using cross-validation for regularization can be done using <a class="tc-tiddlylink tc-tiddlylink-resolves" href="#Early%20stopping">Early stopping</a> using the validation set</p><hr><p><u>Model selection for <a class="tc-tiddlylink tc-tiddlylink-resolves" href="#Artificial%20neural%20network">Artificial neural network</a>s</u>: <a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=Fs-raHUnF2M&amp;list=PL6Xpj9I5qXYEcOhn7TqghAJ6NAPrNmUBH&amp;index=16" rel="noopener noreferrer" target="_blank">Neural networks [2.10] : Training neural networks - model selection</a></p><p><sub><em>Old comment</em>: One can show (maybe technical details I don't know..) that given the real distribution of the data, and a sample used for training, one is likely to underestimate the error. So I think cross-validation can be shown rigorously to be good for assessing a model's predictive power (i.e. probability of predicting rightly). See Elements of Statistical Learning book for all details..</sub></p><p>It is a way to find out if you are overfitting</p><p>Related: <a class="tc-tiddlylink-external" href="https://en.wikipedia.org/wiki/Testing_hypotheses_suggested_by_the_data" rel="noopener noreferrer" target="_blank">https://en.wikipedia.org/wiki/Testing_hypotheses_suggested_by_the_data</a></p>