<p><code>&lt;!doctype html&gt;
&lt;html&gt;
&lt;head&gt;
&lt;meta http-equiv=&quot;Content-Type&quot; content=&quot;text/html;charset=utf-8&quot; /&gt;
&lt;meta name=&quot;generator&quot; content=&quot;TiddlyWiki&quot; /&gt;
&lt;meta name=&quot;tiddlywiki-version&quot; content=&quot;</code>5.1.17<code>&quot; /&gt;
&lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot; /&gt;
&lt;meta name=&quot;apple-mobile-web-app-capable&quot; content=&quot;yes&quot; /&gt;
&lt;meta name=&quot;apple-mobile-web-app-status-bar-style&quot; content=&quot;black-translucent&quot; /&gt;
&lt;meta name=&quot;mobile-web-app-capable&quot; content=&quot;yes&quot;/&gt;
&lt;meta name=&quot;format-detection&quot; content=&quot;telephone=no&quot;&gt;
&lt;link id=&quot;faviconLink&quot; rel=&quot;shortcut icon&quot; href=&quot;favicon.ico&quot;&gt;
&lt;link rel=&quot;stylesheet&quot; href=&quot;static.css&quot;&gt;
&lt;title&gt;</code>Generative adversarial network: Cosmos — Everything there was, there is, <span class="subtitle-dark">and there will be</span><code>&lt;/title&gt;
&lt;/head&gt;
&lt;body class=&quot;tc-body&quot;&gt;
</code><code>
&lt;section class=&quot;tc-story-river&quot;&gt;
</code>
&lt;p&gt;&lt;div class=&quot;tc-tiddler-frame tc-tiddler-view-frame tc-tiddler-exists   tc-tagged-Generative%20model &quot; data-tags=&quot;[[Generative model]]&quot; data-tiddler-title=&quot;Generative adversarial network&quot;&gt;&lt;div class=&quot;tc-tiddler-title&quot;&gt;
&lt;div class=&quot;tc-titlebar&quot;&gt;
&lt;span class=&quot;tc-tiddler-controls&quot;&gt;
&lt;span class=&quot; tc-reveal&quot;&gt;&lt;button aria-label=&quot;more&quot; class=&quot;tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fmore-tiddler-actions&quot; title=&quot;More actions&quot;&gt;&lt;/button&gt;&lt;div class=&quot; tc-reveal&quot; hidden=&quot;true&quot;&gt;&lt;/div&gt;&lt;/span&gt;&lt;span class=&quot; tc-reveal&quot; hidden=&quot;true&quot;&gt;&lt;/span&gt;&lt;span class=&quot; tc-reveal&quot; hidden=&quot;true&quot;&gt;&lt;/span&gt;&lt;span class=&quot; tc-reveal&quot; hidden=&quot;true&quot;&gt;&lt;/span&gt;&lt;span class=&quot; tc-reveal&quot; hidden=&quot;true&quot;&gt;&lt;/span&gt;&lt;span class=&quot; tc-reveal&quot; hidden=&quot;true&quot;&gt;&lt;/span&gt;&lt;span class=&quot; tc-reveal&quot;&gt;&lt;button aria-label=&quot;edit&quot; class=&quot;tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fedit&quot; title=&quot;Edit this tiddler&quot;&gt;&lt;/button&gt;&lt;/span&gt;&lt;span class=&quot; tc-reveal&quot; hidden=&quot;true&quot;&gt;&lt;/span&gt;&lt;span class=&quot; tc-reveal&quot; hidden=&quot;true&quot;&gt;&lt;/span&gt;&lt;span class=&quot; tc-reveal&quot; hidden=&quot;true&quot;&gt;&lt;/span&gt;&lt;span class=&quot; tc-reveal&quot; hidden=&quot;true&quot;&gt;&lt;/span&gt;&lt;span class=&quot; tc-reveal&quot; hidden=&quot;true&quot;&gt;&lt;/span&gt;&lt;span class=&quot; tc-reveal&quot;&gt;&lt;button aria-label=&quot;close&quot; class=&quot;tc-btn-invisible tc-btn-%24%3A%2Fcore%2Fui%2FButtons%2Fclose&quot; title=&quot;Close this tiddler&quot;&gt;&lt;/button&gt;&lt;/span&gt;&lt;span class=&quot; tc-reveal&quot; hidden=&quot;true&quot;&gt;&lt;/span&gt;&lt;span class=&quot; tc-reveal&quot; hidden=&quot;true&quot;&gt;&lt;/span&gt;&lt;span class=&quot; tc-reveal&quot; hidden=&quot;true&quot;&gt;&lt;/span&gt;&lt;span class=&quot; tc-reveal&quot;&gt;&lt;button aria-label=&quot;tiddlymap&quot; class=&quot;tc-btn-invisible tc-btn-%24%3A%2Fplugins%2Ffelixhayashi%2Ftiddlymap%2Fmisc%2FquickConnectButton &quot; title=&quot;Toggle TiddlyMap actions&quot;&gt;


&lt;/button&gt;&lt;/span&gt;
&lt;/span&gt;

&lt;span&gt;

&lt;span class=&quot;tc-tiddler-title-icon&quot; style=&quot;fill:;&quot;&gt;

&lt;/span&gt;



&lt;h2 class=&quot;tc-title&quot;&gt;
Generative adversarial network
&lt;/h2&gt;

&lt;/span&gt;

&lt;/div&gt;

&lt;div class=&quot;tc-tiddler-info tc-popup-handle tc-reveal&quot; hidden=&quot;true&quot;&gt;&lt;/div&gt;
&lt;/div&gt;&lt;div class=&quot; tc-reveal&quot; hidden=&quot;true&quot;&gt;&lt;/div&gt;
&lt;div class=&quot; tc-reveal&quot;&gt;
&lt;div class=&quot;tc-subtitle&quot;&gt;
&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-missing&quot; href=&quot;cosmos.html&quot;&gt;
cosmos
&lt;/a&gt; 6th November 2017 at 5:26pm
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot; tc-reveal&quot;&gt;
&lt;div class=&quot;tc-tags-wrapper&quot;&gt;&lt;span class=&quot;tc-tag-list-item&quot;&gt;


&lt;span class=&quot;tc-tag-label tc-btn-invisible&quot; draggable=&quot;true&quot; style=&quot;background-color:;
fill:#333333;
color:#333333;&quot;&gt;
 Generative model
&lt;/span&gt;

&lt;span class=&quot;tc-drop-down tc-reveal&quot; hidden=&quot;true&quot;&gt;&lt;/span&gt;

&lt;/span&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;tc-tiddler-body tc-reveal&quot;&gt;&lt;p&gt;An architecture to train generative neural networks, i.e. &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;Artificial%2520neural%2520network.html&quot;&gt;neural networks&lt;/a&gt; which act as &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;Generative%2520model.html&quot;&gt;Generative model&lt;/a&gt;s, i.e. their inputs are &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;Latent%2520variable.html&quot;&gt;Latent variable&lt;/a&gt;s, and their output is the observed data.&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://deephunt.in/the-gan-zoo-79597dc8c347&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;https://deephunt.in/the-gan-zoo-79597dc8c347&lt;/a&gt; – &lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://github.com/wiseodd/generative-models&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;https://github.com/wiseodd/generative-models&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://arxiv.org/pdf/1701.00160.pdf&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;NIPS tutorial&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://reiinakano.github.io/gan-playground/&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;GAN on browser&lt;/a&gt;&lt;/p&gt;&lt;h2 class=&quot;&quot;&gt;&lt;u&gt;Adversarial networks&lt;/u&gt;&lt;/h2&gt;&lt;p&gt;The way the network is trained is by having the generative network produce images, while training a different discriminative network to discriminate between real and generated images. In this way, the discriminative network can be used as a very good cost function, which penalized generated images which are distinguishably different from the real images that the generative network is train to model.&lt;/p&gt;&lt;p&gt;We are in effect learning the cost function&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=QPkb5VcgXAM#t=14m30&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;video&lt;/a&gt;&lt;/p&gt;&lt;h2 class=&quot;&quot;&gt;&lt;u&gt;Trining GANs&lt;/u&gt;&lt;/h2&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=X1mUN6dD8uE&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;NIPS 2016 Workshop on Adversarial Training - Soumith Chintala - How to train a GAN&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=QPkb5VcgXAM#t=18m05&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Trained&lt;/a&gt; via &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;Gradient%2520descent.html&quot;&gt;Gradient descent&lt;/a&gt; and &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;Backpropagation.html&quot;&gt;Backpropagation&lt;/a&gt;&lt;/p&gt;&lt;p&gt;I think that the discriminator needs to have a separate cost function which measures the number of images the discriminator missclassified as being real or generated. &lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=QPkb5VcgXAM#t=19m47&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Discriminator is optimized to not be fooled by the generator&lt;/a&gt;&lt;/p&gt;&lt;p&gt;On the other hand, the generative network uses the discriminative network as cost. &lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=QPkb5VcgXAM#t=19m20&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Generator to fool discriminator, i.e. it is trained to maximize the mistakes the the discriminator does&lt;/a&gt;, that's why they are called &lt;strong&gt;adversarial&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;The discriminator is &lt;em&gt;teaching&lt;/em&gt; the generator, and it's adapting to the generator's knowledge and flaws. &lt;em&gt;Machine teaching&lt;/em&gt;, not just machine learning.&lt;/p&gt;&lt;h3 class=&quot;&quot;&gt;&lt;u&gt;Alternating &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;Optimization.html&quot;&gt;Optimization&lt;/a&gt;&lt;/u&gt;&lt;/h3&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=QPkb5VcgXAM#t=19m59&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;video&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://arxiv.org/abs/1606.03498&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Improved Techniques for Training GANs&lt;/a&gt; &lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=QPkb5VcgXAM#t=45m30&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;vid&lt;/a&gt;&lt;/p&gt;&lt;h2 class=&quot;&quot;&gt;&lt;u&gt;Theoretical properties&lt;/u&gt;&lt;/h2&gt;&lt;p&gt;If you have an optimal discriminator, the generator minimizes the &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;Jensen-Shanon%2520divergence.html&quot;&gt;Jensen-Shanon divergence&lt;/a&gt;&lt;/p&gt;&lt;h2 class=&quot;&quot;&gt;&lt;u&gt;Variants&lt;/u&gt;&lt;/h2&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=QPkb5VcgXAM#t=23m15&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Original GANs were diffucult to train&lt;/a&gt; &lt;/p&gt;&lt;h3 class=&quot;&quot;&gt;&lt;u&gt;Class-conditional GANs&lt;/u&gt;&lt;/h3&gt;&lt;p&gt;They are &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;Supervised%2520learning.html&quot;&gt;supervised&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://arxiv.org/abs/1506.05751&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Deep Generative Image Models using a Laplacian Pyramid of Adversarial Networks&lt;/a&gt; &lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=QPkb5VcgXAM#t=24m&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;vid&lt;/a&gt;&lt;/p&gt;&lt;h3 class=&quot;&quot;&gt;&lt;u&gt;Video-prediction GANs&lt;/u&gt;&lt;/h3&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://arxiv.org/abs/1511.05440&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Deep multi-scale video prediction beyond mean square error&lt;/a&gt;
&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=QPkb5VcgXAM#t=25m45s&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;vid&lt;/a&gt;&lt;/p&gt;&lt;h3 class=&quot;&quot;&gt;&lt;u&gt;DCGANs&lt;/u&gt;&lt;/h3&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://arxiv.org/abs/1511.06434&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=QPkb5VcgXAM#t=30m30s&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Latent space arithmetic&lt;/a&gt;&lt;/p&gt;&lt;h2 class=&quot;&quot;&gt;&lt;u&gt;In-painting GANs&lt;/u&gt;&lt;/h2&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://arxiv.org/abs/1604.07379&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Context Encoders: Feature Learning by Inpainting&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=QPkb5VcgXAM#t=39m05&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;video&lt;/a&gt;&lt;/p&gt;&lt;h2 class=&quot;&quot;&gt;&lt;u&gt;Applications&lt;/u&gt;&lt;/h2&gt;&lt;h3 class=&quot;&quot;&gt;&lt;u&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;Feature%2520learning.html&quot;&gt;Feature learning&lt;/a&gt; for &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;Semi-supervised%2520learning.html&quot;&gt;Semi-supervised learning&lt;/a&gt;&lt;/u&gt;&lt;/h3&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=QPkb5VcgXAM#t=33m25&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;GANs for feature learning&lt;/a&gt;. &lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=pqkpIfu36Os&amp;amp;list=PLujxSBD-JXgnqDD1n-V30pKtp6Q886x7e&amp;amp;index=108&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Two Minute Papers - Image Editing with Generative Adversarial Networks&lt;/a&gt;&lt;/p&gt;&lt;h3 class=&quot;&quot;&gt;&lt;u&gt;Disentangling representations&lt;/u&gt;&lt;/h3&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=QPkb5VcgXAM#t=41m50s&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;vid&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://arxiv.org/abs/1606.03657&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets&lt;/a&gt; (from &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-missing&quot; href=&quot;OpenAI.html&quot;&gt;OpenAI&lt;/a&gt;)&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;http://www.inference.vc/how-to-train-your-generative-models-why-generative-adversarial-networks-work-so-well-2/&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;http://www.inference.vc/how-to-train-your-generative-models-why-generative-adversarial-networks-work-so-well-2/&lt;/a&gt;&lt;/p&gt;&lt;p&gt;They are similar to &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;Autoencoder.html&quot;&gt;Autoencoder&lt;/a&gt;s but we learn the cost function, instead of just using l2 loss  (&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=QPkb5VcgXAM#t=58m50&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;vid&lt;/a&gt;)&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=deyOX6Mt_As&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;vid&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://arxiv.org/abs/1406.2661&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Generative Adversarial Networks&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.wikiwand.com/en/Generative_adversarial_networks&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;https://www.wikiwand.com/en/Generative_adversarial_networks&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=QPkb5VcgXAM#t=51m20&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;the future&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://arxiv.org/abs/1610.01945&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Connecting Generative Adversarial Networks and Actor-Critic Methods&lt;/a&gt;&lt;/p&gt;&lt;hr&gt;&lt;p&gt;More variations and others&lt;/p&gt;&lt;p&gt;URL list from Sunday, May. 21 2017 16:41 PM&lt;/p&gt;&lt;p&gt;To copy this list, type [Ctrl] A, then type [Ctrl] C. &lt;/p&gt;&lt;p&gt;1603.08155.pdf
&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://arxiv.org/pdf/1603.08155.pdf&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/pdf/1603.08155.pdf&lt;/a&gt;&lt;/p&gt;&lt;p&gt;1703.10593.pdf
&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://arxiv.org/pdf/1703.10593.pdf&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/pdf/1703.10593.pdf&lt;/a&gt;&lt;/p&gt;&lt;p&gt;1610.09003.pdf
&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://arxiv.org/pdf/1610.09003.pdf&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/pdf/1610.09003.pdf&lt;/a&gt;&lt;/p&gt;&lt;p&gt;RL Course by David Silver - Lecture 5: Model Free Control - YouTube
&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=0g4j2k_Ggc4&amp;amp;index=5&amp;amp;list=PL7-jPKtc4r78-wCZcQn5IqyuWhBZ8fOxT&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;https://www.youtube.com/watch?v=0g4j2k_Ggc4&amp;amp;index=5&amp;amp;list=PL7-jPKtc4r78-wCZcQn5IqyuWhBZ8fOxT&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Teaching
&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Lecture 1a - Introduction [Phil Blunsom] - YouTube
&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://www.youtube.com/watch?v=RP3tZFcC2e8&amp;amp;list=PL613dYIGMXoZBtZhbyiBqb0QtgK6oJbpm&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;https://www.youtube.com/watch?v=RP3tZFcC2e8&amp;amp;list=PL613dYIGMXoZBtZhbyiBqb0QtgK6oJbpm&lt;/a&gt;&lt;/p&gt;&lt;p&gt;[1612.03242] StackGAN: Text to Photo-realistic Image Synthesis with Stacked Generative Adversarial Networks
&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://arxiv.org/abs/1612.03242&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/1612.03242&lt;/a&gt;&lt;/p&gt;&lt;p&gt;[1703.06412] TAC-GAN - Text Conditioned Auxiliary Classifier Generative Adversarial Network
&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://arxiv.org/abs/1703.06412&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/1703.06412&lt;/a&gt;&lt;/p&gt;&lt;p&gt;[1703.06676] I2T2I: Learning Text to Image Synthesis with Textual Data Augmentation
&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://arxiv.org/abs/1703.06676&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/1703.06676&lt;/a&gt;&lt;/p&gt;&lt;p&gt;I2T2I: LEARNING TEXT TO IMAGE SYNTHESIS WITH TEXTUAL DATA AUGMENTATION
&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://arxiv.org/pdf/1703.06676.pdf&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/pdf/1703.06676.pdf&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Generative Adversarial Text to Image Synthesis
&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://arxiv.org/pdf/1605.05396.pdf&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/pdf/1605.05396.pdf&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Reed: Generative adversarial text to image synthesis - Google Scholar
&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://scholar.google.co.uk/scholar?start=70&amp;amp;hl=en&amp;amp;as_sdt=0,5&amp;amp;sciodt=0,5&amp;amp;cites=8255440757806230750&amp;amp;scipsc&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;https://scholar.google.co.uk/scholar?start=70&amp;amp;hl=en&amp;amp;as_sdt=0,5&amp;amp;sciodt=0,5&amp;amp;cites=8255440757806230750&amp;amp;scipsc&lt;/a&gt;=&lt;/p&gt;&lt;p&gt;Learning What and Where to Draw
&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;http://papers.nips.cc/paper/6111-learning-what-and-where-to-draw&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;http://papers.nips.cc/paper/6111-learning-what-and-where-to-draw&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Generating Visual Explanations | SpringerLink
&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://link.springer.com/chapter/10.1007/978-3-319-46493-0_1&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;https://link.springer.com/chapter/10.1007/978-3-319-46493-0_1&lt;/a&gt;&lt;/p&gt;&lt;p&gt;[1609.09444] Contextual RNN-GANs for Abstract Reasoning Diagram Generation
&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://arxiv.org/abs/1609.09444&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/1609.09444&lt;/a&gt;&lt;/p&gt;&lt;p&gt;[1702.03431] Crossing Nets: Dual Generative Models with a Shared Latent Space for Hand Pose Estimation
&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://arxiv.org/abs/1702.03431&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/1702.03431&lt;/a&gt;&lt;/p&gt;&lt;p&gt;DISCO Nets : DISsimilarity COefficients Networks
&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;http://papers.nips.cc/paper/6143-disco-nets-dissimilarity-coefficients-networks&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;http://papers.nips.cc/paper/6143-disco-nets-dissimilarity-coefficients-networks&lt;/a&gt;&lt;/p&gt;&lt;p&gt;[1704.06933] Adversarial Neural Machine Translation
&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://arxiv.org/abs/1704.06933&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/1704.06933&lt;/a&gt;&lt;/p&gt;&lt;p&gt;[1702.04125] One-Step Time-Dependent Future Video Frame Prediction with a Convolutional Encoder-Decoder Neural Network
&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://arxiv.org/abs/1702.04125&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/1702.04125&lt;/a&gt;&lt;/p&gt;&lt;p&gt;[1703.06029] Towards Diverse and Natural Image Descriptions via a Conditional GAN
&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://arxiv.org/abs/1703.06029&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;https://arxiv.org/abs/1703.06029&lt;/a&gt;&lt;/p&gt;&lt;p&gt;cvpr17_summarization.pdf
&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;http://web.engr.oregonstate.edu/~sinisa/research/publications/cvpr17_summarization.pdf&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;http://web.engr.oregonstate.edu/~sinisa/research/publications/cvpr17_summarization.pdf&lt;/a&gt;&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;http://make.girls.moe/&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;http://make.girls.moe/&lt;/a&gt;
&lt;/p&gt;&lt;/div&gt;


&lt;/div&gt;

&lt;/p&gt;
<code>
&lt;/section&gt;
&lt;/body&gt;
&lt;/html&gt;
</code></p>