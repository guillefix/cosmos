<p>An architecture to train generative neural networks, i.e. <a class="tc-tiddlylink tc-tiddlylink-resolves" href="#Artificial%20neural%20network">neural networks</a> which act as <a class="tc-tiddlylink tc-tiddlylink-resolves" href="#Generative%20model">Generative model</a>s, i.e. their inputs are <a class="tc-tiddlylink tc-tiddlylink-resolves" href="#Latent%20variable">Latent variable</a>s, and their output is the observed data.</p><p><a class="tc-tiddlylink-external" href="https://deephunt.in/the-gan-zoo-79597dc8c347" rel="noopener noreferrer" target="_blank">https://deephunt.in/the-gan-zoo-79597dc8c347</a> â€“ <a class="tc-tiddlylink-external" href="https://github.com/wiseodd/generative-models" rel="noopener noreferrer" target="_blank">https://github.com/wiseodd/generative-models</a></p><p><a class="tc-tiddlylink-external" href="https://arxiv.org/pdf/1701.00160.pdf" rel="noopener noreferrer" target="_blank">NIPS tutorial</a></p><p><a class="tc-tiddlylink-external" href="https://reiinakano.github.io/gan-playground/" rel="noopener noreferrer" target="_blank">GAN on browser</a></p><h2 class=""><u>Adversarial networks</u></h2><p>The way the network is trained is by having the generative network produce images, while training a different discriminative network to discriminate between real and generated images. In this way, the discriminative network can be used as a very good cost function, which penalized generated images which are distinguishably different from the real images that the generative network is train to model.</p><p>We are in effect learning the cost function</p><p><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=QPkb5VcgXAM#t=14m30" rel="noopener noreferrer" target="_blank">video</a></p><h2 class=""><u>Trining GANs</u></h2><p><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=X1mUN6dD8uE" rel="noopener noreferrer" target="_blank">NIPS 2016 Workshop on Adversarial Training - Soumith Chintala - How to train a GAN</a></p><p><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=QPkb5VcgXAM#t=18m05" rel="noopener noreferrer" target="_blank">Trained</a> via <a class="tc-tiddlylink tc-tiddlylink-resolves" href="#Gradient%20descent">Gradient descent</a> and <a class="tc-tiddlylink tc-tiddlylink-resolves" href="#Backpropagation">Backpropagation</a></p><p>I think that the discriminator needs to have a separate cost function which measures the number of images the discriminator missclassified as being real or generated. <a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=QPkb5VcgXAM#t=19m47" rel="noopener noreferrer" target="_blank">Discriminator is optimized to not be fooled by the generator</a></p><p>On the other hand, the generative network uses the discriminative network as cost. <a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=QPkb5VcgXAM#t=19m20" rel="noopener noreferrer" target="_blank">Generator to fool discriminator, i.e. it is trained to maximize the mistakes the the discriminator does</a>, that's why they are called <strong>adversarial</strong></p><p>The discriminator is <em>teaching</em> the generator, and it's adapting to the generator's knowledge and flaws. <em>Machine teaching</em>, not just machine learning.</p><h3 class=""><u>Alternating <a class="tc-tiddlylink tc-tiddlylink-resolves" href="#Optimization">Optimization</a></u></h3><p><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=QPkb5VcgXAM#t=19m59" rel="noopener noreferrer" target="_blank">video</a></p><p><a class="tc-tiddlylink-external" href="https://arxiv.org/abs/1606.03498" rel="noopener noreferrer" target="_blank">Improved Techniques for Training GANs</a> <a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=QPkb5VcgXAM#t=45m30" rel="noopener noreferrer" target="_blank">vid</a></p><h2 class=""><u>Theoretical properties</u></h2><p>If you have an optimal discriminator, the generator minimizes the <a class="tc-tiddlylink tc-tiddlylink-resolves" href="#Jensen-Shanon%20divergence">Jensen-Shanon divergence</a></p><h2 class=""><u>Variants</u></h2><p><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=QPkb5VcgXAM#t=23m15" rel="noopener noreferrer" target="_blank">Original GANs were diffucult to train</a> </p><h3 class=""><u>Class-conditional GANs</u></h3><p>They are <a class="tc-tiddlylink tc-tiddlylink-resolves" href="#Supervised%20learning">supervised</a></p><p><a class="tc-tiddlylink-external" href="https://arxiv.org/abs/1506.05751" rel="noopener noreferrer" target="_blank">Deep Generative Image Models using a Laplacian Pyramid of Adversarial Networks</a> <a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=QPkb5VcgXAM#t=24m" rel="noopener noreferrer" target="_blank">vid</a></p><h3 class=""><u>Video-prediction GANs</u></h3><p><a class="tc-tiddlylink-external" href="https://arxiv.org/abs/1511.05440" rel="noopener noreferrer" target="_blank">Deep multi-scale video prediction beyond mean square error</a>
<a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=QPkb5VcgXAM#t=25m45s" rel="noopener noreferrer" target="_blank">vid</a></p><h3 class=""><u>DCGANs</u></h3><p><a class="tc-tiddlylink-external" href="https://arxiv.org/abs/1511.06434" rel="noopener noreferrer" target="_blank">Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks</a></p><p><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=QPkb5VcgXAM#t=30m30s" rel="noopener noreferrer" target="_blank">Latent space arithmetic</a></p><h2 class=""><u>In-painting GANs</u></h2><p><a class="tc-tiddlylink-external" href="https://arxiv.org/abs/1604.07379" rel="noopener noreferrer" target="_blank">Context Encoders: Feature Learning by Inpainting</a></p><p><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=QPkb5VcgXAM#t=39m05" rel="noopener noreferrer" target="_blank">video</a></p><h2 class=""><u>Applications</u></h2><h3 class=""><u><a class="tc-tiddlylink tc-tiddlylink-resolves" href="#Feature%20learning">Feature learning</a> for <a class="tc-tiddlylink tc-tiddlylink-resolves" href="#Semi-supervised%20learning">Semi-supervised learning</a></u></h3><p><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=QPkb5VcgXAM#t=33m25" rel="noopener noreferrer" target="_blank">GANs for feature learning</a>. </p><p><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=pqkpIfu36Os&amp;list=PLujxSBD-JXgnqDD1n-V30pKtp6Q886x7e&amp;index=108" rel="noopener noreferrer" target="_blank">Two Minute Papers - Image Editing with Generative Adversarial Networks</a></p><h3 class=""><u>Disentangling representations</u></h3><p><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=QPkb5VcgXAM#t=41m50s" rel="noopener noreferrer" target="_blank">vid</a></p><p><a class="tc-tiddlylink-external" href="https://arxiv.org/abs/1606.03657" rel="noopener noreferrer" target="_blank">InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets</a> (from <a class="tc-tiddlylink tc-tiddlylink-missing" href="#OpenAI">OpenAI</a>)</p><hr><p><a class="tc-tiddlylink-external" href="http://www.inference.vc/how-to-train-your-generative-models-why-generative-adversarial-networks-work-so-well-2/" rel="noopener noreferrer" target="_blank">http://www.inference.vc/how-to-train-your-generative-models-why-generative-adversarial-networks-work-so-well-2/</a></p><p>They are similar to <a class="tc-tiddlylink tc-tiddlylink-resolves" href="#Autoencoder">Autoencoder</a>s but we learn the cost function, instead of just using l2 loss  (<a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=QPkb5VcgXAM#t=58m50" rel="noopener noreferrer" target="_blank">vid</a>)</p><p><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=deyOX6Mt_As" rel="noopener noreferrer" target="_blank">vid</a></p><p><a class="tc-tiddlylink-external" href="https://arxiv.org/abs/1406.2661" rel="noopener noreferrer" target="_blank">Generative Adversarial Networks</a></p><p><a class="tc-tiddlylink-external" href="https://www.wikiwand.com/en/Generative_adversarial_networks" rel="noopener noreferrer" target="_blank">https://www.wikiwand.com/en/Generative_adversarial_networks</a></p><p><a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=QPkb5VcgXAM#t=51m20" rel="noopener noreferrer" target="_blank">the future</a></p><p><a class="tc-tiddlylink-external" href="https://arxiv.org/abs/1610.01945" rel="noopener noreferrer" target="_blank">Connecting Generative Adversarial Networks and Actor-Critic Methods</a></p><hr><p>More variations and others</p><p>URL list from Sunday, May. 21 2017 16:41 PM</p><p>To copy this list, type [Ctrl] A, then type [Ctrl] C. </p><p>1603.08155.pdf
<a class="tc-tiddlylink-external" href="https://arxiv.org/pdf/1603.08155.pdf" rel="noopener noreferrer" target="_blank">https://arxiv.org/pdf/1603.08155.pdf</a></p><p>1703.10593.pdf
<a class="tc-tiddlylink-external" href="https://arxiv.org/pdf/1703.10593.pdf" rel="noopener noreferrer" target="_blank">https://arxiv.org/pdf/1703.10593.pdf</a></p><p>1610.09003.pdf
<a class="tc-tiddlylink-external" href="https://arxiv.org/pdf/1610.09003.pdf" rel="noopener noreferrer" target="_blank">https://arxiv.org/pdf/1610.09003.pdf</a></p><p>RL Course by David Silver - Lecture 5: Model Free Control - YouTube
<a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=0g4j2k_Ggc4&amp;index=5&amp;list=PL7-jPKtc4r78-wCZcQn5IqyuWhBZ8fOxT" rel="noopener noreferrer" target="_blank">https://www.youtube.com/watch?v=0g4j2k_Ggc4&amp;index=5&amp;list=PL7-jPKtc4r78-wCZcQn5IqyuWhBZ8fOxT</a></p><p>Teaching
<a class="tc-tiddlylink-external" href="http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html" rel="noopener noreferrer" target="_blank">http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html</a></p><p>Lecture 1a - Introduction [Phil Blunsom] - YouTube
<a class="tc-tiddlylink-external" href="https://www.youtube.com/watch?v=RP3tZFcC2e8&amp;list=PL613dYIGMXoZBtZhbyiBqb0QtgK6oJbpm" rel="noopener noreferrer" target="_blank">https://www.youtube.com/watch?v=RP3tZFcC2e8&amp;list=PL613dYIGMXoZBtZhbyiBqb0QtgK6oJbpm</a></p><p>[1612.03242] StackGAN: Text to Photo-realistic Image Synthesis with Stacked Generative Adversarial Networks
<a class="tc-tiddlylink-external" href="https://arxiv.org/abs/1612.03242" rel="noopener noreferrer" target="_blank">https://arxiv.org/abs/1612.03242</a></p><p>[1703.06412] TAC-GAN - Text Conditioned Auxiliary Classifier Generative Adversarial Network
<a class="tc-tiddlylink-external" href="https://arxiv.org/abs/1703.06412" rel="noopener noreferrer" target="_blank">https://arxiv.org/abs/1703.06412</a></p><p>[1703.06676] I2T2I: Learning Text to Image Synthesis with Textual Data Augmentation
<a class="tc-tiddlylink-external" href="https://arxiv.org/abs/1703.06676" rel="noopener noreferrer" target="_blank">https://arxiv.org/abs/1703.06676</a></p><p>I2T2I: LEARNING TEXT TO IMAGE SYNTHESIS WITH TEXTUAL DATA AUGMENTATION
<a class="tc-tiddlylink-external" href="https://arxiv.org/pdf/1703.06676.pdf" rel="noopener noreferrer" target="_blank">https://arxiv.org/pdf/1703.06676.pdf</a></p><p>Generative Adversarial Text to Image Synthesis
<a class="tc-tiddlylink-external" href="https://arxiv.org/pdf/1605.05396.pdf" rel="noopener noreferrer" target="_blank">https://arxiv.org/pdf/1605.05396.pdf</a></p><p>Reed: Generative adversarial text to image synthesis - Google Scholar
<a class="tc-tiddlylink-external" href="https://scholar.google.co.uk/scholar?start=70&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5&amp;cites=8255440757806230750&amp;scipsc" rel="noopener noreferrer" target="_blank">https://scholar.google.co.uk/scholar?start=70&amp;hl=en&amp;as_sdt=0,5&amp;sciodt=0,5&amp;cites=8255440757806230750&amp;scipsc</a>=</p><p>Learning What and Where to Draw
<a class="tc-tiddlylink-external" href="http://papers.nips.cc/paper/6111-learning-what-and-where-to-draw" rel="noopener noreferrer" target="_blank">http://papers.nips.cc/paper/6111-learning-what-and-where-to-draw</a></p><p>Generating Visual Explanations | SpringerLink
<a class="tc-tiddlylink-external" href="https://link.springer.com/chapter/10.1007/978-3-319-46493-0_1" rel="noopener noreferrer" target="_blank">https://link.springer.com/chapter/10.1007/978-3-319-46493-0_1</a></p><p>[1609.09444] Contextual RNN-GANs for Abstract Reasoning Diagram Generation
<a class="tc-tiddlylink-external" href="https://arxiv.org/abs/1609.09444" rel="noopener noreferrer" target="_blank">https://arxiv.org/abs/1609.09444</a></p><p>[1702.03431] Crossing Nets: Dual Generative Models with a Shared Latent Space for Hand Pose Estimation
<a class="tc-tiddlylink-external" href="https://arxiv.org/abs/1702.03431" rel="noopener noreferrer" target="_blank">https://arxiv.org/abs/1702.03431</a></p><p>DISCO Nets : DISsimilarity COefficients Networks
<a class="tc-tiddlylink-external" href="http://papers.nips.cc/paper/6143-disco-nets-dissimilarity-coefficients-networks" rel="noopener noreferrer" target="_blank">http://papers.nips.cc/paper/6143-disco-nets-dissimilarity-coefficients-networks</a></p><p>[1704.06933] Adversarial Neural Machine Translation
<a class="tc-tiddlylink-external" href="https://arxiv.org/abs/1704.06933" rel="noopener noreferrer" target="_blank">https://arxiv.org/abs/1704.06933</a></p><p>[1702.04125] One-Step Time-Dependent Future Video Frame Prediction with a Convolutional Encoder-Decoder Neural Network
<a class="tc-tiddlylink-external" href="https://arxiv.org/abs/1702.04125" rel="noopener noreferrer" target="_blank">https://arxiv.org/abs/1702.04125</a></p><p>[1703.06029] Towards Diverse and Natural Image Descriptions via a Conditional GAN
<a class="tc-tiddlylink-external" href="https://arxiv.org/abs/1703.06029" rel="noopener noreferrer" target="_blank">https://arxiv.org/abs/1703.06029</a></p><p>cvpr17_summarization.pdf
<a class="tc-tiddlylink-external" href="http://web.engr.oregonstate.edu/~sinisa/research/publications/cvpr17_summarization.pdf" rel="noopener noreferrer" target="_blank">http://web.engr.oregonstate.edu/~sinisa/research/publications/cvpr17_summarization.pdf</a></p><hr><p><a class="tc-tiddlylink-external" href="http://make.girls.moe/" rel="noopener noreferrer" target="_blank">http://make.girls.moe/</a>
</p>