<p>A computable class of <a class="tc-tiddlylink tc-tiddlylink-resolves" href="#Descriptional%20complexity">Descriptional complexity</a> measures, based on <a class="tc-tiddlylink tc-tiddlylink-resolves" href="#Automata%20theory">automata</a></p><h2 class=""><u>Automatic complexity</u></h2><p><a class="tc-tiddlylink-external" href="https://cs.uwaterloo.ca/~shallit/Papers/auto5.pdf" rel="noopener noreferrer" target="_blank">Automatic complexity of strings</a> smallest number of states of a DFA (deterministic finite automaton) that acceptsxand does not accept any other string of length |x|. Note that a DFA recognizing the singleton language {x} always needs |x|+1 states, which is the reason the definition considers only strings of length |x|. </p><p><a class="tc-tiddlylink-external" href="https://arxiv.org/pdf/1701.09060.pdf" rel="noopener noreferrer" target="_blank">Automatic Kolmogorov complexity and normality revisited</a></p><h2 class=""><u>Automaticity</u></h2><p><a class="tc-tiddlylink-external" href="http://catdir.loc.gov/catdir/samples/cam033/2002041262.pdf" rel="noopener noreferrer" target="_blank">AUTOMATIC SEQUENCES </a></p><p><a class="tc-tiddlylink-external" href="http://www.sciencedirect.com/science/article/pii/S002200009690046X" rel="noopener noreferrer" target="_blank">Automaticity I: Properties of a Measure of Descriptional Complexity</a></p><p><a class="tc-tiddlylink-external" href="https://math.dartmouth.edu/~carlp/PDF/paper113.pdf" rel="noopener noreferrer" target="_blank">Automaticity II</a></p><p>is an analogous descriptional complexity measure as Automatic complexity but for languages.</p><h2 class=""><u>Finite state dimension</u></h2><p>The finite-state dimension is defined in terms of computations of finite transducers on infinite sequences,</p><p><a class="tc-tiddlylink-external" href="http://www.sciencedirect.com/science/article/pii/S0304397505005797" rel="noopener noreferrer" target="_blank">Entropy rates and finite-state dimension</a> – <a class="tc-tiddlylink-external" href="http://cse.unl.edu/~cbourke/pubs/erfsd.pdf" rel="noopener noreferrer" target="_blank">pdf</a></p><p><a class="tc-tiddlylink-external" href="http://www.sciencedirect.com/science/article/pii/S089054010700065X" rel="noopener noreferrer" target="_blank">Finite-state dimension and real arithmetic ☆</a></p><h2 class=""><u>Finite state complexity</u></h2><p>Newest measure in this area.</p><p>Paper: <a class="tc-tiddlylink-external" href="http://www.sciencedirect.com/science/article/pii/S0304397511005408" rel="noopener noreferrer" target="_blank">http://www.sciencedirect.com/science/article/pii/S0304397511005408</a></p><p>Finite state complexity defines smallest length of input that will produce result under finite transducer (finite state machine with output basically, which i think can describe the GP maps). Then we can apply Ards argument of how many ways of fitting this shortest string in the fixed-length input of interest (say the genotype). This could be the beginning of the formal theory we need! We probably would also want to develop a concept of algorithmic probability (like Salomonoff's) for finite state machines.</p><p><a class="tc-tiddlylink-external" href="https://researchspace.auckland.ac.nz/handle/2292/10527" rel="noopener noreferrer" target="_blank">Finite-State Complexity and Randomness</a></p><p><a class="tc-tiddlylink-external" href="http://arxiv.org/pdf/1008.1667.pdf" rel="noopener noreferrer" target="_blank">Finite-State Complexity and the Size of Transducers</a></p><p><a class="tc-tiddlylink-external" href="https://en.wikipedia.org/wiki/Finite_state_transducer" rel="noopener noreferrer" target="_blank">Finite state transducer</a> <a class="tc-tiddlylink-external" href="https://en.wikipedia.org/wiki/Finite_model_theory" rel="noopener noreferrer" target="_blank">Finite model theory</a></p><hr><p><em>Others</em></p><h3 class=""><u>NFA based complexity</u></h3><p><a class="tc-tiddlylink-external" href="http://dl.acm.org/citation.cfm?id=510021" rel="noopener noreferrer" target="_blank">Approximating the smallest grammar: Kolmogorov complexity in natural models</a>. <sub>However, the model allows the advice strings to be over an arbitrary alphabet with no penalty in terms of complexity and, as observed in [8], consequently the NFAs used for compression can always be assumed to consist of only one state... (so not very good measure).</sub></p><h3 class=""><u>State complexity</u></h3><p><a class="tc-tiddlylink-external" href="https://www.semanticscholar.org/paper/State-Complexity-of-Regular-Languages-Yu/2efe616ba8b456177e1a1e19e6558b2d7494a854/pdf" rel="noopener noreferrer" target="_blank">State complexity of regular languages</a></p>