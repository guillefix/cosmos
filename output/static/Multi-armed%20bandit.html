<p>&lt;p&gt;Choosing among a series of actions, each of which has a certain probability distribution of rewards (normally a &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Bernoulli%20distribution&quot;&gt;Bernoulli distribution&lt;/a&gt;). It's like a &lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Markov%20decision%20process&quot;&gt;Markov decision process&lt;/a&gt; with only 1 state).&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-missing&quot; href=&quot;#Contextual%20bandits&quot;&gt;Contextual bandits&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-resolves&quot; href=&quot;#Thompson%20sampling&quot;&gt;Thompson sampling&lt;/a&gt;&lt;/p&gt;&lt;p&gt;See Sutton and Barto.
See here: &lt;a class=&quot;tc-tiddlylink-external&quot; href=&quot;https://github.com/damaru2/optimization17/&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;https://github.com/damaru2/optimization17/&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a class=&quot;tc-tiddlylink tc-tiddlylink-missing&quot; href=&quot;#Stochastic%20bandits&quot;&gt;Stochastic bandits&lt;/a&gt;&lt;/p&gt;</p>