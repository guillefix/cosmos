created: 20170313182526998
creator: cosmos
modified: 20170313195430143
modifier: cosmos
tags: [[Deep art]]
title: Neural style
tmap.id: e9c0654c-f593-443c-8b70-616befe99c30
type: text/vnd.tiddlywiki

See [[Convolutional neural network]], [[Deep art]]

[[video|https://www.youtube.com/watch?v=GHVaaHESrlY&list=PL16j5WbGpaM0_Tj8CRmurZ8Kk1gEBc7fg&index=9#t=52m]]. Achieved with optimization using [[ConvNets|Convolutional neural network]]

We have ''content image'' and ''style image'', and want to transfer the style into the content.

[[A Neural Algorithm of Artistic Style|http://arxiv.org/pdf/1508.06576v1.pdf]]

[[Pikazo - neural style video tech demo|https://www.youtube.com/watch?v=FzvTLEB_3KY]] [[Artistic style transfer for videos|https://www.youtube.com/watch?v=Khuj4ASldmU]]

[[Analogy-Driven 3D Style Transfer|https://www.youtube.com/watch?v=h0xF6R5MpyA]]

[[reddit discussion|https://www.reddit.com/r/MachineLearning/comments/3imx1m/a_neural_algorithm_of_artistic_style/]]

Code: [[code|http://gitxiv.com/posts/jG46ukGod8R7Rdtud/a-neural-algorithm-of-artistic-style]]

*[[neural-style|https://github.com/jcjohnson/neural-style]] for torch
* [[Neural style in TensorFlow|https://github.com/anishathalye/neural-style]] -- [["Neural Art" in TensorFlow|https://github.com/woodrush/neural-art-tf]]

[[Two Minute Papers - Deep Neural Network Learns Van Gogh's Art|https://www.youtube.com/watch?v=-R9bJGNHltQ&list=PLujxSBD-JXglGL3ERdDOhthD3jTlfudC2&index=6]]

Neural-style applied to videos too.

!!__Method__

# Step 1: [[Extract content targets|https://www.youtube.com/watch?v=GHVaaHESrlY&list=PL16j5WbGpaM0_Tj8CRmurZ8Kk1gEBc7fg&index=9#t=53m14s]], by passing content image through convnet, and record all raw activations in the convnet, which we say correspond to the "content" of the image.

# Step 2: [[Extract style targets|https://www.youtube.com/watch?v=GHVaaHESrlY&list=PL16j5WbGpaM0_Tj8CRmurZ8Kk1gEBc7fg&index=9#t=53m40s]]. Pass style image through convent, and look at pairwise statistics in style gram matrices. They have found these are good statistics for the style of an image. They are basically, for a certain convolutional layer of size nxn, and p features, the ~covariance of the features over the nxn space. That is take a particlar point in the nxn space and look at all p features. The vector of p features is called a fiber. Take the outer product of that vector with itself (which is like a covariance matrix), and average it over all points in the nxn space, can also be written in other ways using matrices.. Intuitively, it represents ''how often each pair of features fire together''. [[Could use other spatially-invariant statistics|https://www.youtube.com/watch?v=GHVaaHESrlY&list=PL16j5WbGpaM0_Tj8CRmurZ8Kk1gEBc7fg&index=9#t=1h20s]]

# [[Optimization of image step|https://www.youtube.com/watch?v=GHVaaHESrlY&list=PL16j5WbGpaM0_Tj8CRmurZ8Kk1gEBc7fg&index=9#t=55m45s]]. Loss consists of two terms:
##A content loss: match activations
## a style loss: match gram matrices

Best optimized with [[LBFGS|https://www.wikiwand.com/en/Limited-memory_BFGS]], because everything fits in memory, as only have one image..