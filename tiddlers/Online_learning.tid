created: 20170306160617394
creator: cosmos
modified: 20180713205218466
modifier: cosmos
tags: [[Learning theory]]
title: Online learning
tmap.id: 4c8d5d4b-c22d-4eb0-9e6a-9dd206b45c01
type: text/vnd.tiddlywiki


This takes the distribution-free bounds of [[Statistical learning theory]] and goes one step further, by assuming that the data does not necessarily follow a distribution at all. Instead we consider it //arbitrary// so that to obtain bounds on the [[Regret (Online learning)]], we need to consider the worst-case data.

[[lecture notes|http://courses.cs.washington.edu/courses/cse599s/12sp/scribes.html]] -- [ext[intro notes|http://sbubeck.com/BubeckLectureNotes.pdf]]

[[Other notes|http://www.cs.ox.ac.uk/people/varun.kanade/teaching/AML-HT2017/lectures/mistakebound-online.pdf]]

[[Prediction with expert advice]]

Can relate to [[Learning boosting]]

he essential difference be-tween online learning and statistical learning, in addition to the sequential aspect,is the fact that no probabilistic assumption is made on the dataset.

Online learnability (worst-case regret) is stronger (it implies) [[PAC learnability|Probably approximately correct]]

__[[Bandit problem]]__

An example of an online learning problem with //limited feedback//: instead of observing the adversary's action, we observe only the incurred loss in the case of bandits.

[[Multiarmed Bandits With Limited Expert Advice|http://www.jmlr.org/proceedings/papers/v35/kale14a.pdf]]

-------------------
----------------------

Adversarial online learning is about being probability-free, but solution requires stochastic agent, so needs probability at the end..

Is the usefulness of adversarial/agnostic analyses that they tend to imply non-worst case learnability often..?

Adversarial analysis of the agent. we have control over it. Doesn't make so much sense
