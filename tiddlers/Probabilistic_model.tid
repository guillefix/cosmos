created: 20160918223934834
creator: cosmos
modified: 20190515013308027
modifier: cosmos
tags: [[Probability theory]]
title: Probabilistic model
tmap.id: df0ed99c-e6a6-4a1c-86f9-141891ff170c
type: text/vnd.tiddlywiki

A [[Probability distribution]], which is used to [[model|Model]] some system, often with [[Uncertainty]]/[[Randomness]].

These models relate [[Random variable]]s, using some more or less general assumptions about the nature of the data.

[[Graphical model]]

[[Artificial neural network]]

See [[Machine learning]]

[[Generative model]] -- [[Deep generative model]]

[[Random-cluster model]]

----------------

Example of probabilistic modeling (particulary in [[Deep learning]] paradigm), using the [[DeepSaber]] project as example.

_technical outline of ML approach to beat saber problem_

* Supervised learning: song -> level
* But there are many levels that are good for a song
* Learn the probability distribution over beat-saber levels, conditioned on song
* We parametrize the distribution by a neural network with softmax output
* Train by Max Likelihood: find set of parameters that make the training data most likely.
* ''How do you even express a complicated distribution with a neural network?''
   ** Insert noise into it: GANs, normalizing flows
   ** Divide and conquer (autoregression)!. Decompose distribution into product of conditionals
   ** State space
* All of our approaches use autoregression over the sequence
* For each point in the sequence, we tried both GAN, and state space approach to express distribution over block states.