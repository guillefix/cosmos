created: 20160703120327871
creator: guillefix
modified: 20161104134329176
modifier: guillefix
title: Joint entropy
tmap.id: 820102d1-d74e-442e-b897-5de24c484096
type: text/vnd.tiddlywiki

In [[Information theory]], the ''joint entropy'' of a pair of [[Random variable]] $$X$$ and $$Y$$ is defined as:

$$H(X,Y) = \sum_{x,y} p(x,y) \log{p(x,y)}$$

[[Joint entropy|https://www.youtube.com/watch?v=6RJP5m3m1XA&index=7&list=PLJfu_xpF92pvTfcJAILr5Kg1ptMvHUnft#t=6m20s]]