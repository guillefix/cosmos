created: 20160709020525444
creator: guillefix
modified: 20170922125312219
modifier: cosmos
tags: [[Supervised classification]]
title: Logistic regression
tmap.id: e38fc94a-ff8d-4edd-8206-c8c5b38f1c01
type: text/vnd.tiddlywiki

A type of [[Classification]] method.

[[Logistic regression|https://www.youtube.com/watch?v=FYgsztDxSvE&list=PLjK8ddCbDMphIMSXn-w1IjyYpHU3DaUYw&index=7]] [[Definition|https://www.youtube.com/watch?v=FYgsztDxSvE&list=PLjK8ddCbDMphIMSXn-w1IjyYpHU3DaUYw&index=7#t=14m42s]]

See [[also here|https://www.youtube.com/watch?v=HZ4cvaztQEs&index=3&list=PLA89DCFA6ADACE599#t=50m]] for intro

__[[Probabilistic interpretation|https://www.youtube.com/watch?v=HZ4cvaztQEs&index=3&list=PLA89DCFA6ADACE599#t=57m17s]]__. Logitistic regression can also be interpretedas a [[Maximum likelihood]] estimate assuming the Logistic funciton (sigmoid) gives the probability of belonging to a given class. We can then use [[Gradient descent]]. More theoretical understanding can be acquired from the theory of [[Generalized linear model]]s

A simpler version: [[Perceptron]]

See [[here|http://www.cs.ox.ac.uk/people/varun.kanade/teaching/ML-MT2016/slides/slides08.pdf]]

[[Why is it convex|http://mathgotchas.blogspot.co.uk/2011/10/why-is-error-function-minimized-in.html]]

!!__Training__

Maximum likelihood. Log likelihood turns out to be cross-entropy.

To see if problem is convex, we test if the [[Hessian]] is positive semi-definite, and it is. See [[here|http://www.cs.ox.ac.uk/people/varun.kanade/teaching/ML-MT2016/slides/slides08.pdf]] for form of Hessian