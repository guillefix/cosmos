created: 20160328184231393
creator: guillefix
modified: 20180303130945779
modifier: cosmos
tags: [[Artificial neural network]]
title: Convolutional neural network
tmap.id: c6d7fec1-261c-4b1c-971c-06616c8b7b25
type: text/vnd.tiddlywiki

[[Nando's vid|https://www.youtube.com/watch?v=bEUX_56Lojc&list=PLjK8ddCbDMphIMSXn-w1IjyYpHU3DaUYw&index=10]]

http://cs231n.github.io/

http://cs231n.github.io/convolutional-networks/

http://cs231n.stanford.edu/syllabus.html

!!![ext[Convnet demo on the web!|http://scs.ryerson.ca/~aharley/vis/conv/]] [ext[details here|http://scs.ryerson.ca/~aharley/vis/]]

See [[this review|http://sci-hub.io/10.1109/msp.2017.2693418]] of [[Geometric deep learning]] for understanding why CNNs work, and other new related models

[[[MISS 2016] Andrea Vedaldi - Advanced Convolutional Neural Networks|https://www.youtube.com/watch?v=SceY4Xnz104]]

[[Spatial transformer network|https://arxiv.org/abs/1506.02025]] -- a variant to allow for more general invariances to spatial transformations of the data

-----------------------

[img[http://scs.ryerson.ca/~aharley/vis/images/convnet_480.png]]

[img[http://deeplearning.net/tutorial/_images/mylenet.png]]

''Convolution''

[[Convolutional arithmetic|https://github.com/vdumoulin/conv_arithmetic]] -- [[more explanation here|http://deeplearning.net/software/theano/tutorial/conv_arithmetic.html#transposed-convolution-arithmetic]] (includes deconv nets)

In The "c1 feature maps" are a set of 2D arrays of neurons. Each array looks for a feature, and a point in the array would represent the location of that feature. To accomplish this, that point of that array is connected to a set of pixels centered in the corresponding point in the input image (an array of pixels). We have much less parameters because for each of these 2D arrays we only specify the parameters for one of the neruons in that array, all other neurons are identical, just connected to displaced sets of pixels.

[[What is convolution|https://www.youtube.com/watch?v=bEUX_56Lojc&list=PLjK8ddCbDMphIMSXn-w1IjyYpHU3DaUYw&index=10#t=14m35s]]. [[Correlation|https://www.youtube.com/watch?v=bEUX_56Lojc&list=PLjK8ddCbDMphIMSXn-w1IjyYpHU3DaUYw&index=10#t=18m39s]]. Flip parameters vector (or array..) and rewrite the correlation, [[we get a convolution|https://www.youtube.com/watch?v=bEUX_56Lojc&list=PLjK8ddCbDMphIMSXn-w1IjyYpHU3DaUYw&index=10#t=21m50s]]. Of course, there's much more to [[convolutions|https://en.wikipedia.org/wiki/Convolution]], including the convolution theorem for e.g.

''Stride'' How much you jump in pixel space (or in previous layer) when you move from one point to another in a feature layer.

Can also expand boundary (//zero padding//) to keep layer gotten by convolution is of same size as original layer.

[[Nice example|https://www.youtube.com/watch?v=bEUX_56Lojc&list=PLjK8ddCbDMphIMSXn-w1IjyYpHU3DaUYw&index=10#t=27m06s]]

[[So many indices!|https://www.youtube.com/watch?v=bEUX_56Lojc&list=PLjK8ddCbDMphIMSXn-w1IjyYpHU3DaUYw&index=10#t=35m06s]]

''Pooling''

[[This is what it does|https://www.youtube.com/watch?v=bEUX_56Lojc&list=PLjK8ddCbDMphIMSXn-w1IjyYpHU3DaUYw&index=10#t=9m56s]]. It downsamples. For memory, and invariance (being more insesitive to perturbations).

We can also apply non-linearities in between layers of course, like for contours enhacement

Use as many of these layers Iconvolutions and poolings) as we can train, 20+ ([[Deep learning]])

At the end we may have a fully connected neural layer, to do the classification, but researchers are questioning if it is that useful..

We may [[visualize the features|https://www.youtube.com/watch?v=bEUX_56Lojc&list=PLjK8ddCbDMphIMSXn-w1IjyYpHU3DaUYw&index=10#t=13m30s]] in the feature maps by visualizing the matrices of parameters.

''MaxPooling'' coarse grains by chosing the maximum value in a certain patch of a few pixels. Nearby pixels are likely to be similar, and it is useful to distinguish between the same pattern been seen several times by the filter convolving around it, or several distinct repetitions of the pattern. Maxpool tries to solve for the former fake repetition..

!!!__Sentence ConvNets__

[[Vid|https://www.youtube.com/watch?v=bEUX_56Lojc&list=PLjK8ddCbDMphIMSXn-w1IjyYpHU3DaUYw&index=10#t=44m55s]]

Sentence DynConvNet

Document models (Misha Denil)

[[Natural language processing]]

[[MatConvNet: CNNs for MATLAB|http://www.vlfeat.org/matconvnet/]]

!!![[explanation vid|https://www.youtube.com/watch?v=7Wq-QmMT4gM]]

-----------------

!!__[[Understanding and visualizing CNNs|https://www.youtube.com/watch?v=GHVaaHESrlY&list=PL16j5WbGpaM0_Tj8CRmurZ8Kk1gEBc7fg&index=9]]__

[[Look at the raw activations|https://www.youtube.com/watch?v=GHVaaHESrlY&list=PL16j5WbGpaM0_Tj8CRmurZ8Kk1gEBc7fg&index=9#t=2m30s]]

[[Look at weights|https://www.youtube.com/watch?v=GHVaaHESrlY&list=PL16j5WbGpaM0_Tj8CRmurZ8Kk1gEBc7fg&index=9#t=3m25s]]

[[Visualizing the representation|https://www.youtube.com/watch?v=GHVaaHESrlY&list=PL16j5WbGpaM0_Tj8CRmurZ8Kk1gEBc7fg&index=9#t=5m25s]] can use [[t-SNE]] to visualize

[[Occlusion experiments|https://www.youtube.com/watch?v=GHVaaHESrlY&list=PL16j5WbGpaM0_Tj8CRmurZ8Kk1gEBc7fg&index=9#t=8m38s]]

[[Deep Visualization Toolbox|https://www.youtube.com/watch?v=AgkfIQ4IGaM]] -- [[code|https://github.com/yosinski/deep-visualization-toolbox]]

!!![[Deconv approach|https://www.youtube.com/watch?v=GHVaaHESrlY&list=PL16j5WbGpaM0_Tj8CRmurZ8Kk1gEBc7fg&index=9#t=15m35s]]
[[Guided backpropagation|https://www.youtube.com/watch?v=GHVaaHESrlY&list=PL16j5WbGpaM0_Tj8CRmurZ8Kk1gEBc7fg&index=9#t=18m45s]] is like ReLu backwards, only [[backpropagating|Backpropagation]] positive gradients.

[[Deconvnets|https://www.youtube.com/watch?v=GHVaaHESrlY&list=PL16j5WbGpaM0_Tj8CRmurZ8Kk1gEBc7fg&index=9#t=26m40s]]

!!![[Optimization method|https://www.youtube.com/watch?v=GHVaaHESrlY&list=PL16j5WbGpaM0_Tj8CRmurZ8Kk1gEBc7fg&index=9#t=29m40s]]

[[They look pretty funny|https://www.youtube.com/watch?v=GHVaaHESrlY&list=PL16j5WbGpaM0_Tj8CRmurZ8Kk1gEBc7fg&index=9#t=31m25s]]

[[Combine with grabcut|https://www.youtube.com/watch?v=GHVaaHESrlY&list=PL16j5WbGpaM0_Tj8CRmurZ8Kk1gEBc7fg&index=9#t=34m30s]] [[segmentation|Image segmentation]] algorithm to cut out the important part of an image

[[can do optimization for any neuron|https://www.youtube.com/watch?v=GHVaaHESrlY&list=PL16j5WbGpaM0_Tj8CRmurZ8Kk1gEBc7fg&index=9#t=35m20s]]. There are better ways of regularizing for images, they do it indirectly (kind of like [[Dropout]]), by blurring.

[[How much can you reconstruct an image from the code|https://www.youtube.com/watch?v=GHVaaHESrlY&list=PL16j5WbGpaM0_Tj8CRmurZ8Kk1gEBc7fg&index=9#t=40m]]

[[Deep dream]]

[[Neural style]]

!!!__Stability to local input perturbations__

if one specifies the convolutional tensors to be complex wavelet decomposition operators and uses complex modulus as pointwise nonlinearities, one can provably obtain stability to local deformations [ext[(17)|https://www.di.ens.fr/~mallat/papiers/ScatCPAM.pdf]] . Although this stability is not rigorously proved for generic compactly supported convolutional tensors, it underpins the empirical success of CNN architectures across a variety of computer-vision applications [1] . See [[here|http://sci-hub.io/10.1109/msp.2017.2693418]]
.

---------------------------------

[[Genetic CNN|https://arxiv.org/pdf/1703.01513.pdf]]


[[Densely Connected Convolutional Networks|https://arxiv.org/pdf/1608.06993.pdf]]