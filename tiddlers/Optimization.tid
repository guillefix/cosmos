created: 20160221181117472
creator: guillefix
modified: 20171128232227647
modifier: cosmos
tags: Engineering [[Scientific computing]] [[Operations research]] [[Mathematical methods]]
title: Optimization
tmap.id: 000eeacd-eb46-40ca-a38b-1d78a2c89866
type: text/vnd.tiddlywiki

https://en.wikipedia.org/wiki/Mathematical_optimization

https://en.wikipedia.org/wiki/Optimization_%28disambiguation%29

,,[ext[oxford course|http://mpawankumar.info/teaching/cdt-optimization.html]],,

http://www.benfrederickson.com/numerical-optimization/

-----------

$$\min\limits_{x \in X} f(x)$$

* ''Continuous otpimization''. The space $$X$$ over which you are optimizing is continuous
* ''Discrete optimization''. The space $$X$$ over which you are optimizing is discrete. [[Good book|http://www.designofapproxalgs.com/]]

!__[[Continuous optimization]]__

Good learning resource: [ext[book + lectures|http://stanford.edu/~boyd/cvxbook/]].

!!!__Unconstrained and constrained optimization__

$$\min\limits_{x \in X} f(x)$$

See [[intro slides|http://mpawankumar.info/teaching/cdt-optimization/lecture1_1.pdf]]. Often $$X = R^n$$ an n-dimensional real number space.

''Constrained optimization'' refers to optimization where the optimization space is some subspace of an "underlying space". This is a bit arbitrary, but the underlying space is most often assumed to be $$R^n$$ and the constraints then define a subset of $$R^n$$ through inequalities and equalities.

!!__[[Constrained optimization]]__

//All of these are mostly refering to continuous optimization//

[[wiki|https://www.wikiwand.com/en/Constrained_optimization]] -- [ext[notes|http://www1.maths.leeds.ac.uk/~cajones/math2640/notes4.pdf]] -- [ext[notes2|http://www.stat.cmu.edu/~cshalizi/statcomp/14/lectures/18/lecture-18.pdf]]

!!!--__Optimization problem with inequality constraints__

A //mathematical optimization problem//, or ''optimization problem''.

[img[http://i.imgur.com/BwndXEY.jpg]]

One can also have equality constraints, apart from inequalities.

!!!__Primal and dual problem and KKT conditions__

[[Andrew Ng video|https://www.youtube.com/watch?v=s8B4A5ubw6c&index=7&list=PLA89DCFA6ADACE599#t=23m30s]] -- [[General optimization problem|https://www.youtube.com/watch?v=s8B4A5ubw6c&index=7&list=PLA89DCFA6ADACE599#t=27m]] -- [[Dual problem|https://www.youtube.com/watch?v=s8B4A5ubw6c&index=7&list=PLA89DCFA6ADACE599#t=34m30s]], uses [[Max–min inequality]]. [[Conditions for the primal and dual problems being equivalent|https://www.youtube.com/watch?v=s8B4A5ubw6c&index=7&list=PLA89DCFA6ADACE599#t=39m]] (includes [[Karush–Kuhn–Tucker conditions|https://www.wikiwand.com/en/Karush%E2%80%93Kuhn%E2%80%93Tucker_conditions]])

Has applications in [[Support vector machine]]s. The reasons we use the dual problem is that it has many useful properties, I think it is convex?

!!!__[[Linear programming]]__: [[Linear|Linearity]] objective and constraint functions.

Used in [[Operations research]]. Can be used to solve (either exactly or approximately) some discrete optimization problems. See [[Linear programming relaxation]]

!!!__''Nonlinear programming''__

Objective and constraint functins are non-linear. Some special cases:

* [[Convex optimization]]. Generalizes linear programming.
* [[Quadratic programming]]
** [[Least-squares]]

Often for global nonlinear optimization, we need to use brute force methods, with [[Computational complexity]] exponential in the dimension of th optimzation space (space of optimization variables). For approximate but faster solutions, we can use local optimizal optimization, or heuristics.

!!!__[[Lagrange multiplier]] method__

http://mat.gsia.cmu.edu/classes/QUANT/NOTES/chap4/node6.html

Good explanation of inequality constraints using an extension of Lagrange multipliers. Think of planes in 3D as constraint surfaces for intuition on equation! Delta f should be perpendicular to hypersurface defined by constraints.

!__[[Discrete optimization]]__

!!!__Discrete optimizatino using energy minimization__

Can formulate discrete optimization as an [[Energy minimization|http://mpawankumar.info/teaching/cdt-optimization/lecture2_2.pdf]] problem on a set of random variables which can take values in a discrete set. This can be formulated as a [[Graphical model]]. [[Energy-based model]], [[Ising model]]..

!!!__[[Linear programming relaxation]]__

!!--__[[Local optimization]]__

{{Local optimization}}

[[More things on optimization|https://www.youtube.com/watch?v=0qUAb94CpOw&list=PLjK8ddCbDMphIMSXn-w1IjyYpHU3DaUYw&index=6#t=56m20s]]

-------------

!!--__[[Heuristic optimization]]__

[[Evolutionary computing]]

[[Artificial intelligence]]?

-----------

!!!__Hyperoptimization__

[[Gradient-based Hyperparameter Optimization through Reversible Learning|http://arxiv.org/abs/1502.03492]]

----------------


[[Probabilistic programming|http://probabilistic-programming.org/wiki/Home]]

See links [[here|https://en.wikipedia.org/wiki/Multidisciplinary_design_optimization#Problem_solution]]

[[Memetic algorithm|https://en.wikipedia.org/wiki/Memetic_algorithm]]

[[Evolutionary computing]]

!!![[Simulated annealing|https://en.wikipedia.org/wiki/Simulated_annealing]] ! [ext[http://www.mit.edu/~dbertsim/papers/Optimization/Simulated%20annealing.pdf]]

https://en.wikipedia.org/wiki/Inferential_programming

------------

!!__Applications__

Many applications in [[Science]], [[Engineering]], [[Statistics]]... 

* [[Portfolio theory]]

* [[Electronic design]]

* [[Machine learning]] (data fitting, in particular)

* [[Computational geometry]]

----------------------

[[Can we measure the difficulty of an optimization problem?|http://ieeexplore.ieee.org/abstract/document/6970853/]]