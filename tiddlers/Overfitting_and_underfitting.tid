created: 20160914090135656
creator: cosmos
modified: 20161104134331350
modifier: cosmos
title: Overfitting and underfitting
tmap.id: 784308cf-055f-4b69-9343-ad16abe3df0b
type: text/vnd.tiddlywiki

Overfitting and underfitting refer to ways of misstraining a model, i.e., making it have poor generalization error, compared to the optimal model.

[[Bias-variance tradeoff|https://www.youtube.com/watch?v=tojaGtMPo5U&list=PLA89DCFA6ADACE599&index=9#t=4m1.5s]], see also [[Relation to bias/variance tradeoff|https://www.youtube.com/watch?v=tojaGtMPo5U&list=PLA89DCFA6ADACE599&index=9#t=1h03m40s]]

[[training error/generalization error|https://www.youtube.com/watch?v=tojaGtMPo5U&list=PLA89DCFA6ADACE599&index=9#t=1h08m20s]]

''Underfitting''. A learning algorithm with a lot of ''bias'', meaning that they impose a lot of a priori structure/assumptions to the fitted functions. These, however, tend to have low ''variance'', meaning that the fitted function doesn't tend to vary much when different training data sampled from the same process are used, they are //stable//

''Overfitting''. A learning algorithm with low bias (it is more //flexible//), which however has a lot of variance, as it fits the idiosyncrasies of the data; it fits the noise.

[[See explanation here|https://www.youtube.com/watch?v=JfkbyODyujw&list=PL6Xpj9I5qXYEcOhn7TqghAJ6NAPrNmUBH&index=14#t=6m45s]] and [[here|https://www.youtube.com/watch?v=Fs-raHUnF2M&list=PL6Xpj9I5qXYEcOhn7TqghAJ6NAPrNmUBH&index=16#t=9m05s]]

[img[https://lh3.googleusercontent.com/1vNipHvUofw7v2XurbRcoKWdrha4XwW2Wg6iv_CjnPJ7yaJeLuOGPHEXP5r0bHiXDa5jXmi3gXWzRs-rnOmoWT2qdrpDlhqoPaINOW1e8wCnkcMmsfjL5I7MAnuysZNkA0ZS-AduSU6My_vj8QjrLwgU7PtqeOxEmOHYOzJMm1COtI55peywxXwYc4Ot0XMg3WSk4ctE620Fg-kQuA8Zw86ejVU0wPx4C6f-yYJYDol4KmH_zV43EJREoK0ZJaU0v4j54Luq0_enrS9FA4oPcWX5v4h6hTCXJq3aubFRI-HBAP0Az3Js3cA9ZxPQV0U-1MZBCEdfI-0b87bEVSEAvZ7vsWTfyadsG43bfwc8ZGr4XRhXWYVlGj48WxrpQyTPFhPQMXNoiRURzx5bm4ZHukhomdEE98JJ4c5XqhybUHdIk6qJbUS7BXjcYaBlm3z8bGiBlPtDSdt61a59mbotPi7DS3N-LdHrHUd3PXtG59t_5fHfKi3WpqNS_dJOefgRukPJ0OAK4fE579XHNw_8l0Fi2mAqsP7Y8WNm1lg8yXQI2c6hrlGzWt2jO_4it_Zef_2r=w1269-h675-no]]

[[Deep Learning Lecture 5: Regularization, model complexity and data complexity (part 2)|https://www.youtube.com/watch?v=qz9bKfOqd0Y&index=5&list=PLjK8ddCbDMphIMSXn-w1IjyYpHU3DaUYw#t=25m43s]]

So the simplest model that works seems to work best most of the time. Seems like an example of Occam's razor, and thus related to Solomonoff's ideas on inference (see [[Algorithmic information theory]]). Epicurus principle also related to Bayesian inference, because we give a distribution over models, but we keep all of them.

Hmm, also your error can't be smaller than the fundamental noise in the data. Well it can, but your model will at best be wasteful then.