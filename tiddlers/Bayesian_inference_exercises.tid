created: 20161102152518531
creator: cosmos
modified: 20161104134327098
modifier: cosmos
title: Bayesian inference exercises
tmap.id: 70b31386-94d6-4cd4-8358-3f7ff0226091
type: text/vnd.tiddlywiki

See [[Bayesian inference]]

!!1. Dodgy coins

1.1 $$P(C|H) \propto P(H|C)$$

0.75+0.5+0.25=1.5

1.2 [[Maximum likelihood]] estimate is $$C=1$$

1.3 $$P(C=c|X=H) = \frac{P(X=H \cap C=c)}{P(X=H)}\propto P(X=H \cap C=c) =P(X=H | C=c) \times P(C=c) $$

1.4 & 1.5 Using [[Baye's theorem]]

|C|likelihood|prior|likelihood x prior| posterior|
|1|0.75|1/3|3/4 x 1/3 = 1/4|$$\frac{1/4}{1/2}=1/2$$|
|2|0.5|1/3|1/2 x 1/3 = 1/6|$$\frac{1/6}{1/2}=1/3$$|
|3|0.25|1/3|1/4 x 1/3 = 1/12|$$\frac{1/12}{1/2}=1/6$$|
||||$$P(X=H) = 3/12 + 2/12+1/12 = 6/12 = 1/2$$||

$$1/2 + 1/3 + 1/6 = 3/6+2/6+1/6 = 1$$

1.6 

|C|likelihood|prior|likelihood x prior| posterior|
|1|$$0.75^2$$|1/3|3/4 x 3/4 x 1/3 = 3/16|$$\frac{3/16}{7/24}=9/14$$|
|2|$$0.5^2$$|1/3|1/2 x 1/2 x 1/3 = 1/12|$$\frac{1/12}{7/24}=4/14$$|
|3|$$0.25^2$$|1/3|1/4 x 1/4 x 1/3 = 1/48|$$\frac{1/48}{7/24}=1/14$$|
||||<small>$$P(X=H) = 9/48 + 4/48+1/48 = 14/48 = 7/24$$</small>||

1.7 

0.11111... use [[this|http://stattrek.com/online-calculator/bayes-rule-calculator.aspx]]

P( C=1|H ) = 0.111111111111111

P( C=2|H ) = 0.37037037037037

P( C=3|H ) = 0.518518518518518. Maximum a posteriori

$$P(\tilde{X}=H|X=H) = 0.75\times 1/2 + 0.5 \times 1/3 + 0.25 \times 1/6 $$ $$= 3/8 + 1/6 + 1/24 = 9/24+4/24+1/24 =14/24=7/12$$

$$P(\tilde{X}=T|X=H) = 5/12$$

1.10 
$$P(\tilde{X}=H|X=H) = \sum\limits_{C=1}^r P(\tilde{X} \cap C | X=H) = \sum\limits_{C=1}^r P(\tilde{X} | C \cap  X=H) \times P(C | X=H)$$ $$= \sum\limits_{C=1}^r P(\tilde{X} | C) \times P(C | X=H)$$

!!2. The [[Epidemiology]] of Lyme disease

2.1 [[Binomial distribution]] as likelihood of number of ticks with Borrelia bacteria is reasonable because it's the prob dist if the probability of each tick having the bacteria is the same, and they are independent.

2.2

$$L(X_i | \theta) = \binom{n}{X_i} \theta^{X_i} (1-\theta)^{n-X_i}$$

n=10

2.3 

$$10 \theta (1-\theta)^{9}$$

https://www.wolframalpha.com/input/?i=10+theta+(1-%5Ctheta)%5E%7B9%7D

$$\theta \approx 0.1$$ is MLE

2.4 

https://www.wolframalpha.com/input/?i=integrate+10+q(1-q)%5E%7B9%7D+from+q%3D+0+to+1

2.5

https://www.wolframalpha.com/input/?i=binomial+distribution+with+p%3D0.1,+n%3D10

[img[https://s11.postimg.org/o4kfvny4z/IMG1.png]]

2.6

$$\frac{d}{d\theta} \log{L(X|\theta)} = 0$$

$$\frac{d}{d\theta} \log{ \binom{n}{X_i} \theta^{X_i} (1-\theta)^{n-X_i}} = \frac{d}{d\theta} \left[ \log{ \binom{n}{X_i} } +  X_i \log{ \theta} + (n-X_i)  \log{ (1-\theta)} \right] $$ $$ 0 + \frac{X_i}{\theta} - \frac{(n-X_i)}{(1-\theta)} = 0$$

$$ X_i - X_i  \theta = \theta n - \theta X_i$$

$$ X_i = \theta n$$ => 
$$ \theta = \frac{X_i}{n} = \frac{X_i}{10} $$

2.7 

[[Beta distribution]] as [[Prior distribution]]

Plot this on RStudio!

2.8

The expected value (mean) (μ) of a Beta distribution random variable X with two parameters α and β is a function of only the ratio β/α

[img[https://wikimedia.org/api/rest_v1/media/math/render/svg/3905662ceed484cba5580951e29eda96f4d2605e]]

2.9

$$Beta(a, b) = \frac{\Gamma(a+b)}{\Gamma(a)\Gamma(b)}\, \theta^{a-1}(1-\theta)^{b-1}$$

$$\binom{n}{X_i} \theta^{X_i} (1-\theta)^{n-X_i} \frac{\Gamma(a+b)}{\Gamma(a)\Gamma(b)}\, x\theta^{a-1}(1-\theta)^{b-1} = \frac{\Gamma(n+1)}{\Gamma(n+1-X_i)\Gamma(X_i+1)} \frac{\Gamma(a+b)}{\Gamma(a)\Gamma(b)}\, \theta^{X_i +a - 1} (1-\theta)^{n-X_i +b -1} $$ $$ \propto  \theta^{X_i +a - 1} (1-\theta)^{n-X_i +b -1} $$, which is propto $$Beta(X_i1+a, n-X_i+b)$$

See [[wiki|https://en.wikipedia.org/wiki/Gamma_function]]

