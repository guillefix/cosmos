created: 20160709004653144
creator: guillefix
modified: 20170521165849452
modifier: cosmos
tags: [[Statistical inference]] Learning [[Artificial intelligence]] [[Machine learning]]
title: Learning theory
tmap.id: fde229eb-00fc-4002-98bb-ad7a1dcce373
type: text/vnd.tiddlywiki

//the general field of computational learning theory, statistical learning theory, etc; note that these have slightly different connotations//

Mathematical theory of learning, and learning algorithms. See [[Machine learning]], [[Deep learning theory]], [[wiki|https://www.wikiwand.com/en/Computational_learning_theory]].

''Learning problem'': Design a system that improves on its ability to perform task T, as measured by performance measure P, by going through experience E.

!!__Types of learning problem__

Some important types:

* [[Supervised learning]]
* [[Unsupervised learning]]
* [[Reinforcement learning]]
* [[Statistical inference]]
** [[Causal inference]]
* [[Inverse problem]]
** [[Linear inverse problem]]

See more at [[Machine learning]], and [[Computational learning theory]]

<b>Most of the topics below apply to [[Supervised learning]], which is the most common learning problem in practice.</b>

!__Principles of learning algorithms__

!!__Risk minimization__

If one defines a [[Loss function]] (or ''risk'', or ''cost'', see [[Decision theory]]), $$R_f (\hat{y}, y)$$, one can ask what is the prediction scheme (for instance, the function $$\hat{y} = f(x)$$ that minimizes the expected risk. This is called risk minimization. 

!!!__Generalization/prediction__

[[Making good generalizations is the goal of predictive/supervised learning|https://www.youtube.com/watch?v=tojaGtMPo5U&list=PLA89DCFA6ADACE599&index=9#t=17m45s]], where ''generalization'' means 
making predictions about unseen data from seen data, and good generalization means these predictions agree with the actual results, as often as possible. See also [[Induction]].

For the case of 0-1 loss functions, the expected risk is also known as ''generalization error'', $$\epsilon$$, [[defined as|https://www.youtube.com/watch?v=tojaGtMPo5U&list=PLA89DCFA6ADACE599&index=9#t=18m10s]] the probability that if I sample a new sample $$(x,y)$$ from the same distribution producing the data, my hypothesis misslabels that example.

!!!__[[Empirical risk minimization]]__

Risk minimization, requires knowing the joint probability distribution $$P(x,y)$$, so one often uses the sample mean of the risk as an estimator for the expected value of the risk. Minimizing this empirical quantity is called empirical risk minimization.

The empirical risk, for a 0-1 loss function is also known as ''training error'' $$\hat{\epsilon}$$, which is just the fraction of training points that your hypothesis missclassifies. See [[Training error (vid)|https://www.youtube.com/watch?v=tojaGtMPo5U&list=PLA89DCFA6ADACE599&index=9#t=11m]]

!!__[[Maximum likelihood]]__

Minimize the negative log [[likelihood|Likelihood function]] (similar to entropy. More precisely, cross-entropy, or relative entropy), which corresponds to ''maximizing likelihood''.

!!!__[[Maximum a posteriori]] (MAP)__

!!__[[Bayesian expectation|Bayesian statistics]]__


!!__Design factors in machine learning__

[img[machine_learning_design_factors.png]]


!!__[[Overfitting and underfitting]]__

Overfitting and underfitting refer to ways of misstraining a model, i.e., making it have poor generalization error, compared to the optimal model.

[[Bias-variance tradeoff|https://www.youtube.com/watch?v=tojaGtMPo5U&list=PLA89DCFA6ADACE599&index=9#t=4m1.5s]]

''A lot of the theory below is about dealing with the issues of overfitting and underfitting, so as to train the model as well as possible''.

!__[[Convergence and performance results in learning theory]]__

See more at [[Computational learning theory]]!

Mostly about general bounds, that often are pessimistic because they have to include worst cases, but give good intuition of general relations, for instance, between training set size and model complexity.

-->[[Theorem|https://www.youtube.com/watch?v=0kWZoyNRxTY&index=10&list=PLA89DCFA6ADACE599#t=17m15s]]. Let a hypothesis class $$H$$ be given, and let the [[VC dimension]] VC(H) = d. Then w.p. at leat$$1-\delta$$, we have that for all $$h \in H$$

$$|\epsilon(h)-\hat{\epsilon}(h)|\leq O\left(\sqrt{\frac{d}{m}\log{\frac{m}{d}}+\frac{1}{m}\log{\frac{1}{d}}}\right)$$

where $$m$$ is the size of the training set. A corollary is that for ERM, the number of training samples needed for a particular performance is roughly linear on the [[VC dimension]] of the hypothesis class (see [[video|https://www.youtube.com/watch?v=0kWZoyNRxTY&index=10&list=PLA89DCFA6ADACE599#t=22m]]). ''Sample complexity is upper bounded by VC dimension''.

!__[[Model selection/assessment|Model selection]]__

Model selection algorithms provide methods to automatically choose optimal bias/variance tradeoffs. 

* [[Cross-validation]]

* [[Feature selection]]

!__[[Bayesian statistics]]__



!!__[[Regularization]]__

A different way to avoid overfitting, while keeping all parameters in your model.
[[Intro vid|https://www.youtube.com/watch?v=sQ8T9b-uGVE&list=PLA89DCFA6ADACE599&index=11#t=1m]]

We use the [[Prior distribution]] from [[Bayesian statistics]], to make [[simple|Simplicity]] hypothesis more likely. See [[Simplicity and learning]].

[[Intuition|https://www.youtube.com/watch?v=sQ8T9b-uGVE&list=PLA89DCFA6ADACE599&index=11#t=12m]]

!__[[Computational learning theory]]__

* [[Probably approximately correct]]

--------------------

!__[[Optimization for learning]]__

!__[[Statistical physics and inference]]__

-------------------

[[Adaptive resonance theory|https://en.wikipedia.org/wiki/Adaptive_resonance_theory]]
The primary intuition behind the ART model is that object identification and recognition generally occur as a result of the interaction of 'top-down' observer expectations with 'bottom-up' sensory information. The model postulates that <b>'top-down' expectations take the form of a memory template or prototype that is then compared with the actual features of an object as detected by the senses</b>. This comparison gives rise to a measure of category belongingness. As long as this difference between sensation and expectation does not exceed a set threshold called the 'vigilance parameter', the sensed object will be considered a member of the expected class. The system thus offers a solution to the 'plasticity/stability' problem, i.e. the problem of acquiring new knowledge without disrupting existing knowledge.

[[Learning theory and neural networks gingko tree|https://gingkoapp.com/vehvff]]

------------------

!!__General/worst-case analysis vs specific case analysis of learning__

[img[specific_case_learning_theory.jpg]]

quite relevant for [[Deep learning theory]]
