created: 20160629171233090
creator: guillefix
modified: 20170522193932847
modifier: cosmos
tags: Complexity
title: Kolmogorov complexity
tmap.id: 42fc93ab-283d-41bb-a9d4-0c9266a47138
type: text/vnd.tiddlywiki

,,//aka algorithmic complexity, although that term may refer to some generalizations of Kolmogorov complexity too, I think//,,

One of the main kinds of [[Descriptional complexity]], based on the minimum size of a program (interpreted by a [[Turing machine]]) that produces (//describes//) the object.

Kolmogorov complexity is central in [[Algorithmic information theory]]. __See more in that page__

[[Math 574, Lesson 4-3: Kolmogorov Complexity|https://www.youtube.com/watch?v=S31CbvpZBU4]]
[[other video intro|https://www.youtube.com/watch?v=HWsa_hZ7F3I#ft=28m10s]]

This is based on describing the information content of a discrete object such as a binary string $$x$$ in terms of the length of the shortest program that generates $$x$$ on universal Turing machine (UTM). This measure is called the Kolmogorov-Chaitin complexity or simply ''Kolmogorov complexity'' $$K(x)$$ of $$x$$.

AIT differs fundamentally from Shannon information theory because the latter is fundamentally a theory about distributions, whereas the former is a theory about the information content of individual objects. Descriptional complexity also differs simplcitly with the notions of complexity in [[Complex systems]].

[ext[Lecture notes on descriptional complexity and randomness|http://www.cs.bu.edu/~gacs/papers/ait-notes.pdf]]

--> [[Calculating Kolmogorov Complexity from the Output Frequency Distributions of Small Turing Machines|http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0096223]] See [[Coding theorem method]]

!!!__Invariance theorem__

See [[Algorithmic information theory]]

Based on defining an ''optimal compressor'', which turns out to be realizable by a "reasonable" [[Universal Turing machine]], if we restrict ourselves to [[computable functions|Computability theory]] (if we consider all functions, there are no optimal compressors). This is a compressor that is able to describe any string by a description that is never longer than that produced by other compressor __by more than an additive constant__.

This defines a hierarchy. The bottom of the hierarchy (optimal compressors) is not unique, as there are an infinite number of additively equivalent UTMs. Therefore, KC is well defined, but only up to an additive constant! This is the content of the invariance theorem.

This is shown by showing that any UTM can simulate any other UTM, by only adding a fixed number of bits (analogous to a [[Compiler]]). However, this number of bits itself depends on the particular way of enumerating Turing machines used, but it can be shown that the invariance theorem still holds as long as the enumerations are computable (analogous to the notion of //acceptable numberings// in de Mises definition of [[Randomness]]).

!!!__Two-part codes__

One can equivalently define KCs as the minimum description of the form "description of Turing machine"+"program such that when read by that Turing machine it produces x". It can be shown that any minimal program can be written in that way. This is just like a reinterpretation of KC..

!!!__Bounds___

$$C(x) \leq l(x) + c$$ and $$C(x|y) \leq C(x) + c$$

$$C(x,y) \leq C(x) + C(y)  + 2\log{(\min{(C(x),C(y))})}+O(1)$$, but also $$C(x,y) \geq C(x) + C(y) + \log{n} -c$$ for some $$c$$

$$C(x) < C(y) + C(x|y) + O(log(C(x))$$ ([[chain rule|https://www.wikiwand.com/en/Chain_rule_for_Kolmogorov_complexity]])

$$C(x^*|x) \leq \log{l(x)}$$, where $$x^*$$ is the first shortest program producing $$x$$. Note that even though $$x\rightarrow x^*$$ is a function, it is not a computable function, and so it actually requires extra information to computably produce $$x^*$$ given $$x$$! //Nice//

$$C(x) \leq \log{|A|} + c$$, when $$x\in A$$, and $$A$$ is a computable set.

There are at least $$m(1-2^{-c})+1$$ elements in $$x\in A$$ with $$C(X) \geq \log{m} -c $$, where $$m=|A|$$.

C is nonmonotonic on prefixes, that is we can have C(y) > C(x), where y is a proper prefix of x. This could be because the length of x is some special number, while the length of y is a very complex number.. //the complexity of a part can turn out to be bigger than the complexity
of the whole.// $$C(x|l(x))$$ turns out to also be nonmonotonic on prefixes.

!!!__Computability of KC__

KC is not computable, but it is [[semi lower computable|Semicomputable function]], meaning  it can be approximated from above, for example, via lossless compression algorithms.. See [[Computability theory]], and "Li, M.; Vitanyi, P. An Introduction to Kolmogorov Complexity and Its Application", for formal proofs.

__Computable approximations to KC__

Levin complexity

[[Data compression]] rate

!!!__Paucity theorems__

Simple strings (paucity) are rare among all possible strings

[[The frequent paucity of trivial strings|http://sci-hub.bz/10.1016/j.ipl.2014.05.006]]

--------------------------

Kolmogorov complexity is not subadditive, meaning, that __there are__ x and y such that C(x,y) > C(x)+C(y)

---------------

[[ A Computable Measure of Algorithmic Probability by Finite Approximations|http://arxiv.org/abs/1504.06240]]

See [[MMathPhys oral presentation]]

__Deficiencies of KC__

[img[http://i.imgur.com/Eyx7L1A.png]]

from [ext[here|https://cs.uwaterloo.ca/~shallit/Papers/auto5.pdf]]

-----------------

[[Kolmogorov Complexity and Solovay Functions|https://arxiv.org/abs/0902.1041]]

[[On the Gaussianity of Kolmogorov Complexity of Mixing Sequences|https://arxiv.org/abs/1702.01317]]

---------

An use in AI [[here|http://saffrontech.com/tag/kolmogorov-complexity/]]