created: 20160709015859880
creator: guillefix
modified: 20170104130812965
modifier: cosmos
tags: [[Regression analysis]]
title: Nearest-neighbour classification
tmap.id: 9018ed64-ada7-469c-b9de-7de652c4f8bc
type: text/vnd.tiddlywiki

//aka KNN classifier//

Nearest-neighbor methods: To get the prediction Å¶ for a point $$x$$, use [those observations ($$k$$ of them) in the training set T, closest in input space to point x]. Remember training set is a set of pairs $$(x,y)$$. Closest often refers to Euclidean distance.

It turns out that the //effective number of parameters// of k-nearest neighbors is $$N/k$$, even if technically there is only one parameter, $$k$$.

 --> To me it seems more like a method in [[Nonparametric statistics]]! Indeed it is (see [[Wiki|https://en.wikipedia.org/wiki/Nonparametric_statistics#Non-parametric_models]]).

[[Classification w/ K Nearest Neighbors Intro - Practical Machine Learning Tutorial with Python p.13|https://www.youtube.com/watch?v=44jq6ano5n0&list=PLQVvvaa0QuDfKTOs3Keq_kaG2P55YRn5v&index=13]]

A KNN classifier with K=1 induces a [[Voronoi tessellation]]