created: 20161018183639198
creator: cosmos
modified: 20190331023956353
modifier: cosmos
tags: [[Generative model]]
title: Generative adversarial network
tmap.id: 517ed2dc-97df-437d-a5fe-096124b8f399
type: text/vnd.tiddlywiki

An architecture to train generative neural networks, i.e. [[neural networks|Artificial neural network]] which act as [[Generative model]]s, i.e. their inputs are [[Latent variable]]s, and their output is the observed data.

https://deephunt.in/the-gan-zoo-79597dc8c347 -- https://github.com/wiseodd/generative-models

[[NIPS tutorial|https://arxiv.org/pdf/1701.00160.pdf]]

[[GAN on browser|https://reiinakano.github.io/gan-playground/]]

example of GANs for discrete data: https://arxiv.org/pdf/1611.08408.pdf (in area of semantic segmentation) It's funny how people in NLP literature keep talking about how GANs are hard to make work for discrete data. Then, people in image segmentation literature (oblivious of all this?) successfully apply vanilla GANs to discrete data..

!!__Adversarial networks__

The way the network is trained is by having the generative network produce images, while training a different discriminative network to discriminate between real and generated images. In this way, the discriminative network can be used as a very good cost function, which penalized generated images which are distinguishably different from the real images that the generative network is train to model. E.g. for NLP literature stuff https://arxiv.org/abs/1611.04051?fbclid=IwAR0MOTB8nsV555rKdNb3EQ8pt-LbTKcxUHP_5ZC-of4zDGf_Et_uz1r39b4

We are in effect learning the cost function

[[video|https://www.youtube.com/watch?v=QPkb5VcgXAM#t=14m30]]

!!__Trining GANs__

[[NIPS 2016 Workshop on Adversarial Training - Soumith Chintala - How to train a GAN|https://www.youtube.com/watch?v=X1mUN6dD8uE]]

[[Trained|https://www.youtube.com/watch?v=QPkb5VcgXAM#t=18m05]] via [[Gradient descent]] and [[Backpropagation]]

I think that the discriminator needs to have a separate cost function which measures the number of images the discriminator missclassified as being real or generated. [[Discriminator is optimized to not be fooled by the generator|https://www.youtube.com/watch?v=QPkb5VcgXAM#t=19m47]]

On the other hand, the generative network uses the discriminative network as cost. [[Generator to fool discriminator, i.e. it is trained to maximize the mistakes the the discriminator does|https://www.youtube.com/watch?v=QPkb5VcgXAM#t=19m20]], that's why they are called ''adversarial''

The discriminator is //teaching// the generator, and it's adapting to the generator's knowledge and flaws. //Machine teaching//, not just machine learning.

!!!__Alternating [[Optimization]]__

[[video|https://www.youtube.com/watch?v=QPkb5VcgXAM#t=19m59]]

[[Improved Techniques for Training GANs|https://arxiv.org/abs/1606.03498]] [[vid|https://www.youtube.com/watch?v=QPkb5VcgXAM#t=45m30]]

!!__Theoretical properties__

If you have an optimal discriminator, the generator minimizes the [[Jensen-Shanon divergence]]

!!__Variants__

[[Original GANs were diffucult to train|https://www.youtube.com/watch?v=QPkb5VcgXAM#t=23m15]] 

!!!__Class-conditional GANs__

They are [[supervised|Supervised learning]]

[[Deep Generative Image Models using a Laplacian Pyramid of Adversarial Networks|https://arxiv.org/abs/1506.05751]] [[vid|https://www.youtube.com/watch?v=QPkb5VcgXAM#t=24m]]

!!!__Video-prediction GANs__

[[Deep multi-scale video prediction beyond mean square error|https://arxiv.org/abs/1511.05440]]
[[vid|https://www.youtube.com/watch?v=QPkb5VcgXAM#t=25m45s]]

!!!__DCGANs__

[[Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks|https://arxiv.org/abs/1511.06434]]

[[Latent space arithmetic|https://www.youtube.com/watch?v=QPkb5VcgXAM#t=30m30s]]

!!__In-painting GANs__

[[Context Encoders: Feature Learning by Inpainting|https://arxiv.org/abs/1604.07379]]

[[video|https://www.youtube.com/watch?v=QPkb5VcgXAM#t=39m05]]

!!__Applications__

!!!__[[Feature learning]] for [[Semi-supervised learning]]__

[[GANs for feature learning|https://www.youtube.com/watch?v=QPkb5VcgXAM#t=33m25]]. 

[[Two Minute Papers - Image Editing with Generative Adversarial Networks|https://www.youtube.com/watch?v=pqkpIfu36Os&list=PLujxSBD-JXgnqDD1n-V30pKtp6Q886x7e&index=108]]

!!!__Disentangling representations__

[[vid|https://www.youtube.com/watch?v=QPkb5VcgXAM#t=41m50s]]

[[InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets|https://arxiv.org/abs/1606.03657]] (from [[OpenAI]])

---------------

http://www.inference.vc/how-to-train-your-generative-models-why-generative-adversarial-networks-work-so-well-2/

They are similar to [[Autoencoder]]s but we learn the cost function, instead of just using l2 loss  ([[vid|https://www.youtube.com/watch?v=QPkb5VcgXAM#t=58m50]])

[[vid|https://www.youtube.com/watch?v=deyOX6Mt_As]]

[[Generative Adversarial Networks|https://arxiv.org/abs/1406.2661]]

https://www.wikiwand.com/en/Generative_adversarial_networks

[[the future|https://www.youtube.com/watch?v=QPkb5VcgXAM#t=51m20]]

[[Connecting Generative Adversarial Networks and Actor-Critic Methods|https://arxiv.org/abs/1610.01945]]

-----------------

More variations and others

URL list from Sunday, May. 21 2017 16:41 PM

To copy this list, type [Ctrl] A, then type [Ctrl] C. 

1603.08155.pdf
https://arxiv.org/pdf/1603.08155.pdf

1703.10593.pdf
https://arxiv.org/pdf/1703.10593.pdf

1610.09003.pdf
https://arxiv.org/pdf/1610.09003.pdf

RL Course by David Silver - Lecture 5: Model Free Control - YouTube
https://www.youtube.com/watch?v=0g4j2k_Ggc4&index=5&list=PL7-jPKtc4r78-wCZcQn5IqyuWhBZ8fOxT

Teaching
http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html

Lecture 1a - Introduction [Phil Blunsom] - YouTube
https://www.youtube.com/watch?v=RP3tZFcC2e8&list=PL613dYIGMXoZBtZhbyiBqb0QtgK6oJbpm

[1612.03242] StackGAN: Text to Photo-realistic Image Synthesis with Stacked Generative Adversarial Networks
https://arxiv.org/abs/1612.03242

[1703.06412] TAC-GAN - Text Conditioned Auxiliary Classifier Generative Adversarial Network
https://arxiv.org/abs/1703.06412

[1703.06676] I2T2I: Learning Text to Image Synthesis with Textual Data Augmentation
https://arxiv.org/abs/1703.06676

I2T2I: LEARNING TEXT TO IMAGE SYNTHESIS WITH TEXTUAL DATA AUGMENTATION
https://arxiv.org/pdf/1703.06676.pdf

Generative Adversarial Text to Image Synthesis
https://arxiv.org/pdf/1605.05396.pdf

Reed: Generative adversarial text to image synthesis - Google Scholar
https://scholar.google.co.uk/scholar?start=70&hl=en&as_sdt=0,5&sciodt=0,5&cites=8255440757806230750&scipsc=

Learning What and Where to Draw
http://papers.nips.cc/paper/6111-learning-what-and-where-to-draw

Generating Visual Explanations | SpringerLink
https://link.springer.com/chapter/10.1007/978-3-319-46493-0_1

[1609.09444] Contextual RNN-GANs for Abstract Reasoning Diagram Generation
https://arxiv.org/abs/1609.09444

[1702.03431] Crossing Nets: Dual Generative Models with a Shared Latent Space for Hand Pose Estimation
https://arxiv.org/abs/1702.03431

DISCO Nets : DISsimilarity COefficients Networks
http://papers.nips.cc/paper/6143-disco-nets-dissimilarity-coefficients-networks

[1704.06933] Adversarial Neural Machine Translation
https://arxiv.org/abs/1704.06933

[1702.04125] One-Step Time-Dependent Future Video Frame Prediction with a Convolutional Encoder-Decoder Neural Network
https://arxiv.org/abs/1702.04125

[1703.06029] Towards Diverse and Natural Image Descriptions via a Conditional GAN
https://arxiv.org/abs/1703.06029

cvpr17_summarization.pdf
http://web.engr.oregonstate.edu/~sinisa/research/publications/cvpr17_summarization.pdf

-------------------

http://make.girls.moe/
