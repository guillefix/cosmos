created: 20160810175348089
creator: cosmos
modified: 20161104134328547
modifier: cosmos
tags: [[Supervised learning]]
title: Generalized linear model
tmap.id: 2010fdde-2caa-404d-acef-f76f256b07e4
type: text/vnd.tiddlywiki

See part III in [[here|http://cs229.stanford.edu/notes/cs229-notes1.pdf]], [[video|https://www.youtube.com/watch?v=nLKOQfKLUks&index=4&list=PLA89DCFA6ADACE599#t=16m40s]]. [[video2|https://www.youtube.com/watch?v=nLKOQfKLUks&index=4&list=PLA89DCFA6ADACE599#t=38m27s]]

A generalization of [[Linear regression]], where $$p(y|x;\theta)=f (y;\theta^T x)$$. This means that the model output has the form $$h_\theta (x)=E [y|x;\theta]=g (\theta^T x)$$, i.e. the model is a function of the linear model, and the errors aren't necessarely Gaussian. Here $$g $$ is called the canonical response function

In GLM, a common family of probability distributions is the [[Exponential family distributions]]

https://www.wikiwand.com/en/Generalized_linear_model

Assumptions:

* $$y|x;\theta \sim \text{ExpFamily}(\eta)$$, for some chosen functions $$a$$ and $$b$$

* Given $$x$$, goal is to output $$E[T(y)|x]$$. Want $$h(x) = E[T(y)|x]$$. Therefore we're really learning a function (and thus this is an example of [[Regression|Regression analysis]]). However, $$y$$ itself can be categorical, so GLM can be applied to [[Classification]].

* ,,(assumption/design choice),, $$\eta = \theta^T x$$.

Note that $$\eta $$ can be a vector (as in the multinomial example below), in which case $$\theta $$ is a matrix.

__Example__:

Min 43 of lect4 (Ng)

Classification with Bernoulli distribution (parametrized by $$\eta $$) ([[Logistic regression]])

Regression with Gaussian distribution (the mean being $$\eta $$) ([[Linear regression]]).

Classification over $$k $$ categories with multinomial distribution (min 52, lec4 (Ng))

