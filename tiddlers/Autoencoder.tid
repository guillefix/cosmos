created: 20160919105809475
creator: cosmos
modified: 20161104134327010
modifier: cosmos
tags: [[Unsupervised learning]]
title: Autoencoder
tmap.id: 63d48e35-fd03-4a90-9c31-9ba6a9ac0aee
type: text/vnd.tiddlywiki

A type of [[Artificial neural network]] where the output has the same dimensionality as the input, and the network is train to be able to reproduce the output in the input. The key point is that there is an ''information bottleneck'' in some of the hidden layers, where the number of neurons is limited, so that the network is forced to learn a ''sparse representation'' of the data. For this reason, they can be used for [[Data compression]], and other areas where such a representation may be useful. 

As they are designed to extract important features of the data, they are a form of [[Unsupervised learning]], and they can be used as [[Generative model]]s

[img[http://nghiaho.com/wp-content/uploads/2012/12/autoencoder_network1.png]]

[[Neural networks [6.1] : Autoencoder - definition|https://www.youtube.com/watch?v=FzS3tMl4Nsc&list=PL6Xpj9I5qXYEcOhn7TqghAJ6NAPrNmUBH&index=44]]

[[Two Minute Papers - What is an Autoencoder?|https://www.youtube.com/watch?v=Rdpbnd0pCiI]]

https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/

!!__Variational autoencoder__

[[Deep Learning Lecture 14: Karol Gregor on Variational Autoencoders and Image Generation|https://www.youtube.com/watch?v=P78QYjWh5sM&list=PLjK8ddCbDMphIMSXn-w1IjyYpHU3DaUYw&index=14]]

!!__Denoising autoencoder__

http://deeplearning.net/tutorial/dA.html

!!__Sparse autoencoder__

---------------

[[Generative adversarial network]] are similar, but we learn the cost function, instead of just using l2 loss  ([[vid|https://www.youtube.com/watch?v=QPkb5VcgXAM#t=58m50]])

https://www.wikiwand.com/en/Autoencoder

http://ufldl.stanford.edu/tutorial/unsupervised/Autoencoders/